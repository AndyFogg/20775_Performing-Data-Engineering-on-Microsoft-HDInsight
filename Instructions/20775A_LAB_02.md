# Module 2: Deploying HDInsight Clusters

## Lab: Managing HDInsight clusters by using the Azure Portal

### Scenario

You are piloting HDInsight clusters on Machine Learning and you want to create HDInsight clusters that can access data that is held in Data Lake Store. You then want to customize these clusters by using script actions, implemented through the Azure Portal.

At the end of the lab, you will delete the cluster so that your account does not get charged.

### Objectives

After completing this lab, you will be able to:

-   Create an HDInsight cluster that uses Data Lake Store storage.

-   Customize HDInsight by using script actions.

-   Delete an HDInsight cluster.

### Lab Setup

-   **Estimated Time**: 60 minutes

-   **Virtual machine**: 20775A-LON-DEV

-   **Username**: Admin

-   **Password**: Pa55w.rd

## Exercise 1: Create an HDInsight cluster that uses Data Lake Store storage

### Scenario

You have been tasked to use the Azure Portal to create an HDInsight cluster that has access to Data Lake Store. For supported cluster types, you can use Data Lake Store as default storage or as an additional storage account. For this scenario, you will use Data Lake Store as the default storage account.

The main tasks for this exercise are as follows:

1. Create a Data Lake Store account

2. Define basic configuration for a Linux-based Spark cluster

3. Configure access between the Spark cluster and the Data Lake Store account

4. Provision the cluster and verify cluster creation

#### Task 1: Create a Data Lake Store account

1.  Ensure that the **MT17B-WS2016-NAT**, and **20775A-LON-DEV** virtual machines are running, and then log on to **20775A-LON-DEV** as **Admin** with the password **Pa55w.rd**.

2.  In the Azure Portal, select **New** and **Data Lake Store**, and configure it as follows:

    -   **Name**: \<*your name*\>\<*date*\>dls (must be unique)

    -   **Subscription**: Your Azure subscription

    -   **Resource group (create new)**: datalakerg

    -   **Location**: Select your region

    -   **Pricing**: Pay-as-You-Go

    -   **Encryption settings**: Do not enable encryption

3.  Create a new folder under your new Data Lake Store account called **clusters** to manage and store data.

#### Task 2: Define basic configuration for a Linux-based Spark cluster 

1.  On the **HDInsight** blade, create a custom Spark 2.3.0 (HDI 3.6) Linux cluster on a standard tier within your Azure subscription.

2.  Use the following details:

    -   **Cluster login password**: Pa55w.rdPa55w.rd

    -   **Resource group (Use existing)**: datalakerg

    -   **Location**: Select your region

#### Task 3: Configure access between the Spark cluster and the Data Lake Store account

1.  Create a new service principal for your Data Lake Store account by using the following information:

    -   **Service principal name**: \<*your name*\>\<*date*\>sp

    -   **Certificate password**: Pa55w.rd

    -   **Confirm password**: Pa55w.rd

2.  Configure Read, Write, and Execute file permissions for your Data Lake Store account.

#### Task 4: Provision the cluster and verify cluster creation

1.  Complete your cluster configuration, using the following cluster size options:

    -   **Number of Worker nodes**: 1

    -   **Worker node size**: A3 General Purpose

    -   **Head node size**: A3 General Purpose

2.  On the **Cluster summary** blade, note the estimated cost per hour of this cluster. To avoid using up your Azure Pass allowance, it is important that you remove the cluster when you are not using it.

3.  Create the cluster. The deployment might take 20-30 minutes to complete. Wait for the cluster to be provisioned and do not continue with this exercise until the status shows as **Running**.

4.  Verify that the HDInsight cluster is using the Data Lake Store account.

5.  Verify that the service principal is correctly associated with the HDInsight cluster, and that the **SERVICE PRINCIPAL** status is **Enabled**.

**Results**: At the end of this exercise, you will have set up an
HDInsight cluster that uses Data Lake Store as the storage.

## Exercise 2: Customize HDInsight by using script actions

### Scenario

You have been asked to attach an additional Azure Storage account to the Spark in HDInsight cluster that you created in the last exercise. You will perform this action by using the Azure Portal.


> **Note**: For the purposes of this exercise, the Azure Storage account will be a new, empty account. In a production system, the additional storage account might contain data that you want to analyze in HDInsight.

The main tasks for this exercise are as follows:

1. Create a storage account to use as additional storage

2. Connect additional storage to a running cluster by using a script action

#### Task 1: Create a storage account to use as additional storage

1.  In the Azure Portal, create a new **blob, file, table, queue** storage account with the name **\<*your name*\>\<*date*\>sa**. Use **Locally Redundant storage (LRS)** replication, and link the account to your **Azure Pass** subscription.

2.  Wait for the storage account to be created before continuing with this exercise.

3.  Copy one of the storage account access keys into Notepad, for easy access in the next task.

#### Task 2: Connect additional storage to a running cluster by using a script action

1.  In the Azure Portal, use the predefined **Add an Azure Storage account** script action to add the additional storage account to your HDInsight cluster. The script takes two parameters:

    -   The storage account name.

    -   The access key for the storage account (which you copied into Notepad in the previous task).

2.  To verify your changes, log in to the Cluster dashboard (Ambari) for your HDInsight cluster. Search **HDFS Configs** for references to the additional storage account name. When you have finished, close the cluster dashboard.

**Results**: At the end of this exercise, you will have used script actions from the Azure Portal to add storage to a running cluster.

## Exercise 3: Delete an HDInsight cluster

### Scenario

The Azure charging model makes it imperative to know how to delete clusters when you're not using them. In this exercise, you will delete clusters by using Azure Portal. This ensures that you avoid being charged for cluster resources when you are not using them. If you are using a trial Azure subscription that includes a limited free credit value, deleting the cluster maximizes your credit and helps to prevent using all of the credit before the free trial period.

Now that you have finished the demonstrations and lab, you can delete the HDInsight cluster and storage account.

The main tasks for this exercise are as follows:

1. Delete the HDInsight cluster and storage account

#### Task 1: Delete the HDInsight cluster and storage account

- Delete the HDInsight cluster and storage account by deleting the associated resource group.

**Results**: At the end of this exercise, you will have deleted a cluster, and its storage account, by using the Azure Portal.

---

Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
