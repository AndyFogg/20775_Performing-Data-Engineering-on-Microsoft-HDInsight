# Module 6: Implementing Batch Solutions

## Lab: Implement batch solutions

### Exercise 1: Deploy HDInsight cluster and data storage

#### Task 1: Create an Azure SQL Database

1.  Ensure that the **MT17B-WS2016-NAT**, and **20775A-LON-DEV** virtual machines are running, and then log on to **20775A-LON-DEV** as **Admin** with the password **Pa55w.rd**.

2.  On the **20775A-LON-DEV** virtual machine, on the Start menu, start to type **Internet Explorer**, and then click **Internet Explorer**.

3.  In the address bar, type **http://portal.azure.com**, and then sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.

4.  In the Azure Portal, click **+ Create a resource**.

5.  Click **Databases**, and then click **SQL Database**.

6.  On the **SQL Database** blade, enter the following details, and then click **Server**:

    -   **Database name**: sqldb1

    -   **Subscription**: Your subscription

    -   **Resource group (Create new)**: mod06rg

    -   **Select source**: Blank database

7.  On the **New server** blade, enter the following details, and then click **Select**:

    -   **Server name**: \<*your name\>\<date*\>mod06sqlsvr1

    -   **Server admin login**: dbadmin

    -   **Password**: Pa55w.rd123

    -   **Confirm password**: Pa55w.rd123

    -   **Location**: your region
  
    -   **Allow Azure services to access server**: selected  

8.  On the **SQL Database** blade, click **Pricing tier**.

9.  On the **Configure** blade, click **Basic**, and then click **Apply**.

10. On the **SQL Database** blade, click **Create**.

11. Wait for the database to be created; this will take a few minutes.

#### Task 2: Create an HDInsight cluster

1.  In the Azure Portal, click **+ Create a resource**.

2.  Click **Analytics**, and then click **HDInsight**.

3.  On the **Basics** blade, enter the following information, and then click **Cluster type**:

    -   **Cluster name**: \<*your name\>\<date*\>mod06hive

    -   **Subscription**: Your subscription

4.  On the **Cluster configuration** blade, enter the following information, and then click **Select**:

    -   **Cluster type**: Hadoop

    -   **Operating system**: Linux

    -   **Version**: Hadoop 2.7.3 (HDI 3.6)

5.  On the **Basics** blade, enter the following information, and then click **Next**:

    -   **Cluster login username**: hadmin

    -   **Cluster login password**: Pa55w.rd123

    -   **Secure Shell (SSH) username**: sadmin

    -   **Use same password as cluster login**: selected

    -   **Resource group (Use existing)**: mod06rg

    -   **Location**: Your region

6.  On the **Storage** blade, under **Select a Storage account**, click **Create new**.

7.  In the **Create a new Storage account** box, type **\<*your name\>\<date*\>mod06sa**.

8.  Edit the **Default container**, so that it is **\<*your cluster name*\>-ctr**.

9.  Under **Metastore Settings (optional)**, in the **Select a SQL database for Hive** list, click **<*your name><date*>mod06sqlsvr1/sqldb1**.

10. Click **Authenticate SQL database**.

11. On the **Authenticate** blade, in the **SQL Database username** box, type **dbadmin**.

12. In the **SQL Database password** box, type **Pa55w.rd123**, and then click **Select**.

13. On the **Storage** blade, in the **Select a SQL database for Oozie** list, click **<*your name><date*>mod06sqlsvr1/sqldb1**.

14. Click **Authenticate SQL database**.

15. On the **Authenticate** blade, in the **SQL Database username** box, type **dbadmin**.

16. In the **SQL Database password** box, type **Pa55w.rd123**, and then click **Select**.

17. On the **Storage** blade, click **Next**.

18. On the **Cluster summary** blade, next to **Cluster size**, click **Edit**.

19. On the **Cluster size** blade, in the **Number of Worker nodes** box, type **1**.

20. Click **Worker node size**.

21. On the **Choose your node size** blade, click **View all**, click **A3 General Purpose**, and then click **Select**.

22. Click **Head node size**.

23. On the **Choose your node size** blade, click **View all**, click **A3 General Purpose**, and then click **Select**.

24. On the **Cluster size** blade, click **Next**.

25. On the **Script actions** blade, click **Next**.

26. On the **Cluster summary** blade, click **Download template and parameters**.

27. On the **Template** blade, click **Download**.

28. In the message box, click the **Save** drop-down arrow, and then click **Save as**.

29. In the **Save As** dialog box, navigate to **E:\\Labfiles\\Lab06**, in the **File name** box, type **my_hive_deployment**, and then click **Save**.

30. Close the Template blade.

31. On the **Cluster summary** blade, click **Create**.

32. Wait until the cluster is created before continuing to the next task; cluster creation will take between 10 and 15 minutes.

**Results**: At the end of this exercise, you will have created an Azure SQL Database, and created an HDInsight, Hadoop cluster that uses this data storage.

### Exercise 2: Use data transfers with HDInsight clusters

#### Task 1: Download data from Blob storage using the Azure Portal

1.  In the Azure Portal, click **All resources**, and then click **<*your name><date*>mod06sa**.

2.  On the **<*your name><date*>mod06sa** blade, under **Blob service**, click **Blobs**.

3.  In the containers list, click **<*your name><date*>mod06hive-ctr**.

4.  Navigate to the **user/oozie/share/lib/hcatalog** folder, right-click **activation-1.1.jar**, and then click **Download**.

5.  In the message box, click **Save**.

6.  In the message box, click **Open folder**.

7.  In File Explorer, note the downloaded file, and then close File Explorer.

#### Task 2: Download data using the Cloud Shell

1.  On the toolbar, click **Microsoft Edge**.

2.  In the address bar, type **http://portal.azure.com**, and then sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.

3.  In the Azure Portal, click **All resources**, and then click **<*your name><date*>mod06sa**.

4.  On the **<*your name><date*>mod06sa** blade, under **Settings**, click **Access keys**.

5.  On the **Access keys** blade, under **key1**, click the **Click to copy** button next to **Key**.

6.  Click **Start**, type **notepad**, and then click **Notepad**.

7.  In Notepad, on the **Edit** menu, **Paste**.

8.  In Edge, in the Azure Portal, on the top ribbon, click **Cloud Shell** (the **>_** button).

9.  In the window at the bottom of the screen, on the **Welcome to Azure Cloud Shell** window, click **Bash**.
    
10. In the **You have no storage mounted** dialog box, click **Create storage**.

11. Wait for the Cloud Shell initialization to complete.

> **Note**: All of the following commands can be copied from **E:\\Labfiles\\Lab06\\BashCmds.txt**.

12. At the Bash prompt, type the following command, and then press Enter:
    ````
    azure storage account list
    ````

    A list of all storage accounts is now shown; note that you now have an additional cloud shell account.

13. At the Bash prompt, type the following command, and then press Enter (replacing **\<storage account\>** with the storage account you created earlier, **\<*your name\>\<date*\>mod06sa**):
    ````
    export AZURE_STORAGE_ACCOUNT=<storage account>
    ````

    This command saves your storage account in a variable, so that you do not have to enter it every time; note that in Edge, you can right-click, and click **Paste**, to copy the text strings you have saved in Notepad.

14. At the Bash prompt, type the following command, and then press Enter (replacing **\<primary key\>** with the details you saved to Notepad):
    ````
    export AZURE_STORAGE_ACCESS_KEY=<primary key>
    ````

    This command saves your primary key in a variable, so that you do not have to enter it every time.

15. To list all the blobs in your Azure storage container, type the following command, and then press Enter (replacing **\<container\>** with the storage container you created earlier, **\<your name\>\<date\>mod06hive-ctr**):
    ````
    azure storage blob list <container>
    ````

    This command lists all the blobs in the default container.

16. At the Bash prompt, type the following command, and then press Enter:
    ````
    ls
    ````

17. The file list should be empty, except for a mount point for the Cloud Shell's persistent file share (clouddrive).

18. At the Bash prompt, type the following command, and then press Enter:
    ````
    cd clouddrive
    ````

19. At the Bash prompt, type the following command, and then press Enter:
    ````
    ls
    ````
    The file list should also be empty.

20. At the Bash prompt, type the following command, and then press Enter (replacing **\<container\>** with the storage container you created earlier, **\<your name\>\<date\>mod06hive-ctr**):
    ````
    azure storage blob download <container> example/data/fruits.txt fruits.txt
    ````

21. At the Bash prompt, type the following command, and then press Enter:
    ````
    ls
    ````

22. The file list should now show that **fruits.txt** has been downloaded to your bash user's cloud shell folder.

23. At the Bash prompt, type the following command, and then press Enter:
    ````
    nano
    ````

24. In the nano editor, type some text, press CTRL+X, and then press Y.

25. At the **File Name to Write** prompt, type **worknotes.txt**, and then press Enter.

26. At the Bash prompt, type the following command, and then press Enter:
    ````
    ls
    ````

27. The file list should be show that **worknotes.txt** has been created in your bash user's cloud shell folder.

28. Close the bash shell.

#### Task 3: Deprovision an HDInsight cluster

1.  Switch to Internet Explorer, and in the Azure Portal, click **All resources**, and then click **\<*your name\>\<date*\>mod06hive**.

2.  On the **\<*your name\>\<date*\>mod06hive** blade, click **Delete**.

3.  On the **Are you sure you want to delete \<*your name\>\<date*\>mod06hive** blade, in the **Type HDInsight cluster name** box, type **\<*your name\>\<date*\>mod06hive**, and then click **Delete**.

4.  Wait until the cluster deletion has completed, before continuing to the next task.

#### Task 4: Reprovision an HDInsight cluster using a template

1.  In Internet Explorer, in the Azure Portal, click **All services**.

2.  In the services list, click **Templates**, and then click **+ Add**.

3.  On the **General** blade, in the **Name** box, type **my_hive_deployment**.

4.  In the **Description** box, type **My hive deployment**, and then click **OK**.

5.  On the **ARM Template** blade, delete all the existing default text.

6.  Using File Explorer, navigate to **E:\\Labfiles\\Lab06**, right-click **my_hive_deployment.zip**, and then click **Extract All**.

7.  In the **Extract Compressed (Zipped) Folders** dialog box, click **Extract**.

8.  In the **my_hive_deployment** folder, right-click **template.json**, point to **Open with**, and then click **Choose another app**.

9.  In the **How do you want to open this file** dialog box, click **More apps**, and then double-click **Notepad**.

10. In Notepad, on the **Edit** menu, click **Select All**, and then press CTRL+C.

11. In Internet Explorer, in the **ARM Template** box, press CTRL+V to paste the template code.

> **Note**: All of the following template code can be copied from **E:\\Labfiles\\Lab06\\templateCode.txt**.

12. On the **ARM Template** blade, click at the end of line 6, press Enter, and then type the following code:
    ````
    "defaultValue": "<your name><date>mod06hiveX",
    ````

13. On line 14, replace **admin** with **hadmin**.

14. On line 55, replace **sshuser** with **sadmin**.

15. Click at the end of line 67, press Enter, and then type the following code:
    ````
    "defaultValue": "dbadmin",
    ````
    
16. Click at the end of line 77, press Enter, and then type the following code:
    ````
    "defaultValue": "dbadmin",
    ````    
17. Click **OK**.

18. On the **Add template** blade, click **Add**.

19. On the **Templates** blade, click **Refresh**.

20. On the **Templates** blade, right-click **my_hive_deployment**, and then click **Deploy**.
    
21. On the **Custom deployment** blade, enter the following information:
    - **Resource group (Use existing)**: mod06rg
 
    - **Cluster Name**: replace "X" with 2 (for example, \<*your name\>\<date*\>mod06hive2)

    - **Cluster Login Password**: Pa55w.rd123

    - **Ssh Password**: Pa55w.rd123

    - **Hive Password**: Pa55w.rd123

    - **Oozie Password**: Pa55w.rd123

22. Select the **I agree to the terms and conditions stated above** check box, and then click **Purchase**.

23. Wait until the cluster is created before continuing to the next task; cluster creation will take between 10 and 15 minutes.

#### Task 5: Upload data from the Cloud Shell to HDInsight cluster

1.  Switch to Edge.

2.  In the Azure Portal, on the top ribbon click **Cloud Shell** (the **>_** button).

> **Note**: All of the following commands can be copied from **E:\\Labfiles\\Lab06\\BashCmds.txt**.

3.  At the Bash prompt, type the following command, and then press Enter:
    ````
    azure storage account list
    ````

4.  Note, that you still have the same storage accounts as before.

5.  At the Bash prompt, type the following command, and then press Enter (replacing **\<storage account\>** with the storage account you created earlier, **\<*your name\>\<date*\>mod06sa**):
    ````
    export AZURE_STORAGE_ACCOUNT=<storage account>
    ````

6.  At the Bash prompt, type the following command, and then press Enter (replacing **\<primary key\>** with the details you saved to Notepad):
    ````
    export AZURE_STORAGE_ACCESS_KEY=<primary key>
    ````

7.  At the Bash prompt, type the following command, and then press Enter:
    ````
    cd clouddrive
    ````

8.  At the Bash prompt, type the following command, and then press Enter (replacing **\<container\>** with the storage container you created earlier, **\<*your name\>\<date*\>mod06hive-ctr**):
    ````
    azure storage blob upload worknotes.txt <container> example/data/worknotes.txt
    ````

9.  Click **All resources**, and then click **\<*your name\>\<date*\>mod06sa**.

10. On the **\<*your name\>\<date*\>mod06sa** blade, under **Blob service**, click **Blobs**, and then click **\<*your name\>\<date*\>mod06hive-ctr**.

11.  Navigate to the **example/data/** folder, and verify that **worknotes.txt** has been uploaded.

12.  Close Microsoft Edge.

**Results**: At the end of this exercise, you will have downloaded data from Blob storage using the Azure Portal, and by using the Cloud Shell; you will also have deprovisioned an HDInsight cluster, reprovisioned the HDInsight cluster using a template, and then uploaded data from the Cloud Shell to the HDInsight cluster.

### Exercise 3: Query HDInsight cluster data

#### Task 1: Query data using a Pig job in PowerShell

1.  Using File Explorer, navigate to **E:\\Labfiles\\Lab06**.

2.  Rename **hivepig.ps1.txt** to **hivepig.ps1**.

3.  In the **Rename** dialog box, click **Yes**.

4.  Click **Start**, type **Windows** **PowerShell ISE**, and then press Enter. 

5.  In the PowerShell ISE, on the **File** menu, click **Open**.

6.  In the **Open** dialog box, navigate to **E:\\Labfiles\\Lab06**, click **hivepig.ps1**, and then click **Open**.

7.  On the toolbar, click **Run Script**.

8.  In the **Sign in to your account** dialog box, enter the Microsoft account and password that is associated with your Azure Learning Pass subscription, and then click **Sign in**.

9.  When prompted, type **\<*your name\>\<date*\>mod06hiveX** (the name of the cluster you created in Exercise 2), and then press Enter.

10. In the **Windows PowerShell credential request** dialog box, enter the following, and then click **OK**:

    -   **User name**: hadmin

    -   **Password**: Pa55w.rd123

11. The Pig job should now run; if you get errors, repeat from step 7 above.

12. When the job has completed, it will display the following results:
    ````
    (TRACE,816)
    (DEBUG,434)
    (INFO,96) 
    (WARN,11) 
    (ERROR,6) 
    (FATAL,2)
    ````
    These results show the total number of different severity level messages reported in in the sample log.

#### Task 2: Query data using an interactive Pig job

1.  Click **Start**, type **putty**, and then press Enter.

2.  In the **PuTTY Configuration** dialog box, on the **Session** page, in the **Host Name (or IP address)** box, enter the following, replacing :
    ````
    <your name><date>mod06hiveX-ssh.azurehdinsight.net
    ````

3.  Under **Connection type**, click **SSH**, and then click **Open**.

4.  In the **PuTTY Security Alert** dialog box, click **Yes**.

5.  When you are prompted, enter **sadmin** and **Pa55w.rd123** as the credentials.

6.  At the PuTTY prompt, type the following command, and then press Enter:
    ````
    pig
    ````

7.  At the PuTTY prompt, type the following command, and then press Enter:
    > **Note**: This code can be copied from **E:\\Labfiles\\Lab06\\pigJob.txt**:
    ````
    LOGS = LOAD 'wasbs:///example/data/sample.log';
    LEVELS = foreach LOGS generate REGEX_EXTRACT($0, '(TRACE|DEBUG|INFO|WARN|ERROR|FATAL)', 1) as LOGLEVEL;
    FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;
    GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;
    FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL,
    COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;
    RESULT = order FREQUENCIES by COUNT desc;
    DUMP RESULT;
    ````

8.  The job will take several minutes to complete; the results should be the same as the previous task:
    ````
    (TRACE,816)
    (DEBUG,434)
    (INFO,96) 
    (WARN,11) 
    (ERROR,6) 
    (FATAL,2)
    ````

    As before, these results show the total number of different severity level messages reported in in the sample log.

9.  Close PuTTY.

#### Task 3: Query data using HiveQL from the Ambari dashboard

1.  In the Azure Portal, click **All resources**, and then click **\<*your name\>\<date*\>mod06hiveX**.

2.  On the **\<*your name\>\<date*\>mod06hiveX** blade, under **Cluster dashboards**, click **Ambari home**.

3.  In the **Windows Security** dialog box, enter the following details, and then click **OK**:

    -   **User name**: hadmin

    -   **Password**: Pa55w.rd123

4.  On the Ambari dashboard, if there are any alerts, complete the following steps:

    1.  On the **Actions** drop-down list, click **Start All**.
    2.  In the **Confirmation** dialog box, click **Confirm Start**.
    3.  In the **1 Background Operation Running** dialog box, wait until the services have been started, click **OK**.

5.  On the top toolbar, click the hamburger menu, and then click **Hive View 2.0**.

6.  In the **Query Editor**, type the following code, and then click **Execute**:
    > **Note**: This code can be copied from **E:\\Labfiles\\Lab06\\hiveHql.txt**.
    ````
    set hive.execution.engine=tez;
    DROP TABLE log4jLogs;
    CREATE EXTERNAL TABLE log4jLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '
    STORED AS TEXTFILE LOCATION 'wasbs:///example/data/';
    SELECT t4 AS sev, COUNT(*) AS count FROM log4jLogs WHERE t4 = '[ERROR]' AND INPUT__FILE__NAME LIKE '%.log' GROUP BY t4;
    ````

7.  The job will take several minutes to complete; there are only 3 rows in the logs where the column t4 contains the value **[ERROR]**, so the result should be:
    ````
    [ERROR] 3
    ````

8.  Close the Ambari tab.

#### Task 4: Remove all Azure resources

1.  In the Microsoft Azure Portal, click **Resource groups**.

2.  On the **Resource groups** blade, right-click **mod06rg**, and then click **Delete resource group**.

3.  On the **Are you sure you want to delete** blade, in the **TYPE THE RESOURCE GROUP NAME** box, type **mod06rg**, and then click **Delete**.

4.  Wait for your resource group to be deleted, and then click **All resources**. Verify that the cluster, SQL database and server, and the storage account that was created with your cluster, have all been removed.

5.  On the **Resource groups** blade, right-click the resource group that contains your cloud shell storage account, and then click **Delete**.

6.  In the **TYPE THE RESOURCE GROUP NAME** box, type the cloud shell storage account name, and then click **Delete**.

7.  Wait for your resource group to be deleted, and then click **All resources**. Verify that the cloud shell storage account has been deleted, and that all Azure resources have been removed.

**Results**: At the end of this exercise, you will have queried HDInsight data using a Pig job in PowerShell, and by using Pig in an interactive session. You will also have queried HDInsight data using HiveQL from the Ambari dashboard.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
