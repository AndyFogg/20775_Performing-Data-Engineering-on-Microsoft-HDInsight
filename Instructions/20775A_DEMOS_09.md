# Module 9: Analyze Data with Hive and Phoenix


## Demo 1: Implement interactive queries for big data with Interactive Hive

### Scenario

In this demonstration, you will perform the following tasks to implement an interactive query with Hive:
-  Create an Interactive Hive cluster.
-  Review the LLAP settings in Ambari.
-  Connect Excel to an Interactive Hive cluster.

### Preparation

Ensure that the **MT17B-WS2016-NAT** and **20775A-LON-DEV** virtual machines are running, and then log on to **20775A-LON-DEV** as **Admin** with the password **Pa55w.rd**. 

Install the following: [Microsoft HiveODBC Driver (32 and 64 bit versions)](http://www.microsoft.com/en-ca/download/details.aspx?id=40886)

### Create an Interactive Hive cluster
1.  On the **20775A-LON-DEV** virtual machine, on the Start menu, start to type **Internet Explorer**, and then click **Internet Explorer**.
2.  In the address bar, type **http://azure.microsoft.com**, click **Portal**, and then sign in using the Microsoft account that is associated with your Microsoft Learning Azure Pass subscription.
3.  In the Azure Portal, click **All resources**, and then verify that there are no existing HDInsight clusters in your subscription. 
4.  In the Azure Portal, in the left pane, click **+ Create a resource**.
5.  Click **Analytics**, and then click **HDInsight**.
6.  On the **HDInsight** blade, click **Custom (size, settings, apps)**.
7.  On the **Basics** blade, click **Cluster type**.
8.  On the **Cluster configuration** blade, enter the following options, and then click **Select**:
    -  **Cluster type**: Interactive Query
    -  **Version**: Interactive Query 2.1.0 (HDI 3.6)
9.  On the **Basics** blade, enter the following settings, and then click **Next**:
    -  **Cluster name**: \<*your name*\>hivellap
    -  **Subscription**: your subscription
    -  **Cluster login username**: admin
    -  **Cluster login password**: Pa55w.rdPa55w.rd
    -  **Secure Shell (SSH) username**: sshuser
    -  **Use same password as cluster login**: Selected
    -  **Resource group (Create new)**: hivellaptrain01rg
    -  **Location**: Pick your location
10. On the **Security + networking** blade, click **Next**.
11. On the **Storage** blade, under **Select a Storage account**, click **Create new**.
12. In the **Create a new Storage account** box, type **\<*your name*\>hivellapsg**; point out that this name must be globally unique.
13. In the **Default container** box, replace the suggested name with the name of your cluster (for example, **\<*your name*\>hivellap**).
14. Leave all other settings at their defaults, and then click **Next**.
15. On the **Applications (optional)** blade, normally you can install popular data science tools such as H20 or Dataiku or any other apps; however, for Interactive Hive Cluster, no applications are available, click **Next**.
16. On the **Cluster size** blade, in the **Number of Worker nodes** box, type **2**.
17. Click **Worker node size**.
18. On the **Choose your node size** blade, click **View all**, click **D13 V2 Optimized**, and then click **Select**.
19. Click **Head node size**.
20. On the **Choose your node size** blade, click **View all**, click **D13 V2 Optimized**, and then click **Select**.
21. Click **Zookeeper node sizes**.
22. On the **Choose your node size** blade, click **View all**, click **A4 V2 Standard**, and then click **Select**.
23. On the **Cluster size** blade, click **Next**.
24. On the **Script Actions (optional)** blade, click **Next**.
25. On the **Cluster summary** blade, point out the estimated cost per hour of this cluster. Remind students that, to avoid using up their Azure Pass allowance, it is important that they remove clusters when they are not using them.
26. On the **Cluster summary** blade, click **Create**.
27. Wait for the cluster to be provisioned before proceeding with the demonstration. This may take 15â€“20 minutes.
28. Click **All resources**, click **\<*your name*\>hivellap**, and then show the status as **Running**.

### Review the LLAP settings in Ambari
1.  On the **\<*your name*\>hivellap** blade, under **Cluster dashboards**, click **Ambari home**.
2.  In the **Windows Security** dialog box, enter the username name **admin** and password **Pa55w.rdPa55w.rd** to log into the Ambari web-based Hadoop Cluster management console. 
3.  In the left-hand menu, click  **Hive**.
4.  On the **Summary** tab, point out the summary information.
5.  On the **Configs** tab, point out the Interactive Hive settings.

    >**Note**: **Interactive Query** is set to **Yes**, and the key LLAP configurations come with default values. You can always adjust these values as per your query concurrency and cache memory requirements.

6.  Close the Ambari tab.

### Connect Excel to an Interactive Hive cluster

Analyze and visualize the **hivesampletable** dataset, available in the Hive **default** schema.

1.  Click Start, type **ODBC Data Sources (32-bit)**, and then press Enter
2.  In the **ODBC Data Source Administartor (32-bit)** dialog box, on the **User DSN** tab, click **Add**.
3.  In the **Create New Data Source** dialog box, click **Microsoft Hive ODBC Diver**, and then click **Finish**.
4.  In the **Microsoft Hive ODBC Diver DSN Setup** dialog box, enter the following details, and then click **HTTP Options**:
    -  **Data Source name**: Microsoft Hive DSN
    -  **Description**: Sample Microsoft Hive DSN
    -  **Host(s)**: \<*your name*\>hivellap.azurehdinsight.net
    -  **Port**: 443
    -  **Database**: default
    -  **Mechanism**: Windows Azure HDInsight Service
    -  **User Name**: admin
    -  **Password**:  Pa55w.rdPa55w.rd
    -  **Delegation UID**: *empty*
    -  **Thrift Transport**: HTTP
5.  In the **HTTP Properties** dialog box, in the **HTTP Path** box, type **/hive2**, and then click **OK**.
6.  In the **Microsoft Hive ODBC Diver DSN Setup** dialog box, click **SSL Options**.
7.  In the **SSL Options** dialog box, ensure the **Enable SSL** check box is selected, and then click **OK**.
8.  In the **Microsoft Hive ODBC Diver DSN Setup** dialog box, click **Test**.
9.  In the **Test Results** dialog box, ensure the **Successfully connected to data source**  message appears, and then click **OK**.
10. In the **Microsoft Hive ODBC Diver DSN Setup** dialog box, click **OK**.
11. In the **ODBC Data Source Administartor (32-bit)** dialog box, click **OK**.
12. Open Excel 2016 with a blank workbook.
13. On the **Data** ribbon, click **Get External Data**, click **From other sources**, and then click **From Data Connection Wizard**.
14. In the **Data Connection Wizard**, click **ODBC DSN**, and click **Next**.
15. On the **Connect to ODBC Data Source** page, click **Microsoft Hive DSN**, and then click **Next**.
16. In the **Microsoft Hive ODBC Diver Connection Dialog** dialog box, in the **Password** box, type **Pa55w.rdPa55w.rd**, and then click **OK**.
17. On the **Select Database and Table** page, in the **Select the database that contains the data you want** drop-down list, click **HIVE**, click the **hivesampletable** table, and then click **Next**.
18. On the **Select Data Connection File and Finish** page, click **Finish** to start importing data.
19. In the **Import Data** dialog box, click **Properties**.
20. In the **Connection property** dialog box, click **OK**.
21. In the **Import Data** dialog box, click **OK**.
22. In the **Microsoft Hive ODBC Diver Connection Dialog** dialog box, in the **Password** box, type **Pa55w.rdPa55w.rd**, and then click **OK**.
23. Within few seconds, your data will be available in Excel to carry out further analysis.
24. Close Excel 2016 without saving any changes.

## Demo 2: Perform exploratory data analysis using Hive

### Scenario

In this demonstration, you will perform the following tasks to carry out an exploratory analysis:
-  Open Zeppelin Notebook.
-  Create ORC formatted tables.
-  Perform exploratory analysis.

### Preparation

In this demonstration, you will use the Interactive Hive cluster you created in the previous lesson.

You will use a **hivesampletable** that has weblog related information. This table already exists in the default schema on Interactive Hive Cluster. You will then use Zeppelin Notebook to perform data ingestion, exploration, and visualization.

### Open Zeppelin Notebook

1.  In the Azure Portal, on the **\<*your name*\>hivellap** blade, under **Cluster dashboards**, click **Zeppelin notebook**.
2.  If prompted, enter the cluster admin credentials.

### Create an ORC formatted table

1.  On the **Zeppelin** page, in the header pane, click **Notebook**, and then click **+ Create new note**.
2.  In the **Create new note** dialog box, type **ORC formatted table**, and then click **Create Note**.
3.  In the first cell, type **%jdbc(hive)**, and then press Enter.
4.  Using File Explorer, navigate to **E:\Demofiles\Mod09\Demo02**, and then open the **create_orc_table.hql** file in Notepad.
5.  Review the code, and then paste the whole file contents into the first cell of your notebook following the **%jdbc(hive)** command.
6.  Press Shift+Enter.

### Perform exploratory analysis

1.  Using File Explorer, navigate to **E:\Demofiles\Mod09\Demo02**, and then open the **exploratory_data_analysis_with_hive.hql** file in Notepad.
2.  Review all the SQL queries/Steps:
    -  In **Step 1**, you perform basic data exploration (counts, viewing sample rows, and so on).
    -  In **Step 2**, you run a query to identify the countries where the Contoso e-commerce platform is operating.
    -  In **Step 3**, you run a query to identify the countries that have the highest web traffic to this e-commerce platform.
    Please note that any errors reported back, can be ignored.
    -  In **Step 4**, you run a query to identify the device platform that is most commonly used by website users.
    -  In **Step 5**, you run a query to identify the frequent visitors (appearing more than six times in this dataset) across different countries.


>**Note**: For all the following queries, when the data is loaded, click a visualization (bar, pie or trend chart in the rectangular icon at the bottom-left corner of the cell) to convert the data into a visualization. Switching between visualizations can take a long time. Also, click settings to play with advanced settings.

3.  In the new empty cell, type **%jdbc(hive)**, and then press Enter.
4.  Copy and paste all the code under **Step 1** into the bottome cell following the **%jdbc(hive)** command, and then press Shift+Enter.
5.  In the new empty cell, type **%jdbc(hive)**, and then press Enter.
6.  Copy and paste all the code under **Step 2** into the bottome cell following the **%jdbc(hive)** command, and then press Shift+Enter.
7.  In the new empty cell, type **%jdbc(hive)**, and then press Enter.
8.  Copy and paste all the code under **Step 3** into the bottome cell following the **%jdbc(hive)** command, and then press Shift+Enter.
9.  In the new empty cell, type **%jdbc(hive)**, and then press Enter.
10. Copy and paste all the code under **Step 4** into the bottome cell following the **%jdbc(hive)** command, and then press Shift+Enter.
11. In the new empty cell, type **%jdbc(hive)**, and then press Enter.
12. Copy and paste all the code under **Step 5** into the bottome cell following the **%jdbc(hive)** command, and then press Shift+Enter.
13. Close the Zeppelin tab.

>**Note**: Typically, your notebooks are saved on the head node of the cluster. However, its lifetime is for the duration of the cluster only, so you can export the notebook onto your local file system/blob storage and can import in Notebook on any cluster for later usage.


## Demo 3: Perform interactive processing by using Apache Phoenix on HBase

### Scenario

In this demonstration, you will perform the following tasks to implement an interactive query with Phoenix:
-  Create an HBase cluster.
-  Ingest data into Phoenix.
-  Perform interactive queries.

### Create an HBase cluster

1.  On the **20775A-LON-DEV** virtual machine, on the Start menu, start to type **Internet Explorer**, and then click **Internet Explorer**.
2.  In the address bar, type **http://azure.microsoft.com**, click **Portal**, and then sign in using the Microsoft account that is associated with your Microsoft Learning Azure Pass subscription.
3.  In the Azure Portal, in the left pane, click **+ Create a resource**.
4.  Click **Analytics**, and then click **HDInsight**.
5.  On the **HDInsight** blade, click **Custom (size, settings, apps)**.
6.  On the **Basics** blade, click **Cluster type**.
7.  On the **Cluster configuration** blade, enter the following options, and then click **Select**:
    -  **Cluster type**: HBase
    -  **Version**: HBase 1.1.2 (HDI 3.6)
8.  On the **Basics** blade, enter the following settings, and then click **Next**:
    -  **Cluster name**: \<*your name*\>hbasetrain
    -  **Subscription**: your subscription
    -  **Cluster login username**: admin
    -  **Cluster login password**: Pa55w.rdPa55w.rd
    -  **Secure Shell (SSH) username**: sshuser
    -  **Use same password as cluster login**: Selected
    -  **Resource group (Create new)**: hbasetrain01rg
    -  **Location**: Pick a different location to the previous cluster, this is due to the limitation on the cores in one region
9.  On the **Security + networking** blade, click **Next**.
10. On the **Storage** blade, under **Select a Storage account**, click **Create new**.
11. In the **Create a new Storage account** box, type **\<*your name*\>hbasetrainsg**; point out that this name must be globally unique.
12. In the **Default container** box, replace the suggested name with the name of your cluster (for example, **\<*your name*\>hbasetrain**).
13. Leave all other settings at their defaults, and then click **Next**.
14. On the **Applications (optional)** blade, click **Next**.
15. On the **Cluster size** blade, in the **Number of Region nodes** box, type **2**.
16. Click **Region node size**.
17. On the **Choose your node size** blade, click **View all**, click **D3 V2 Optimized**, and then click **Select**.
18. Click **Head node size**.
19. On the **Choose your node size** blade, click **View all**, click **D3 V2 Optimized**, and then click **Select**.
20. Click **Zookeeper node sizes**.
21. On the **Choose your node size** blade, click **View all**, click **A4 V2 Standard**, and then click **Select**.
22. On the **Cluster size** blade, click **Next**.
23. On the **Script Actions (optional)** blade, click **Next**.
24. On the **Cluster summary** blade, point out the estimated cost per hour of this cluster. Remind students that, to avoid using up their Azure Pass allowance, it is important that they remove clusters when they are not using them.
25. On the **Cluster summary** blade, click **Create**.
26. Wait for the cluster to be provisioned before proceeding with the demonstration. This may take 15â€“20 minutes.
27. Click **All resources**, click **\<*your name*\>hbasetrain**, and then show the status as **Running**.


### Ingest data into Phoenix
1.  Click **Start**, type **Microsoft Azure Storage Explorer**, and then press Enter.
2.  If the **Connect to Azure Storage** dialog box appears, click **Add an Azure Account**, and then click **Sign in**.
3.  In the **Sign in to your account** dialog box, enter your Azure credentials, and then click **Sign in**.
4.  In Microsoft Azure Storage Explorer, under **Storage Accounts**, expand **\<*your name*\>hbasetrainsg**, expand **Blob Containers**, and then click **\<*your name*\>hbasetrain**.
5.  In the top menu, click **Upload**, and then click **Upload Folder**.
6.  In the **Upload folder** dialog box, click the ellipsis (**â€¦**).
7.  In the **Select folder to upload** dialog box, navigate to **E:\\Demofiles\\Mod09**, click the **Demo03** folder, and then click **Select Folder**.
8.  In the **Upload folder** dialog box, click **Upload**.
9.  Click **Start**, type **Putty**, and then press Enter.
10. In the **PuTTY Configuration** dialog box, in the **Host Name (or IP address)** box, type **sshuser@\<clustername\>-ssh.azurehdinsight.net**, and then click **Open**. Replace **\<clustername\>** with your cluster name.
11. If the **PuTTY Security Alert** dialog box appears, click **Yes**.
12. At the command prompt, type **Pa55w.rdPa55w.rd**, and then press Enter.
13. At the command prompt, type the following command, and then press Enter to install **jq** (json parser):
    ````
    sudo apt install jq
    ````
14. At the command prompt, type **y**, and then press Enter.
15. At the command prompt, type the following command, and then press Enter to install the dos2unix package:
    ````
    sudo apt install dos2unix
    ````
16. At the command prompt, type the following command, and then press Enter to copy the demo folder contents from HDFS to the local file system on the head node of the cluster:
    ````
    mkdir Demo03;hdfs dfs -copyToLocal /Demo03/*.* $HOME/Demo03
    ````
17. At the command prompt, type the following command, and then press Enter to copy the **uk_cities_population.csv** from the demo folder to the HDFS location at **/example/data**:
    ````
    hdfs dfs -copyFromLocal $HOME/Demo03/uk_cities_population.csv /example/data/
    ````
18. At the command prompt, type the following command, and then press Enter to convert the files into unix format:
    ````
    dos2unix $HOME/Demo03/*.*
    ````
19. At the command prompt, type the following command, and then press Enter to review the **first_phoenix_query.sql** file by opening the file:
    ````
    cat $HOME/Demo03/first_phoenix_query.sql
    ````
    >**Note**: Normally HBase cluster has three zookeeper nodes, and you need one of these nodes to be running every time you connect to Phoenix.
20. At the command prompt, type the following curl command, and then press Enter to get one of the zookeeper names. Replacing **\<CLUSTERNAME\>** with your clustername.
    ````
    curl -u admin:Pa55w.rdPa55w.rd -sS -G "https://<CLUSTERNAME>.azurehdinsight.net/api/v1/clusters/<CLUSTERNAME>/services/ZOOKEEPER/components/ZOOKEEPER_SERVER" | jq '.host_components[].HostRoles.host_name' | head -1 | sed "s/\"//g"
    ````
    >**Note**: You need **ZOOKEEPER_NAME** in the following steps and throughout this demo.

21. At the command prompt, type the following command, and then press Enter to get the Horton Works Data Platform version (**HDP_VERSION**):
    ````
    /usr/bin/hdp-select status|grep phoenix|head -1|cut -d " " -f3
    ````
    >**Note**: You need **HDP_VERSION** in the following step and throughout this demo.

22. At the command prompt, type the following command, and then press Enter to load into the **REGION** table and to view the records. Replacing **\<HDP_VERSION\>** with the **HDP_VERSION** you obtained in step 21, and  **\<ZOOKEEPER_NAME\>** with the zookeeper name you obtained in Step 20.
    ````
    python /usr/hdp/<HDP_VERSION>/phoenix/bin/psql.py <ZOOKEEPER_NAME>:2181:/hbase-unsecure $HOME/Demo03/first_phoenix_query.sql
    ````

23. At the command prompt, type the following command, and then press Enter to create **UK_CITIES_POPULATION** and **UK_CITIES_POPULATION_MR** tables in Phoenix. Replacing **\<HDP_VERSION\>** with the **HDP_VERSION** you obtained in step 21, and  **\<ZOOKEEPER_NAME\>** with the zookeeper name you obtained in Step 20.
    ````
    python /usr/hdp/<HDP_VERSION>/phoenix/bin/psql.py <ZOOKEEPER_NAME>:2181:/hbase-unsecure $HOME//Demo03/create_uk_cities_population.sql
    ````

24. At the command prompt, type the following command, and then press Enter to load into the **UK_CITIES_POPULATION** table in single-threaded mode. Replacing **\<HDP_VERSION\>** with the **HDP_VERSION** you obtained in step 21, and  **\<ZOOKEEPER_NAME\>** with the zookeeper name you obtained in Step 20.
    ````
    python /usr/hdp/<HDP_VERSION>/phoenix/bin/psql.py -t UK_CITIES_POPULATION <ZOOKEEPER_NAME>:2181:/hbase-unsecure $HOME/Demo03/uk_cities_population.csv
    ````

25. At the command prompt, type the following commands, and then press Enter to find the client jar version. Replacing **\<HDP_VERSION\>** with the **HDP_VERSION** you obtained in step 21.
    ````
    cd /usr/hdp/<HDP_VERSION>/phoenix
    ls -lrt phoenix*client.jar
    ````

    >**Note**: Make a note of the version you see for the **phoenix-client.jar**.

26. At the command prompt, type the following command, and then press Enter to load into **UK_CITIES_POPULATION_MR** table in map reduce mode, Replacing **\<HDP_VERSION\>** with the **HDP_VERSION** you obtained in step 21, and **\<PHOENIX_CLIENT_JAR_VERSION\>** obtained in Step 25.
    ````
    HADOOP_CLASSPATH=/usr/hdp/<HDP_VERSION>/hbase/lib/hbase-protocol.jar:/usr/hdp/<HDP_VERSION>/hbase/conf hadoop jar /usr/hdp/<HDP_VERSION>/phoenix/phoenix-<PHOENIX_CLIENT_JAR_VERSION>-client.jar org.apache.phoenix.mapreduce.CsvBulkLoadTool --table UK_CITIES_POPULATION_MR --input /example/data/uk_cities_population.csv
    ````
    
27. At the command prompt, type the following command, and then press Enter to verify the data loads. Replacing **\<HDP_VERSION\>** with the **HDP_VERSION** you obtained in step 21, and  **\<ZOOKEEPER_NAME\>** with the zookeeper name you obtained in Step 20.
    ````
    python /usr/hdp/<HDP_VERSION>/phoenix/bin/psql.py <ZOOKEEPER_NAME>:2181:/hbase-unsecure $HOME/Demo03/verify_bulk_ingests.sql
    ````

### Perform interactive queries

1.  At the command prompt, type the following command, and then press Enter to review the queries in the **query_uk_cities_population_table.sql** file, and then copy the contents to a notepad:
    ````
    cat $HOME/Demo03/query_uk_cities_population_table.sql
    ````
2.  At the command prompt, type the following command, and then press Enter to launch SQLLine Console. Replacing **\<HDP_VERSION\>** and **\<ZOOKEEPER_NAME\>** from the previous task.
    ````
    python /usr/hdp/<HDP_VERSION>/phoenix/bin/sqlline.py <ZOOKEEPER_NAME>:2181:/hbase-unsecure
    ````
        
3.  At the command prompt, type the following commands, and then press Enter to count the number of rows in the **UK_CITIES_POPULATION** table in Step1:
    ````
    SELECT COUNT(*) 
    FROM UK_CITIES_POPULATION;
    ````
4.  At the command prompt, type the following commands, and then press Enter to fetch the cities from the **UK_CITIES_POPULATION** table in Step2:
    ````
    SELECT CITYNAME 
    FROM UK_CITIES_POPULATION;
    ````
5.  At the command prompt, type the following commands, and then press Enter to count the number of rows in the **UK_CITIES_POPULATION** table in Step3:
    ````
    SELECT REGIONID, 
        CITYNAME, 
        POPULATION 
    FROM UK_CITIES_POPULATION 
    WHERE CITYNAME='London';
    ````
6.  At the command prompt, type the following commands, and then press Enter to count the number of rows in the **UK_CITIES_POPULATION** table in Step4:
    ````
    SELECT REGIONID, 
        COUNT(*) 
    FROM UK_CITIES_POPULATION 
    GROUP BY REGIONID;
    ````
7.  At the command prompt, type the following commands, and then press Enter to count the number of rows in the **UK_CITIES_POPULATION** table in Step5:
    ````
    SELECT REGIONID, 
        SUM(POPULATION) 
    FROM UK_CITIES_POPULATION 
    WHERE REGIONID=1000001
    GROUP BY REGIONID;
    ````
8.  At the command prompt, type the following commands, and then press Enter to count the number of rows in the **UK_CITIES_POPULATION** table in Step6:
    ````
    SELECT B.REGIONNAME AS "Country", COUNT(A.CITYNAME) AS "City Count", SUM(A.POPULATION) as "Total Population"
    FROM UK_CITIES_POPULATION A
    INNER JOIN
    REGION B
    ON A.REGIONID = B.REGIONID 
    GROUP BY B.REGIONNAME
    ORDER BY SUM(A.POPULATION) DESC;
    ````

>**Note**: This is the final demonstration in this module. Make sure you delete the clusters before you start the next module.

---

Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
