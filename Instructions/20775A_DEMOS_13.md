# Module 13: Create Spark Streaming applications

## Preparation

This demo uses a local Spark cluster, but requires that you install the Scala 2.12.7 runtime (required by the DStream libraries), and configure the local Hadoop environment, as follows:

1.  Ensure that the **MT17B-WS2016-NAT** and **20775A-LON-DEV** virtual machines are running, and then log on to **20775A-LON-DEV** as **Admin** with the password **Pa55w.rd**.
2.  Using File Explorer, create the following folders:
    -  E:\\Demofiles\\Hadoop
    -  E:\\Demofiles\\Hadoop\\bin
    -  E:\\Demofiles\\Checkpoints
3.  In File Explorer, navigate to **E:\\Demofiles\\Mod13**, right-click **Mod13.zip**, and then click **Extract All**.
4.  In the **Extract Compressed (Zipped) Folder** dialog box, clear the **Show extracted files when complete** check box, and then click **Extract**.
4.  Using Internet Explorer, download **winutils.exe** file from **https://github.com/steveloughran/winutils/blob/master/hadoop-2.6.0/bin/winutils.exe**, and save the file in the **E:\Demofiles\Hadoop\bin** folder.
5.  Start Internet Explorer, and browse to **https://www.jetbrains.com/idea/download/index.html#section=windows**.
6.  Under **Community**, click **Download**.
7.  In the message box, click **Run**.
8.  In the **User Account Control** dialog box, click **Yes**.
9.  In the **IntelliJ IDEA Community Edition Setup** wizard, on the **Welcome to the IntelliJ IDEA Community Edition Setup** page, click **Next**.
10. On the **Choose Install Location** page, click **Next**.
11. On the **Installation Options** page, select the **64-bit launcher** check box, and then click **Next**.
12. On the **Choose Start Menu Folder** page, click **Install**.
13. On the **Completing IntelliJ IDEA Community Edition Setup** page, click **Finish**.
14. In Internet Explorer, browse to **https://www.scala-lang.org/download/**.
15. Under **Other resources**, click **scala-2.12.7.msi**.
16. In the message box, click **Run**.
17. In the **Scala Programming Language Distribution Setup** dialog box, on the welcome page, click **Next**.
18. On the **End-User License Agreement** page, click **I accept the terms in the License Agreement**, and then click **Next**.
19. On the **Custom Setup** page, click **Next**.
20. On the **Ready to install Scala Programming Language Distribution** page, click **Install**.
21. In the **User Account Control** dialog box, click **Yes**.
22. On the **Completed the Scala Programming Language Distribution Setup Wizard** page, click **Finish**.
23. Close Internet Explorer.
24. On the desktop, double-click **IntelliJ IDEA Community Edition**.
25. In the **Complete Installation** dialog box, click **Do not import settings**, and then click **OK**.
26. In the **JetBrains Privacy Policy** dialog box, scroll to the end of the text, and then click **Accept**.
27. In the **Data Sharing** dialog box, click **Don't send**.
28. In the **Customize IntelliJ IDEA** wizard, on the **Set UI theme** page, click **Next: Default plugins**.
29. On the **Tune IDEA to your tasks** page, click **Next: Featured plugins**.
30. On the **Download featured plugins** page, in the **Scala** section, click **Install**, and then click **Start using IntelliJ IDEA**.
31. In the **Welcome to IntelliJ IDEA** dialog box, click **Create New Project**.
32. In the left-hand pane, click **Scala**, in the right-hand pane click **IDEA**, and then click **Next**.
33. Under the **JDK** drop-down list box, click **Download JDK**. This action will open a web browser (Microsoft Edge or Internet Explorer).
34. In the **Oracle** dialog box, click **AGREE AND PROCEED**.
35. In the web browser, in the **Java SE Downloads** section, click the **Java Download** image button.
36. In the **Java SE Development Kit** section, click **Accept License Agreement**, and then click the download link for the **Windows x64 EXE** version of the software.
37. In the web browser message box, click **Save**.
38. When the download has completed, in the web browser message box, click **Run**.
39. In the **User Account Control** dialog box, click **Yes**.
40. In the **Java SE Development Kit Setup** wizard, on the welcome page, click **Next**.
41. On the optional features page, click **Next**.
42. When the installation has finished, click **Close**.
43. Close the web browser and return to the **New Project** dialog box in IntelliJ IDEA.
44. In the **New Project** dialog box, next to the **JDK** drop-down list box, click **New**.
45. In the **Select Home Directory for JDK** dialog box, browse to **C:\\Program Files\\Java**, click **jdk-11.0.1**, and then click **OK**.
46. In the **New Project** dialog box, next to the **Scala SDK** drop-down list box, click **Create**.
47. In the **Select JAR's for the new Scala SDK** dialog box, click **OK**.
48. In the **New Project** dialog box, click **Finish**.
49. In the **Windows Security Alert** dialog box for the **OpenJDK Platform binary**, click **Allow access**.
50. In the **Windows Security Alert** dialog box for **IntelliJ IDEA**, click **Allow access**.
51. In the **Tip of the Day** dialog box, clear **Show tips on startup**, and then click **Close**.
52. On the **File** menu, click **Settings**.
53. In the **Settings** dialog box, click **Plugins**.
54. In the **Plugins** pane, clear **Android Support**, and then click **Browse repositories**.
55. In the **Browse Repositories** dialog box, in the search box, type **Azure**.
56. Click **Azure Toolkit for IntelliJ**, and then click **Install**.
57. In the **Third-party Plugins Privacy Note** dialog box, click **Accept**.
58. In the **Browse Repositories** dialog box, click **Close**.
59. In the **Settings** dialog box, click **OK**.
60. In the **IDE and Plugin Updates** dialog box, click **Restart**.
61. On the **File** menu, click **Open**.
62. In the **Open File or Project** dialog box, navigate to the **E:\\Demofiles\\Mod13** folder, click **StockMarketSocketSender**, and then click **OK**.
63. In the **Open Project** dialog box, click **This Window**.
64. If the **Project JDK is not defined** message appears, complete the following steps:
    1.  Click **Setup JDK**.
    2.  In the **Select Project SDK** dialog box, click **11**, and then click **OK**.
65. If the **No Scala SDK in module** message appears, complete the following steps:
    1.  Click **Setup Scala SDK**.
    2.  In the **Add Scala Support** dialog box, ensure **scala-sdk-2.12.7** is selected, and then click **OK**.
66. In the main pane, close any open tabs.
67. On the **File** menu, click **Save All**.
68. On the **File** menu, click **Close Project**.
69. In the **Welcome to IntelliJ IDEA** window, click **Open**.
70. In the **Open File or Project** dialog box, navigate to the **E:\\Demofiles\\Mod13** folder, click  **StockMarketSocketSender**, and then click **OK**.
71. In the **Open Project** dialog box, click **This Window**.
72. If the **Project JDK is not defined** message appears, complete the following steps:
    1.  Click **Setup JDK**.
    2.  In the **Select Project SDK** dialog box, click **11**, and then click **OK**.
73. If the **No Scala SDK in  module** message appears, complete the following steps:
    1.  Click **Setup Scala SDK**.
    2.  In the **Add Scala Support** dialog box, ensure **scala-sdk-2.12.7** is selected, and then click **OK**.
74. In the main pane, close any open tabs.
75. On the **File** menu, click **Save All**.
76. In the **Welcome to IntelliJ IDEA** window, click **Open**.
77. In the **Open File or Project** dialog box, navigate to the **E:\\Demofiles\\Mod13** folder, click  **StockMarketStreamProcessor**, and then click **OK**.
78. In the **Open Project** dialog box, click **This Window**.
79. If the **Project JDK is not defined** message appears, complete the following steps:
    1.  Click **Setup JDK**.
    2.  In the **Select Project SDK** dialog box, click **11**, and then click **OK**.
80. If the **No Scala SDK in  module** message appears, complete the following steps:
    1.  Click **Setup Scala SDK**.
    2.  In the **Add Scala Support** dialog box, ensure **scala-sdk-2.12.7** is selected, and then click **OK**.
81. In the main pane, close any open tabs.
82. On the **File** menu, click **Save All**.
83. Close IntelliJ IDEA.

## Demo 1: Spark Streaming in action 

### Scenario

In this demonstration, you will see an example of a simple Spark Streaming application. The application connects to a TCP port and reads text from it using the **socketTextStream** data source. The data consists of pairs of stock market tickers and prices. The application displays the data as it is received.

### Examine the code for the StockMarketStreamProcessor application
1.  On the desktop, double-click **IntelliJ IDEA Community Edition**.
2.  In the **Welcome to IntelliJ IDEA** window, click **Open**.
3.  In the **Open File or Project** dialog box, navigate to the **E:\\Demofiles\\Mod13** folder, click **StockMarketStreamProcessor**, and then click **OK**.
4.  In IntelliJ IDEA, in the **Project** pane, expand **StockMarketStreamProcessor**, expand **src**, expand **StockMarketStreamProcessor**, and then double-click **StreamProcessor**.
5.  In the editor window, highlight the following code in the main function:
    ```
    // Create a streaming context using the createStreamingContext function
    val streamingContext: StreamingContext = StreamingContext.getOrCreate(checkpointDirectory,
        () => createStreamingContext(inputOptions))

    // Start streaming
    streamingContext.start()

    // Stream until terminated or a few minutes have passed
    streamingContext.awaitTermination(120000)
    ```
    This code constitutes the typical life cycle of a Spark Streaming application; create a streaming context, start streaming, and then wait for streaming to finish.
6.  Highlight the following code in the **createStreamingContext** function:
    ```
    // Create a Spark streaming context
    val config: SparkConf = new SparkConf
    config.setAppName("StockMarket")
    config.set("spark.streaming.driver.writeAheadLog.allowBatching", "true")
    config.set("spark.streaming.driver.writeAheadLog.batchingTimeout", "60000")
    config.set("spark.streaming.receiver.writeAheadLog.enable", "true")
    config.set("spark.streaming.receiver.writeAheadLog.closeFileAfterWrite", "true")
    config.set("spark.streaming.stopGracefullyOnShutdown", "true")
    config.setMaster("local[*]") // change to "spark://host:port to run in a Spark cluster
    val sparkContext: SparkContext = new SparkContext(config)
    ```
    This code configures the Spark environment and indicates on which Spark cluster to run the application (local, in this case).
7.  Highlight the following code:
    ```
    // Configure the Spark streaming context
    val checkpointDir: String = options(Symbol(ClientArgumentKeys.CheckpointDirectory)).asInstanceOf[String]
    val batchDuration = 5 // 5 second batches
    val streamingContext: StreamingContext = new StreamingContext(sparkContext, Seconds(batchDuration))
    streamingContext.checkpoint(checkpointDir)
    ```
    This code creates the Spark streaming context, specifying a batch interval of five seconds, and forcing a checkpoint.
8.  Highlight the following code:
    ```
    // Create a DStream that connects to the stock market sender socket using the basic socketTextStream source
    val sender: String = options(Symbol(ClientArgumentKeys.Sender)).asInstanceOf[String]
    val port: Int = options(Symbol(ClientArgumentKeys.Port)).asInstanceOf[String].toInt
    val stream = streamingContext.socketTextStream(sender, port)
    ```
    This code connects the Spark streaming context to a TCP/IP socket. Another application will post a stream of stock market tickers and prices to this socket.
9.  Highlight the following code:
    ```
    // Define the processing for the stream
    doProcessing(streamingContext, stream)

    // Return the streaming context
    return(streamingContext)
    ```
    This code calls another function named _doProcessing_ to define the Spark streaming operations to perform, before returning the _StreamingContext_ object to the caller.
10. Highlight the following code in the **doProcessing** function:
    ```
    def doProcessing(streamingContext: StreamingContext, stream: DStream[String]): Unit = {

    // Perform a foreachRDD transformation to process the data in the stream
    // Iterate through each item in each partition in each RDD in the stream
    val parsedDdata = stream.foreachRDD {rdd =>
        try
        {
        rdd foreachPartition { part =>
            part foreach {stockMarketEvent =>

            // Split the input data into the ticker and price
            val tickerInfo = stockMarketEvent.split(",")

            // Display the parsed data
            println(s"Ticker: ${tickerInfo(0)}, Price: ${tickerInfo(1)}")
            }
        }
        } catch {
        case ex: Exception => val message: String = ex.getMessage
            println(s"General error processing data: $message\nDiscarding data")
        }
    }
    }
    ```
    This code uses the foreachRDD output function of the stream to step through each RDD in the stream. The code iterates through each partition, and each item in each partition. The data in each item is a (ticker, price) pair received as a string. The code splits the pair into its individual elements and displays them.

### Run the StockMarketStreamProcessor application
1.  On the **File** menu, click **Open**.
2.  In the **Open File or Project** dialog box, click **StockMarketSocketSender**, and then click **OK**.
3.  In the **Open Project** dialog box, click **New Window**.
4.  In the **StockMarketSocketSender** project, on the **Run** menu, click **Run 'StockMarketSocketSender'**.
This application generates stock market prices and sends them to a socket. It will not start to generate prices until the streaming client application runs.
6.  If the **Windows Security Alert** dialog box appears, click **Allow access**.
7.  On the **Window** menu, click **StockMarketStreamProcessor**.
8.  On the **Run** menu, click **Run 'StockMarketStreamingProcessor'**.
After a few seconds, the console window for the **StockMarketStreamProcessor** application should display a couple of informational messages indicating that it is connecting to the socket.
On the **Window** menu, click **StockMarketSocketSender**. The **StockMarketSocketSender** application should start generating data. The tickers and prices will be received and displayed by the StockMarketStreamProcessor application. 
9.  Allow both applications to run for a couple of minutes, and then stop them both.
10. Close both IntelliJ IDEA windows.

## Demo 2: Working with Structured Streaming

### Scenario

In this demonstration, you will see an example of a Structured Streaming application. This application performs a streaming analysis of stock market data, generating a running count of the number of times each stock market item has a price change.

### Preparation

The instructions in this demonstration assume that you have configured IntelliJ IDEA with the Scala SDK version 2.12.7, and that you have installed the local Hadoop runtime on your virtual machine. If you have not performed these tasks, follow the Preparation instructions listed at the start of this document.

### Examine the code for the StructuredStreamReceiver application
1.  On the desktop, double-click **IntelliJ IDEA Community Edition**.
2.  On the **File** menu, click **Open**.
3.  In the **Open File or Project** dialog box, navigate to the **E:\\Demofiles\\Mod13** folder, click  **StructuredStreamReceiver**, and then click **OK**.
4.  In the **Open Project** dialog box, click **This Window**.
5.  In the **Project** pane, expand  **StructuredStreamReceiver**, expand **src**, expand **StructuredStreamReceiver**, and then double-click **Receiver**.
6.  In the editor window, highlight the following code in the **main** function:
    ```
    // Create a Spark session
    val config: SparkConf = new SparkConf
    config.setAppName("StockMarket")
    config.set("spark.streaming.driver.writeAheadLog.allowBatching", "true")
    config.set("spark.streaming.driver.writeAheadLog.batchingTimeout", "60000")
    config.set("spark.streaming.receiver.writeAheadLog.enable", "true")
    config.set("spark.streaming.receiver.writeAheadLog.closeFileAfterWrite", "true")
    config.set("spark.streaming.stopGracefullyOnShutdown", "true")
    config.setMaster("local[*]") // change to "spark://host:port to run in a Spark cluster

    val spark: SparkSession = SparkSession.builder.config(config).getOrCreate()
    ```
    This code creates and configures a _SparkSession_. It is very similar to the code used by a _DStreams_ application.
7.  Highlight the following code:
    ```
    // Create a DataFrame for the input stream containing the stock market events
    val stockMarketEvent = spark.readStream.format("socket").option("host", sender).option("port", port).load()
    ```
    This code connects to the socket specified by the sender and host parameters, and then reads each batch of data as it arrives into a _DataFrame_.
8.  Highlight the following code:
    ```
    // Extract the ticker from each row in the DataFrame
    import spark.implicits._
    val tickers = stockMarketEvent.as[String].map(_.split(",")(0)).toDF("Ticker")
    ```
    This code parses the data in each row in the _DataFrame_ (each row consists of a string in the format "\<ticker\>, \<price\>"). The ticker values are extracted and written to a new _DataFrame_ containing a single column named "Ticker".
9.  Highlight the following code:
    ```
    // Count how many times each ticker occurs in the DataFrame
    val tickerCounts = tickers.groupBy("Ticker").count
    ```
    This code groups the data in the _DataFrame_ by Ticker, and then counts the number of times each distinct Ticker value occurs. The result is a new _DataFrame_ containing Ticker/Count pairs.
10. Highlight the following code:
    ```
    // Display the tickers and counts
    val output = tickerCounts.writeStream.outputMode("complete").format("console").start()
    ```
    This code uses the _writeStream_ output function to display the results. The start function causes stream processing to begin.
11. Highlight the following code:
    ```
    output.awaitTermination()
    ```
    This statement blocks the application from finishing until the output stream is terminated. Stream processing will continue all the time the output stream is open.

### Run the StructuredStreamReceiver application
1.  On the **File** menu, click **Open**. 
2.  In the **Open File or Project** dialog box, navigate to the **E:\\Demofiles\\Mod13** folder, click  **StockMarketSocketSender**, and then click **OK**.
3.  In the **Open Project** dialog box, click **New Window**.
4.  On the **Window** menu, click **StockMarketSocketSender**.
5.  On the **Run** menu, click **Run 'StockMarketSocketSender'**. This is the same application used by the previous demonstration; it generates stock market prices and sends them to a socket.
6.  On the **Window** menu, click **StructuredStreamReceiver**.
7.  On the **Run** menu, click **Run 'StructuredStreamReceiver'**. After a few seconds, the console window for the **StructuredStreamReceiver** application should display a couple of informational messages indicating that it is connecting to the socket.
8.  On the **Window** menu, click **StockMarketSocketSender**. The **StockMarketSocketSender** application should start generating data. 
9.  On the **Window** menu, click **StructuredStreamReceiver**. The data will be received, and the counts of the number of times each ticker occurs will displayed by the StructuredStreamReceiver application. Note that the counts are cumulative; this is because a DataFrame is essentially an ever-updating table that aggregates and stores data as it is processed.
10. Allow both applications to run for a couple of minutes and then stop them both.
11. Close both IntelliJ IDEA windows.

---

Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
