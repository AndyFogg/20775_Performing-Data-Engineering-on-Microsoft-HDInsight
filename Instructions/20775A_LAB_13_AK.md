# Module 13: Create Spark Streaming applications

## Lab: Building a Spark Streaming application

### Exercise 1: Installing required software

#### Task 1: Install IntelliJ IDEA Community edition

> **Note**: If you already have all these components installed in the 20775A-LON-DEV virtual machine, you can skip this exercise.

1.  Ensure that the **MT17B-WS2016-NAT**, and **20775A-LON-DEV** virtual machines are running, and then log on to **20775A-LON-DEV** as **Admin** with the password **Pa55w.rd**.

2.  Start Internet Explorer, and browse to **https://www.jetbrains.com/idea/download/index.html#section=windows**.

3.  Under **Community**, click **Download**.

4.  In the message box, click **Run**.

5.  If the **User Account Control** dialog box appears, click **Yes**.

6.  In the **IntelliJ IDEA Community Edition Setup** wizard, on the **Welcome to the IntelliJ IDEA Community Edition Setup** page, click **Next**.

7.  On the **Choose Install Location** page, click **Next**.

8.  On the **Installation Options** page, select the **64-bit launcher** check box, and then click **Next**.

9.  On the **Choose Start Menu Folder** page, click **Install**.

10. On the **Completing IntelliJ IDEA Community Edition Setup** page, click **Finish**.

11. In Internet Explorer, browse to **https://www.scala-lang.org/download/**.

12. Under **Other resources**, click **scala-2.12.7.msi**.

13. In the message box, click **Run**.

14. In the **Scala Programming Language Distribution Setup** dialog box, on the welcome page, click **Next**.

15. On the **End-User License Agreement** page, click **I accept the terms in the License Agreement**, and then click **Next**.

16. On the **Custom Setup** page, click **Next**.

17. On the **Ready to install Scala Programming Language Distribution** page, click **Install**.

18. In the **User Account Control** dialog box, click **Yes**.

19. On the **Completed the Scala Programming Language Distribution Setup Wizard** page, click **Finish**.

20. Close Internet Explorer.

21. On the desktop, double-click **IntelliJ IDEA Community Edition**.

22. In the **Complete Installation** dialog box, click **Do not import settings**, and then click **OK**.

23. In the **JetBrains Privacy Policy** dialog box, scroll to the end of the text, and then click **Accept**.

24. In the **Data Sharing** dialog box, click **Don't send**.

25. In the **Customize IntelliJ IDEA** wizard, on the **Set UI theme** page, click **Next: Default plugins**.

26. On the **Tune IDEA to your tasks** page, click **Next: Featured plugins**.

27. On the **Download featured plugins** page, in the **Scala** section, click **Install**, and then click **Start using IntelliJ IDEA**.

#### Task 2: Configure IntelliJ IDEA

1.  In the **Welcome to IntelliJ IDEA** dialog box, click **Create New Project**.

2.  In the left-hand pane, click **Scala**, in the right-hand pane click **IDEA**, and then click **Next**.

3.  Under the **JDK** drop-down list box, click **Download JDK**. This action will open a web browser (Microsoft Edge or Internet Explorer).

4.  In the **Oracle** dialog box, click **AGREE AND PROCEED**.

5.  In the web browser, in the **Java SE Downloads** section, click the **Java Download** image button.

6.  In the **Java SE Development Kit** section, click **Accept License Agreement**, and then click the download link for the **Windows x64 EXE** version of the software.

7.  In the web browser message box, click **Save**.

8.  When the download has completed, in the web browser message box, click **Run**.

9.  If the **User Account Control** dialog box appears, click **Yes**.

10. In the **Java SE Development Kit Setup** wizard, on the welcome page, click **Next**.

11. On the optional features page, click **Next**.

12. When the installation has finished, click **Close**.

13. Close the web browser and return to the **New Project** dialog box in IntelliJ IDEA.

14. In the **New Project** dialog box, next to the **JDK** drop-down list box, click **New**.

15. In the **Select Home Directory for JDK** dialog box, browse to **C:\\Program Files\\Java**, click **jdk-11**, and then click **OK**.

16. In the **New Project** dialog box, next to the **Scala SDK** drop-down list box, click **Create**.

17. In the **Select JAR's for the new Scala SDK** dialog box, click **OK**.

18. In the **New Project** dialog box, click **Finish**.

19. In the **Windows Security Alert** dialog box for the **OpenJDK Platform binary**, click **Allow access**.

20. In the **Windows Security Alert** dialog box for **IntelliJ IDEA**, click **Allow access**.

21. In the **Tip of the Day** dialog box, clear **Show tips on startup**, and then click **Close**.
22. On the **File** menu, click **Settings**.

23. In the **Settings** dialog box, click **Plugins**.

24. In the **Plugins** pane, clear **Android Support**, and then click **Browse repositories**.

25. In the **Browse Repositories** dialog box, in the search box, type **Azure**.

26. Click **Azure Toolkit for IntelliJ**, and then click **Install**.

27. In the **Third-party Plugins Privacy Note** dialog box, click **Accept**.

28. In the **Browse Repositories** dialog box, click **Close**.

29. In the **Settings** dialog box, click **OK**.

30. In the **IDE and Plugin Updates** dialog box, click **Postpone**.

31. Close IntelliJ IDEA.

32. In the **Confirm Exit** dialog box, click **Exit**.

#### Task 3: Install PuTTY (if not already installed)

1.  In a web browser, navigate to **http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html**.

2.  Download the **putty.exe** file, saving it to a suitable folder on your local file system, such as C:\\putty.

3.  Optionally, create a shortcut to the putty.exe file on your desktop for convenience.

**Results**: At the end of this exercise, you will have a Windows client with IntelliJ IDEA Community Edition, the Java SE Development Kit, the Scala SDK, and the PuTTY tool installed for use later in the lab.

### Exercise 2: Creating the data sources and destinations for the Spark application

#### Task 1: Create an Event Hubs namespace

> **Note**: This lab uses the same event hub and Power BI dashboard used by the lab for Module 12. If you have already created these components, you can skip those tasks.

1.  In the 20775A-LON-DEV virtual machine, on the Start menu, type **Internet Explorer**, and then press Enter.

2.  In Microsoft Internet Explorer®, navigate to **https://portal.azure.com**, and then sign in using the Microsoft account that is associated with your Azure Pass subscription.

3.  In the Azure Portal, click **+ Create a resource**, click **Internet of Things**, and then click **Event Hubs**.

4.  On the **Create namespace** blade, enter the following information, and then click **Create**:

    -   **Name**: \<*your name\>\<date*\>ehn (must be unique)

    -   **Pricing tier**: Basic

    -   **Subscription**: your subscription

    -   **Resource group (Create new)**: StormRG

    -   **Location**: West US

    -   **Throughput Units**: 1

#### Task 2: Create an event hub

1.  When the namespace deployment has completed, in the Azure Portal, in the navigation on the left, click **All resources**, and then click **\<*your name\>\<date*\>ehn**.

2.  On the **Event Hub** blade, click **+ Event Hub**.

3.  On the **Create Event Hub** blade, enter the following information, and then click **Create**:

    -   **Name**: TaxiEventSource

    -   **Partition Count**: 2

#### Task 3: Record the Shared Access primary key

1.  On the **\<*your name\>\<date*\>ehn** blade, click **Shared access policies**.

2.  In the list of policies, click **RootManageSharedAccessKey**.

3.  To the right of the **Primary Key** text box, click **Click to copy**.

4.  On the Start menu, type **notepad**, and then press Enter.

5.  On the **Edit** menu, click **Paste**.

6.  On the **File** menu, click **Save As**.

7.  In the **Save As** dialog, browse to **E:\\Labfiles\\Lab13**.

8.  In the **File name** box, type **EventHubKey.txt**, and then click **Save**.

9.  Leave Notepad open while you continue the next exercise.

#### Task 4: Configure a Shared Access policy for listeners

1.  In the Azure Portal, on the **Shared access policies** blade, click **+ Add**.

2.  On the **Add SAS Policy** blade, in the **Policy name** box, type **ListenRule**.

3.  Select the **Listen** check box, leave all the other check boxes cleared, and then click **Create**.

4.  On the **Shared access policies** blade, click **ListenRule**.

5.  On the **SAS Policy: ListenRule** blade, to the right of the **Primary key** box, click **Click to copy**.

6.  In Notepad, in the **EventHubKey.txt** file, at the end of the existing text, press Enter.

7.  On the **Edit** menu, click **Paste**.

8.  On the **File** menu, click **Save**.

9.  Leave Notepad open.

#### Task 5: Create a Power BI streaming dataset

1.  In Internet Explorer, open a new tab, and then browse to **http://www.powerbi.com**.

2.  Click **Sign in**, and sign in using your Power BI credentials.

3.  Close the **GetData** dialog box.

4.  In the left menu, click **My Workspace**, click **+ Create**, and click **Streaming dataset**.

5.  On the **New streaming dataset** blade, click **API**, and click **Next**.

6.  On the **New streaming dataset** blade, enter the following details, and then click **Create**:

    -   **Dataset name**: Taxi Data

    -   **Values from stream**:

        -   **Passengers**: Number

        -   **Distance**: Number

        -   **Fares**: Number

        -   **Tips**: Number

        -   **AvgPassengers**: Number

        -   **AvgDistance**: Number

        -   **AvgFare**: Number

        -   **AvgTip**: Number

7.  On the **Streaming dataset created** blade, select the **Push URL** value, and then press Ctrl+C.

8.  On the Start menu, type **notepad**, and then press Enter.

9.  In Notepad, press Ctrl+V.

10. On the **File** menu, click **Save**.

11. In the **Save As** dialog, browse to **E:\\Labfiles\\Lab13**.

12. In the **File name** box, type **PowerBIPushURL.txt**, and then click **Save**.

13. Leave Notepad open while you complete the next exercises.

14. Switch back to Internet Explorer, and then click **Done**.

#### Task 6: Create a Power BI dashboard

1.  In Internet Explorer, on the **Power BI** page, click **Dashboards**.

2.  Click **+ Create**, and click **Dashboard**.

3.  In the **Create Dashboard** dialog box, in the **Dashboard name** box, type **Taxi Data**, and then click **Create**.

4.  Click **+ Add** **tile**.

5.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and click **Next**.

6.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

7.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

8.  In the **Fields** section, click **Add value**.

9.  In the **Fields** list, click **Passengers**, and then click **Next**.

10.  On the **Tile details** blade, in the **Title** box, type **Number of Passengers**, and then click **Apply**.

11.  Click **+ Add** **tile**.

12.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and then click **Next**.

13.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

14.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

15.  In the **Fields** section, click **Add value**.

16.  In the **Fields** list, click **Distance**, and then click **Next**.

17.  On the **Tile details** blade, in the **Title** box, type **Distance**, and click **Apply**.

18.  Click **+ Add** **tile**.

19.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and then click **Next**.

20.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

21.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

22.  In the **Fields** section, click **Add value**.

23.  In the **Fields** list, click **Fares**, and then click **Next**.

24.  On the **Tile details** blade, in the **Title** box, type **Fares**, and then click **Apply**.

25.  Click **+ Add** **tile**.

26.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and then click **Next**.

27.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

28.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

29.  In the **Fields** section, click **Add value**.

30.  In the **Fields** list, click **Tips**, and then click **Next**.

31.  On the **Tile details** blade, in the **Title** box, type **Tips**, and then click **Apply**.

32.  Click **+ Add** **tile**.

33.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and then click **Next**.

34.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

35.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

36.  In the **Fields** section, click **Add value**.

37.  In the **Fields** list, click **AvgPassengers**, and then click **Next**.

38.  On the **Tile details** blade, in the **Title** box, type **Average Passengers**, and then click **Apply**.

39.  Click **+ Add** **tile**.

40.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and then click **Next**.

41.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

42.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

43.  In the **Fields** section, click **Add value**.

44.  In the **Fields** list, click **AvgDistance**, and then click **Next**.

45.  On the **Tile details** blade, in the **Title** box, type **Average Distance**, and then click **Apply**.

46.  Click **+ Add** **tile**.

47.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and then click **Next**.

48.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

49.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

50.  In the **Fields** section, click **Add value**.

51.  In the **Fields** list, click **AvgFare**, and then click **Next**.

52.  On the **Tile details** blade, in the **Title** box, type **Average Fare**, and then click **Apply**.

53.  Click **+ Add** **tile**.

54.  On the **Add tile** blade, click **CUSTOM STREAMING DATA**, and then click **Next**.

55.  On the **Add a custom streaming data tile** blade, click **Taxi Data**, and then click **Next**.

56.  On the **Add a custom streaming data tile** blade, in the **Visualization Type** list, click **Card**.

57.  In the **Fields** section, click **Add value**.

58.  In the **Fields** list, click **AvgTip**, and then click **Next**.

59.  On the **Tile details** blade, in the **Title** box, type **Average Tip**, and then click **Apply**.

60.  Leave this page open in Internet Explorer.

**Results**: At the end of this exercise, you will have created an event hub that will act as a data source for the Spark Streaming application,and a Power BI dashboard that will display the results of the stream processing.

### Exercise 3: Building a Spark Streaming application

#### Task 1: Set up the infrastructure required to run a local Spark cluster

1.  Using File Explorer, create a new folder named **E:\\Labfiles\\Lab13\\Hadoop\\bin**.

2.  Create another folder named **E:\\Labfiles\\Lab13\\Checkpoints**.

3.  Create a further folder named **E:\\Labfiles\\Lab13\\Progress**.

4.  In Internet Explorer, navigate to **https://github.com/steveloughran/winutils/blob/master/hadoop-2.6.0/bin/winutils.exe**.

5.  Click **Download**.

6.  In the Internet Explorer message bar, click the drop-down arrow on the **Save** button, click **Save as**, and save the file to the **E:\\Labfiles\\Lab13\\Hadoop\\bin** folder.

#### Task 2: Configure streaming in a Spark application

1.  On the desktop, double-click **IntelliJ IDEA Community Edition**.

2.  If the **Tip of the Day** dialog appears, click **Close**.

3.  On the **File** menu, click **Open**.

4.  In the **Open File or Project** dialog box, browse to **E:\\Labfiles\\Lab13\\Starter\\SparkProcessor - Exercise 3** folder, and then click **OK**.

5.  In the **Open Project** dialog box, click **This Window**.

6.  If the **Project JDK is not defined** message appears, complete the following steps:
    1.  Click **Setup JDK**.
    2.  In the **Select Project SDK** dialog box, click **OK**.

7.  If the **No Scala SDK in module** message appears, complete the following steps:
    1.  Click **Setup Scala SDK**.
    2.  In the **Add Scala Support** dialog box, click **OK**.

8.  If the **Project** window is not visible, on the **View** menu, point to **Tool Windows**, and then click **Project**.

9.  In the **Project** window, move to the **SparkProcessor - Exercise 3\\src\\sparkprocessor.main\\scala** folder, and then double-click **SparkDriver**.

10. Locate the comment **// TODO: Create the streaming context and define the processing to be performed**.

11. On the next line, add the following code:
    ````
    val checkpointDirectory = inputOptions(Symbol(ClientArgumentKeys.CheckpointDirectory)).asInstanceOf[String]
    val streamingContext: StreamingContext = StreamingContext.getOrCreate(checkpointDirectory,
    () => createStreamingContext(inputOptions))
    ````

12. Locate the comment **// TODO: Start streaming**.

13. On the next line, add the following code:
    ````
    streamingContext.start()
    ````

14. Locate the comment **// TODO: Stream until terminated or a few minutes have passed**.

15. On the next line, add the following code:
    ````
    streamingContext.awaitTerminationOrTimeout(120000)
    ````

#### Task 3: Set up the streaming context

1.  Locate the comment **// TODO: Create a Spark streaming context**.

2.  On the next line, add the following code:
    ````
    val checkpointDirectory = inputOptions(Symbol(ClientArgumentKeys.CheckpointDirectory)).asInstanceOf[String]
    val config: SparkConf = EventHubsUtils.initializeSparkStreamingConfigurations
    config.setAppName(options(Symbol(ClientArgumentKeys.AppName)).asInstanceOf[String])
    config.set("spark.streaming.driver.writeAheadLog.allowBatching", "true")
    config.set("spark.streaming.driver.writeAheadLog.batchingTimeout", "60000")
    config.set("spark.streaming.receiver.writeAheadLog.enable", "true")
    config.set("spark.streaming.receiver.writeAheadLog.closeFileAfterWrite", "true")
    config.set("spark.streaming.stopGracefullyOnShutdown", "true")
    config.setMaster("local[*]") // change to "spark://host:port to run in a Spark cluster
    val sparkContext: SparkContext = new SparkContext(config)
    ````

3.  Locate the comment **// TODO: Configure the Spark streaming context**.

4.  On the next line, add the following code:
    ````
    val checkpointDir: String = options(Symbol(ClientArgumentKeys.CheckpointDirectory)).asInstanceOf[String]
    val batchDuration = options(Symbol(ClientArgumentKeys.BatchDuration)).asInstanceOf[Int]
    val streamingContext: StreamingContext = new StreamingContext(sparkContext, Seconds(batchDuration))
    streamingContext.checkpoint(checkpointDir)
    ````

5.  Locate the comment **// TODO: Configure the Event Hub parameters for the streaming data source**.

6.  On the next line, add the following code:
    ````
    val namespace: String = options(Symbol(ClientArgumentKeys.EventhubsNamespace)).asInstanceOf[String]
    val name: String = options(Symbol(ClientArgumentKeys.EventhubsName)).asInstanceOf[String]
    val progressDir: String = options(Symbol(ClientArgumentKeys.EventHubsProgressDirectory)).asInstanceOf[String]
    val eventHubsParams = Map[String, String] (
    "eventhubs.namespace" -> namespace,
    "eventhubs.name" -> name,
    "eventhubs.policyname" -> options(Symbol(ClientArgumentKeys.PolicyName)).asInstanceOf[String],
    "eventhubs.policykey" -> options(Symbol(ClientArgumentKeys.PolicyKey)).asInstanceOf[String],
    "eventhubs.consumergroup" -> "$Default",
    "eventhubs.partition.count" -> options(Symbol(ClientArgumentKeys.EventHubsPartitions)).asInstanceOf[Int].toString()
    )
    ````

7.  Locate the comment **// TODO: Create a stream that connects to the Event Hub**.

8.  On the next line, add the following code:
    ````
    val stream = EventHubsUtils.createDirectStreams(streamingContext, namespace, progressDir, Map(name -> eventHubsParams))
    ````

9.  Locate the comment **// TODO: Process the streamed data (parse, persist, and visualize)**.

10. On the next line, add the following code:
    ````
    doProcessing(streamingContext, stream)
    ````

11. Locate the comment **// TODO: Return the streaming context**.

12. On the next line, add the following code:
    ````
    return(streamingContext)
    ````

#### Task 4: Define the stream processing

1.  Locate the comment **// TODO: Use the map transformation to iterate through the RDDs and partitions in the current stream batch**.

2.  After the comment on the next line, add the following code:
    ````
    stream.map(eventData => new String(eventData.getBytes)) foreachRDD { rdd =>
    ````

1.  Locate the comment **// TODO: Store the elements in a Set of Map objects**.

2.  After this comment, add the following block of code:
    ````
        var parsedData: Set[Map[String, String]] = Set.empty
        println(s"*********** rdd is $rdd")
        rdd foreachPartition { part =>
        println(s"*********** part is $part")
        part foreach { item =>
        val mapper: ObjectMapper = new ObjectMapper // Use the ObjectMapper class to parse the record
        val taxiEventData: JsonNode = mapper.readTree(item)
        if (taxiEventData.has("eventData")) { // Only continue with this record if it is an instance of "eventData". Ignore otherwise
        val taxiRecord: JsonNode = taxiEventData.get("eventData")
        var taxiRecordInfo = Map("Pickup" -> taxiRecord.get("pickup").asText,
                "Dropoff" -> taxiRecord.get("dropoff").asText, "Passengers" -> taxiRecord.get("passengers").asText,
                "Distance" -> taxiRecord.get("distance").asText, "PickupLatitude" -> taxiRecord.get("pickupLatitude").asText,
                "PickupLongitude" -> taxiRecord.get("pickupLongitude").asText, "DropoffLatitude" -> taxiRecord.get("dropoffLatitude").asText,
                "DropoffLongitude" -> taxiRecord.get("dropoffLongitude").asText, "PaymentType" -> taxiRecord.get("paymentType").asText,
                "Fare" -> taxiRecord.get("fare").asText, "Extra" -> taxiRecord.get("extra").asText, "TipAmount" -> taxiRecord.get("tipAmount").asText)
        println(s"Parsed data is: ${taxiRecordInfo.toString}")
        parsedData += taxiRecordInfo
        }
        }
        }
    ````

#### Task 5: Specify the command-line arguments for the streaming application

1.  In IntelliJ IDEA, on the **Run** menu, click **Edit Configurations**.

2.  In the **Run/Debug Configurations** dialog box, under **Application**, click **Unnamed**.

3.  Click the edit button next to the **Program arguments** text box.

4.  In the **Program arguments** dialog box, change the program arguments as follows:

    -   **--application-name**: taxi-trips

    -   **--batch-duration**: 5

    -   **--eventhubs-namespace**: \<*your name\>\<date*\>ehn

    -   **--eventhubs-name**: TaxiEventSource

    -   **--policy-name**: ListenRule

    -   **--policy-key**: Copy the primary key value for the **ListenRule** policy from the file currently open in Notepad

    -   **--partition-count**: 1

    -   **--progress-directory**: E:\\Labfiles\\Lab13\\Progress

    -   **--checkpoint-directory**: E:\\Labfiles\\Lab13\\Checkpoints

5.  In the **Run/Debug Configurations** dialog box, in the **Environment variables** box, ensure that the **HADOOP_HOME** listed in the run configuration is set to **E:\\Labfiles\\Lab13\\Hadoop**, and then click **OK**.

#### Task 6: Test the streaming application

1.  On the **File** menu, click **Open**.

2.  In the **Open File or Project** dialog box, navigate to the **E:\\Labfiles\\Lab13\\Starter\\EventHubSender** folder, and then click **OK**.

3.  In the **Open Project** dialog box, click **New Window**.

4.  Switch to the **EventHubSender** project.

5.  On the **Run** menu, click **Edit Configurations**.

6.  In the **Run/Debug Configurations** dialog box, under **Application**, click **EventHubsClientDriver**.

7.  Click the edit button next to the **Program arguments** text box.

8.  In the **Program arguments** dialog box, change the program arguments as follows, and then click **OK**:

    -   **--sourcefilename**: E:\\Labfiles\\Lab13\\yellow_tripdata_2015-01.csv

    -   **--eventhubs-namespace**: \<*your name\>\<date*\>ehn

    -   **--eventhubs-name**: TaxiEventSource

    -   **--policy-name**: RootManageSharedAccessKey

    -   **--policy-key**: Copy the primary key value for the **RootManageSharedAccess** policy from the file currently open in Notepad

9.  On the **File** menu, click **Project Structure**.

10. In the **Project Structure** dialog box, on the **Project** tab, in the **Project SDK** list, click **11 (java version "11")**, and then click **OK**.

11. On the **Run** menu, click **Run** **'EventHubsClientDriver'**.

12. While the application is running, switch to the IntelliJ IDEA window displaying the **SparkProcessor** project.

13. On the **Run** menu, click **Run** **'Unnamed'**.

14. After a few minutes, when you are happy that everything is running correctly, press Ctrl+F2 to stop the application.

15. Switch to the **EventHubsClientDriver** project.

16. Press Ctrl+F2 to stop this application, too.

17. Using File Explorer, move to the **E:\\Labfiles\\Checkpoints** folder. This folder contains files created by the Spark application for checkpointing progress.

**Results**: At the end of this exercise, you will have created and tested a Spark Streaming application.

### Exercise 4: Summarizing and visualizing data in a Spark Streaming application

#### Task 1: Calculate statistics over streamed data

1.  In the IntelliJ IDEA window displaying the SparkProcessing application, on the **File** menu, click **Open**.

2.  In the **Open File or Project** dialog box, navigate to the **E:\\Labfiles\\Lab13\\Starter\\SparkProcessor - Exercise 4** folder, and then click **OK**.

3.  In the **Open Project** dialog box, click **This Window**.

4.  Switch to the **SparkProcessor - Exercise 4** project.

5.  If the **Project** window is not visible, on the **View** menu, point to **Tool Windows**, and then click **Project**.

6.  In the **Project** window, move to the **SparkProcessor - Exercise 4\\src\\sparkprocessor.main\\scala** folder, and then double-click **SparkDriver**.

7.  Locate the comment **// TODO Calculate the stats for Power BI (but only if there is some data in the current batch)**.

8.  On the next line, add the following code:
    ````
    if (!parsedData.isEmpty) {
    val totalPassengers: Int = parsedData.toSeq map { record => record("Passengers").toInt } sum
    val totalDistance: Float = parsedData.toSeq map { record => record("Distance").toFloat } sum
    val totalFares: Float = parsedData.toSeq map { record => record("Fare").toFloat } sum
    val totalTips: Float = parsedData.toSeq map { record => record("TipAmount").toFloat } sum
    val numTrips: Int = parsedData.size
    ````

9.  Locate the comment **// TODO Send the results to the PowerBI dashboard**.

10. On the next line, add the following code:
    ````
    emitStatsToDashboard(StatisticsData(totalPassengers, totalDistance, totalFares, totalTips,
    totalPassengers / numTrips, totalDistance / numTrips, totalFares / numTrips, totalTips / numTrips, numTrips))
    }
    ````

#### Task 2: Test the application

1.  On the **Run** menu, click **Edit Configurations**.

2.  In the **Run/Debug Configurations** dialog box, under **Application**, click **Unnamed**.

3.  Click the edit button next to the **Program arguments** text box.

4.  In the text box, change the program arguments as follows, and then click **OK**:

    -   **--application-name**: taxi-trips

    -   **--batch-duration**: 5

    -   **--eventhubs-namespace**: \<*your name\>\<date*\>ehn

    -   **--eventhubs-name**: TaxiEventSource

    -   **--policy-name**: ListenRule

    -   **--policy-key**: Copy the primary key value for the **ListenRule** policy from the file currently open in Notepad

    -   **--partition-count**: 1

    -   **--progress-directory**: E:\\Labfiles\\Progress

    -   **--checkpoint-directory**: E:\\Labfiles\\Checkpoints

    -   **--dashboard-endpoint**: Copy the URL from the **PowerBIPushURL.txt** that you created earlier

5.  In the **Run/Debug Configurations** dialog box, click **OK**.

6.  Switch to the **EventHubSender** project.

7.  On the **Run** menu, click **Run** **'EventHubsClientDriver'**.

8.  Switch to the **SparkProcessor - Exercise 4** project.

9.  On the **Run** menu, click **Run** **'Unnamed'**.

10. Switch to Internet Explorer and view the page displaying your Power BI dashboard. Verify that the statistics are being updated every few seconds.

#### Task 3: Monitor the Spark cluster

1.  Open another Internet Explorer page and navigate to **http://localhost:4040/streaming/**.

2.  On the **Jobs** page, verify that jobs are running successfully and very few (if any) are failing.

3.  On the **Stages** page, verify that the stages for each job are succeeding.

4.  After a few minutes, when you happy are that everything is running correctly, switch to the IntellJ IDEA window for the **SparkProcessing** project, and then press Ctrl+F2 to stop the application.

5.  Switch to the **EventHubsClientDriver** project.

6.  Press Ctrl+F2 to stop this application.

7.  On the **File** menu, click **Exit**.

8.  In the **Confirm** **Exit** dialog box, click **Exit**.

#### Task 4: Lab clean-up

1.  In the Microsoft Azure Portal, in the left-hand menu, click **Resource groups**.

2.  On the **Resource groups** blade, click your resource group.

3.  On the **Resource groups** blade, click **Delete**.

4.  On the **confirmation** blade, type the name of your resource group, and then click **Delete**.

5.  Wait for your resource group to be deleted, and then click **All resources**.

6.  Verify that the event hub, SQL server, SQL database, and the storage account that were created, have all been removed.

7.  Close Internet Explorer, and any other open windows.

**Results**: At the end of this exercise, you will have modified the application to calculate aggregated statistics over streamed data, and display the results of these calculations using Power BI. You will also see how to monitor a Spark cluster.

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
