# Module 10: Stream Analytics

## Lab: Implement Stream Analytics

### Scenario

You work as a data engineer at Contoso Consulting Services in a division of the company that helps its customers to collect and analyze sensor data, such as temperature and humidity, received from Internet-connected devices installed in offices and residential properties. One of your clients, SmartHomesDevelopers, is planning to deploy such sensors in a newly-built block of flats and wants to understand the capabilities of real-time data collection from the sensors and how this data can be used for real-time data analysis. You decide to build a proof of concept to showcase the capabilities of Stream Analytics and the supporting Azure services.

### Objectives

After completing this lab, you will be able to:

-   Provision an event hub that is connected to an external application that sends real-time data.

-   Provision a Stream Analytics job and configure its input, output and query transformation using temporal window operations on the incoming stream of data.

-   Manage and monitor Stream Analytics job execution using Azure Portal and PowerShell commands.

### Lab Setup

-   **Estimated Time**: 60 minutes

-   **Virtual machine**: 20775A-LON-DEV

-   **Username**: Admin

-   **Password**: Pa55w.rd

## Exercise 1: Process streaming data with Stream Analytics

### Scenario

In this scenario, you will use an application, provided by SmartHomesDevelopers, which simulates real-time sensor data that needs to be consumed and analyzed. As part of the  proof of concept, the customer wants to aggregate humidity sensor data over one-minute time periods, and provide minimum and maximum values for each sensor device.

As a first step, you will create an event hub that can be connected to this application. After that, you will create a Stream Analytics job that will be connected to the event hub, run a specified aggregation over the stream of data, and then output the results into an Azure Storage account in JSON format.

The main tasks for this exercise are as follows:

1. Provision event hub

2. Connect a sensor data application to the event hub

3. Provision a Stream Analytics job

4. Execute a Stream Analytics job using Azure Portal

#### Task 1: Provision event hub

1.  On the **20775A-LON-DEV** virtual machine, open the Azure Portal and create an Azure Event Hub with the following settings:

    -   **Name**: ehlab-\<*your name's initials*\>-20775A

    -   **Pricing tier**: Standard

    -   **Subscription**: Your Azure Learning Pass subscription

    -   **Resource group (Create new)**: module10labrg

    -   **Location**: Select location closest to you

    -   **Name**: EventHubLab

    -   **Partition Count**: 2

    -   **Message Retention**: 1

    -   **Capture**: Off

2.  Access Event Hub **ehlab-\<your name's initials\>-20775A** and copy to the clipboard a primary key for Event Hub's Shared access policy named **RootManageSharedAccessKey**. After that create a text file using Notepad application and paste the key from the clipboard. Do not close the text file.

#### Task 2: Connect a sensor data application to the event hub

1.  Run a console application available at **E:\\Labfiles\\Lab10\\ContosoSensorData\\ContosoSensorData.exe**.

2.  When prompted, provide the following values:

    -   **Event Hub's Namespace**: ehlab-\<*your name's initials*\>-20775A

    -   **Event Hub's Name**: eventhublab

    -   **Shared Access Key**: \<paste the value copied to the clipboard in the previous task\>

    -   Press **2** to generate a continuous stream of data.

3.  Leave the application running for the rest of the lab. The selected event hub will be receiving messages from simulated sensors every 5 seconds.

#### Task 3: Provision a Stream Analytics job

1.  Create a Stream Analytics job with following details:

    -   **Job name**: joblab-\<*your name's initials*\>-20775A

    -   **Subscription**: Your Azure Learning Pass subscription

    -   **Resource group (Use existing)**: module10labrg

    -   **Location**: Leave default location selected for your resource group

2.  Create a Stream Analytics Input with the following details:

    -   **Input alias**: LabInput

    -   **Provide Event Hub settings manually**: Selected

    -   **Service bus namespace**: sb://ehlab-\<*your name's initials*\>-20775A.servicebus.windows.net

    -   **Event Hub name**: eventhublab

    -   **Event Hub policy name**: RootManageSharedAccessKey

    -   **Event Hub policy key**: \<paste the value copied to the clipboard in the task 1\>

3.  Create a Storage account - blob, file, table, queue with the following details:

    -   **Resource group**: module10labrg

    -   **Storage account**: \<*your name's initials*\>mod10labst

    -   **Replication**: Locally-redundant storage (LRS)

4.  Create a Stream Analytics Output with the following details:

    -   **Output alias**: LabOutput

    -   **Select Blob storage from your subscriptions**: Selected

    -   **Storage account**: \<*your name's initials*\>mod10labst

    -   **Container (Create new)**: laboutput

5.  Create a Stream Analytics Query:

    -   Open the file available at **E:\\Labfiles\\Lab10\\JobQuery.txt**, and use the query to create a Stream Analytics Query:
        ````
        Select
            dspl,
            min(hmdt) as min_hmdt,
            max(hmdt) as max_hmdt
        INTO LabOutput
        FROM LabInput
        GROUP BY dspl, 
        TUMBLINGWINDOW(mi, 1)
        ````

#### Task 4: Execute a Stream Analytics job using Azure Portal

1.  Start a Stream Analytics Job with Start time being 1 hour earlier than the current time.

2.  Observe the job status changing from **Starting** to **Running**.

**Results**: At the end of this exercise, you will have deployed and configured a Stream Analytics job that can process, and transform a stream of real-time sensor data.

## Exercise 2: Managing Stream Analytics jobs

### Scenario

In this scenario, you will need to demonstrate how a Stream Analytics job can be managed and monitored using Azure Portal or PowerShell cmdlets.

The main tasks for this exercise are as follows:

1. Monitor a running Stream Analytics job using Azure Portal

2. Manage a Stream Analytics job using PowerShell commands

3. Remove all Azure resources

#### Task 1: Monitor a running Stream Analytics job using Azure Portal

1.  Observe execution of the Stream Analytics Job and monitor a chart that displays Input and Output Events.

2.  Modify this chart to a custom time period that only includes the latest 30 minutes.

#### Task 2: Manage a Stream Analytics job using PowerShell commands

1.  Get Azure Stream Analytics job information using PowerShell cmdlet:
    ````
    Get-AzureRmStreamAnalyticsJob -ResourceGroupName rgModule10Lab -Name joblab-<your name's initials>-20775A
    ````

2.  Observe various job properties, including **CreatedDate**, **JobState,** and **Properties** value with a JSON document that describes the job.

3.  Ensure that **JobState** is **Running** before running the next command below.

4.  Stop the job execution using PowerShell cmdlet:
    ````
    Stop-AzureRmStreamAnalyticsJob -ResourceGroupName rgModule10Lab -Name joblab-<your name's initials>-20775A
    ````

5.  After a couple of minutes observe returned value **True**.

6.  Switch to Azure Portal and observe the status of the job as **Stopped**.

7.  Close Internet Explorer, close Windows PowerShell, and then close the command prompt.

#### Task 3: Remove all Azure resources

1.  Delete the event hub, and the storage account, by deleting the associated resource group.

2.  Verify that all Azure resources have been removed.

**Results**: At the end of this exercise, you will have monitored and managed a Stream Analytics job using Azure Portal and PowerShell cmdlets.

Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
