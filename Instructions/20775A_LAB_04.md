# Module 4: Loading Data into HDInsight

## Lab: Loading data into your Azure account

### Scenario

This lab has two parts. First, you'll identify an e-commerce store's top-selling item with HDInsight. To find this item, you'll move data from a SQL database into HDInsight, find the top-selling product, and export the results to SQL Database. In the second scenario, you will upload a large file to Azure Blob storage, transfer that file to ADLS, and compress it using Hadoop Streaming.

### Objectives

In this lab, you will:

-   Transfer data using Sqoop.

-   Transfer data using AzCopy.

-   Transfer data using AdlCopy.

-   Compress data using HDInsight.

### Lab Setup

-   **Estimated Time**: 45 minutes

-   **Virtual machine**: 20775A-LON-DEV

-   **Username**: Admin

-   **Password**: Pa55w.rd

## Exercise 1: Load data for use with HDInsight

### Scenario

In this lab, you will walk through different tools that you can use to upload data to Azure. The first scenario uses HDInsight to find the top-selling products for a fictional bike company, Adventure Works. The second scenario uploads a large file and uses HDInsight to compress it.

At the end of this lab, you will know how to use AzCopy, AdlCopy, and how to compress files using Hadoop streaming jobs.

Note that if you installed Bash in the lab for Module 3 of this course, you do not need to complete Task 1 in this exercise.

The main tasks for this exercise are as follows:

1. Install Bash

2. Loading data using Sqoop

3. Install AzCopy and AdlCopy.

4. Loading data using AzCopy and AdlCopy.

#### Task 1: Install Bash

1.  Enable the developer features.

2.  Enable **Windows Subsystem for Linux (Beta)**.

#### Task 2: Loading data using Sqoop

In this task, you will compute the top-selling products for the e-commerce store. You will create a SQL Database in Azure that holds the order summary data. You will use Sqoop to transfer data to HDInsight.

1.  Create a standard Linux Hadoop HDInsight Version 3.5 cluster, in your newly created resource group.

2.  Your primary storage should be Azure Storage.

3.  Make sure you remember your SSH username and password.

4.  As the HDInsight cluster deploys, create a SQL Database based on the AdventureworksLT source (you can choose AdventureworksLT from the source blade during creation).

5.  Open the Azure SQL Database Query editor.

6.  Create a new query to run against your SQL Database.

7.  You are using the SalesLT.SalesOrderDetail table, which provides the orders for the fictitious e-commerce website. You're interested in calculating the top selling products of all time and will use HDInsight to manage the processing. Explore the values in the table.
    ````
    SELECT * FROM SalesLT.[SalesOrderDetail]
    ````

8.  You will be exporting data from HDInsight back to SQL Database and need a table for the inserted data. Execute this query to create a table named TopSellers in the SalesLT Schema.
    ````
    CREATE TABLE [SalesLT].[TopSellers]([qty] int,[productid] int )
    GO

    CREATE CLUSTERED INDEX ID_clustered_index on [SalesLT].TopSellers(qty)
    GO
    ````

9.  SSH into your HDInsight cluster.

10. In the SSH terminal, enter the following Sqoop command to confirm connection to your SQL Database. It lists the databases on the SQL Database:
    ````
    sqoop list-databases --connect jdbc:sqlserver://<serverName>.database.windows.net:1433 --username <adminLogin> --password <adminPassword>
    ````

11. Transfer the table from SQL Database to HDInsight using Sqoop:
    ````
    sqoop import --connect 'jdbc:sqlserver://<serverName>.database.windows.net:1433;database=<dbname>' --username <adminLogin> --password <adminPassword> --table 'SalesOrderDetail' --target-dir 'wasbs:///tutorials/usesqoop/importeddata' --fields-terminated-by '\t' --lines-terminated-by '\n' -m 1 -- --schema SalesLT
    ````

12. Confirm a successful transfer using HDFS:
    ````
    hadoop fs -text wasbs:///hive/warehouse/salesorderdetail/part-m-00000
    ````

13. Close the SSH terminal.

#### Task 3: Install AzCopy and AdlCopy

In the section, you will install AzCopy, and AdlCopy.

1.  Install **AzCopy** from **http://aka.ms/downloadazcopy**.

2.  Install **AdlCopy** from **http://aka.ms/downloadadlcopy**.

#### Task 4: Loading data using AzCopy and AdlCopy

In this section, you will use AzCopy to move a large file from your local machine to Azure Blob storage. You will also copy the file to ADLS. Finally, you will compress that file using the HDInsight cluster.

1.  Upload the file in **E:\\Labfiles\\Lab04\\StarterLargeUpload\\dummy.txt** using AzCopy:
    ````
    AzCopy /Source: E:\Labfiles\Lab04\Starter\LargeUpload /Dest:https://<storageaccountname>.blob.core.windows.net/uploadedfilek /DestKey:<yourKey> /S
    ````

2.  You can also copy data using AzCopy. The last command had a typo. You meant to upload the data to a container named **uploadedfiles**, not **uploadedfilek**. Copy the uploaded data to a new container in your storage account using AzCopy:
    ````
    AzCopy /Source:https://<stroageaccountname>.blob.core.windows.net/uploadedfilek /Dest: https://<stroageaccountname>.blob.core.windows.net/uploadedfiles /SourceKey:<YourSourceAccountKey> /DestKey:<YourDestinationAccountKey> /S
    ````

3.  View the file in Microsoft Azure Storage Explorer.

4.  Create an ADLS account using the portal.

5.  Open a command prompt and use AdlCopy to move data from Azure Storage to ADLS:
    ````
    AdlCopy /source https://<source_account>.blob.core.windows.net/<source_container>/<blob name> /dest swebhdfs://<dest_adls_account>.azuredatalakestore.net/<dest_folder>/ /sourcekey <storage_account_key_for_storage_container>
    ````

    In a real-world situation, you would have uploaded this file directly to ADLS, but in the future, you might have data in an Azure Storage account that you need to move to ADLS.

6.  On portal.azure.com, delete the resource group and all resources used for these labs.


Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
