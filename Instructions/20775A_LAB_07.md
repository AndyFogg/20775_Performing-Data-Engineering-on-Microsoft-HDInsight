# Module 7: Design Batch ETL Solutions for Big Data with Spark

## Lab: Working with Spark ETL

### Scenario

You work as a consultant for Contoso, a large IT consultancy organization with staff in different industrial sectors. You are asked to create a Spark ETL application to load data from one of Contoso's clients, a movie streaming service provider. The data contains movie rating information from users of the streaming service; in future, Contoso will use the data as one of several inputs to a machine learning model for making movie recommendations.

In this lab, you will use Jupyter Notebook and a sample data file to prototype the ETL process (using Python 2). You will then create a Python script containing your application and upload the script to the shared storage of your HDInsight cluster. Finally, you will trigger the application from spark-submit.

### Objectives

At the end of this lab, you will be able to:

-   Design a Spark ETL process.

-   Trigger a Spark application from spark-submit.

### Lab Setup

This lab requires you to have access to the resources outlined in the *Prerequisites* section of the *Module Overview*.

-   **Estimated Time**: 60 minutes

-   **Virtual machine**: 20775A-LON-DEV

-   **Username**: Admin

-   **Password**: Pa55w.rd

## Exercise 1: Design a Spark ETL application

### Scenario

You will design a simple ETL process, using Jupyter Notebooks.

The source data file format is a tab-delimited text file that has the following integer columns:

-   **userID**: the user identifier from the source system.

-   **movieID**: the movie identifier from the source system.

-   **userRating**: the user's rating of the movie (out of five).

-   **timestamp**: the date and time of the rating, expressed as a unix timestamp (the number of seconds that have elapsed since January 1, 1970).

A sample data file is located at **/HdiSamples/HdiSamples/MahoutMovieData/user-ratings.txt** on your HDInsight cluster's shared storage. For the purposes of the lab, you should assume that the data file will always have this path. The ETL application is triggered by a manual process, each time a new version of the file arrives.

-   You should store the data from the file in a Hive temporary table called **allUserRatings**.

-   The value of the **userRating** column in the source data is a rating out of five; it should be stored as a rating out of 10.

-   The **userID** column should not be stored.

The main tasks for this exercise are as follows:

0. Prepare the environment

1. Design the ETL

2. Create the ETL application

3. Execute the application using spark-submit

4. Review Spark history

5. Remove all Azure resources

#### Task 0: Prepare the environment

1.  Ensure that the **MT17B-WS2016-NAT**, and **20775A-LON-DEV** virtual machines are running, and then log on to **20775A-LON-DEV** as **Admin** with the password **Pa55w.rd**.

2.  Connect to the Azure Portal, and then sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.

3.  Create a new HDInsight cluster with the following details:

    -   **Cluster name**: \<*your name\>\<date*\>hdi

    -   **Cluster type**: Spark

    -   **Version**: 2.3.0 (HDI 3.6)

    -   **Cluster login username**: sparkadmin

    -   **Cluster login password**: Pa55w.rdPa55w.rd

    -   **Secure Shell (SSH) username**: sshadmin

    -   **Use same password as cluster login**: selected

    -   **Resource group (Create new)**: Sparkrg

    -   **Location**: Select your region

    -   **Storage account (Create new)**: \<*your name\>\<date*\>sa

    -   **Default container**: replace the suggested name with \<*the name of your cluster*\>-ctr (for example, \<*your name\>\<date*\>hdi-ctr).

    -   **Cluster size**:
    
        -   Number of Worker nodes: 1

        -   **Worker node size**: A3 General Purpose

        -   **Head node size**: A3 General Purpose

4.  The deployment might take 20-30 minutes to complete. Wait for the cluster to be provisioned and do not continue with this exercise until the status shows as **Running**.

#### Task 1: Design the ETL

1.  Ensure that the **MT17B-WS2016-NAT**, and **20775A-LON-DEV** virtual machines are running, and then log on to **20775A-LON-DEV** as **Admin** with the password **Pa55w.rd**.

2.  Use the requirements given in the exercise scenario to create a Python 2 Jupyter Notebook on your HDInsight on Azure cluster that loads the datafile into a Hive temporary table, including the specified transformations. Name the notebook **lab-etl**. Run a SQL statement to verify the contents of the table.

#### Task 2: Create the ETL application

-   Using the Python script that you wrote in the previous task, create a Python file that can be run as an application. Upload the file to the shared storage of your HDInsight on Azure cluster as a file called **apps/lab-07-etl.py**. You can use the file **E:\\Labfiles\\Lab07\\template.txt** as a template for your script file.

#### Task 3: Execute the application using spark-submit

1.  Log in to the head node of your HDInsight cluster by SSH, using the **sshuser** username and password.

2.  Copy the script file that you created in the previous task to the node's local filesystem using the **hdfs dfs -copyToLocal** command. Execute the **spark-submit** script using the default values for all options. When the script has completed, review the results. When you have finished reviewing, close and halt your Jupyter  otebook, then close any open browser windows and text editors.

#### Task 4: Review Spark history

1.  In Internet Explorer, open the Spark History server for your cluster via direct URL connection, to determine:

    -   The run time of your application.

    -   The run time of the job(s) in your application.

2.  Review the other information available about your application through the Spark History server, then close the browser.

#### Task 5: Remove all Azure resources

1.  Delete the HDInsight cluster and storage account, by deleting the associated resource group.

2.  Verify that all Azure resources have been removed.

**Results**: At the end of this exercise, you should have designed a Spark ETL process.

Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
