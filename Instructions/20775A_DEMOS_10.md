# Module 10: Stream Analytics

## Demo 1: Process streaming data

### Scenario

In this demonstration, you will see how to:
-  Create a Stream Analytics job.
-  Develop a Stream Analytics job query.
-  Test a Stream Analytics job query.

### Preparation

Before starting this demonstration, you will need to complete the following steps to ensure that the Azure Learning Pass subscription is registered with the Microsoft Insights Resource Provider:
1.  On the **20775A-LON-DEV** virtual machine, in Microsoft Edge, in the address bar, type **http://portal.azure.com** and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
2.  In the menu on the left, click **All services**, and then click **Subscriptions**.
3.  On the **Subscriptions** blade, click your subscription.
4.  On the Subscription blade, under **Settings**, click **Resource providers**.
5.  In the search box, type **microsoft.insights**.
6.  Next to **microsoft.insights**, ensure the status is **Registered**. If the status is **NotRegistered**, complete the following steps:
    1.  Click the **Register** link, and observe the status changing to **Registering**.
    2.  At the top of the page, click **Refresh** until the status is changed to **Registered**.
7.  Close Microsoft Edge.

### Create an Azure Stream Analytics job

1.  On the **20775A-LON-DEV** virtual machine, in Microsoft Edge, in the address bar, type **http://portal.azure.com** and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
2.  In the Azure Portal, click **+ Create a resource**, in the Search box, type **Stream Analytics**, and then press Enter.
3.  On the **Everything** blade, click **Stream Analytics job**, and then click **Create**.
4.  On the **New Stream Analytics job** blade, enter the following details, and then click **Create**:
    -  **Job name**: job-\<*your initials*\>-20775A
    -  **Subscription**: Your subscription
    -  **Resource group (Create new)**: rgModule10
    -  **Location**: Leave default location
5.  Wait until the job is created successfully.

### Develop a Stream Analytics job query

1.  Click **All resources**, and then click **job\-<*your initials*\>-20775A**.
2.  On the **job\-<*your initials*\>-20775A** blade, under **Job topology**, click **Query**.
3.  In the query editor window, change the default query to the one below, and then click **Save**:
    ````sql
    SELECT dspl, temp
    FROM TestInput
    ````
4.  In the **Save** dialog box, click **Yes**.

### Test a Stream Analytics job query

1.  On the **Query** blade, under **Inputs (1)**, right-click **testinput**, and then click **Upload sample data from file**.
2.  On the **Upload test data** blade, click the folder icon.
3.  In the **Choose File to Upload** dialog box, navigate to **E:\\Demofiles\\Mod10**, click **SampleSensorData.json**, and then click **Open**.
4.  On the **Upload test data** blade, click **OK**.
5.  Wait until the upload is complete.
6.  Under **Inputs (1)**, observe that the **testinput** item now shows a text file icon.
7.  At the top of the page, click **Test**.
8.  In the **Test** dialog box, click **OK**. The query is executed against test data.
9.  In the **Results** section, note the message output with **219** rows.
11. In the query editor window, change the query to the one below, and then click **Test**:
    ````sql
    SELECT
        dspl,
        avg(temp) as avgtemp
    FROM
        TestInput
    GROUP BY dspl, TUMBLINGWINDOW(ss, 30)
    ````
12. In the **Test** dialog box, click **OK**. The query is executed against test data.
13. In the **Results** section, note the message output with 3 rows.
14. On the **job\-<*your initials*\>-20775A** blade, click **Overview**.
15. In the **This site says** dialog box, click **OK**.

## Demo 2: Managing Stream Analytics jobs

### Scenario

In this demonstration, you will see how to manage and monitor a Stream Analytics job:
-  In the Azure Portal.
-  Using PowerShell scripts.
-  Using Stream Analytics diagnostic logs.

### Preparation

This demonstration continues from the previous one.
Ensure that Microsoft Edge is running, and you are logged into the Azure Portal page, using the Microsoft account that is associated with your Azure Learning Pass subscription.

### Create an Event Hub

1.  In the Azure Portal, click **+ Create a resource**, in the Search box, type **Event Hubs**, and then press Enter.
2.  On the **Everything** blade, click **Event Hubs**, and then click **Create**.
3.  On the **Create Namespace** blade, enter the following details, and then click **Create**:
    -  **Name**: eh-\<*your initials*\>-20775A
    -  **Pricing tier**: Standard
    -  **Subscription**: Your subscription
    -  **Resource group (Create new)**: rgModule10
    -  **Location**: Your location
4.  When the event hubs namespace has been created, click **All resources**, and then click **eh-\<*your initials*\>-20775A**.
5.  On the **eh-\<*your initials*\>-20775A** blade, click **+ Event Hub**.
6.  On the **Create Event Hub** blade, enter the following details, and then click **Create**:
    -  **Name**: EventHub
    -  **Partition Count**: 2
    -  **Message Retention**: 1
    -  **Capture**: Off
7.  Wait until the Event Hub is created successfully.
8.  On **eh-\<*your initials*\>-20775A** blade, under **Entities**, click **Event Hubs**, and confirm that **eventhub** is in the list of items with status **Active**.
9.  On **eh-\<*your initials*\>-20775A** blade, under **Settings**, click **Shared access policies**, and then click **RootManageSharedAccessKey**.
10. On the **SAS Policy: RootManageSharedAccessKey** blade, to the right of **Primary key**, click on the **Click to copy** button to copy value into the clipboard.
11. Open notepad, and paste the key value to a notepad file.
12. Do not close the file, or save it on the desktop.
13. Start the **ContosoSensorData** application provided in the **E:\\Demofiles\\Mod10\\ContosoSensorData** folder by following the steps below:
    1.  In File Explorer, navigate to **E:\\Demofiles\\Mod10\\ContosoSensorData**, and then double-click **ContosoSensorData.exe**.
    2.  In the console window,enter the follwoing details when  prompted:
        -  **Event Hub Namespace**: eh-\<*your initials*\>-20775A
        -  **Event Hub Name**: eventhub
        -  **Shared Access Key**: \<Value of the key copied from Shared Access Policy setting of the Event Hub\>
        -  Press 2 to create a continuous stream of data. 

>**Note**: Keep the application running for the rest of the demonstration. The selected event hub will be receiving messages from simulated sensors every five seconds.

### Create input for a Stream Analytics job

1.  In the Azure Portal, in the left menu, click **All resources**, and then click **job-\<*your initials*\>-20775A**.
2.  On the **job-\<*your initials*\>-20775A** blade, in the **Job topology** section, click **Inputs**.
3.  On the **Inputs** blade, click **+ Add stream input**, and then click **Event Hub**.
4.  On the **Event Hub** blade, enter the following details, and then click **Save**:
    -  **Input alias**: TestInput
    -  **Provide Event Hub settings manually**: selected
    -  **Service Bus namespace**: sb://eh-\<*your initials*\>-20775a.servicebus.windows.net
    -  **Event Hub name**: EventHub
    -  **Event Hub policy name**: RootManageSharedAccessKey
    -  **Event Hub policy key**: Paste the shared access policy key from Notepad (as done in the previous demo)
5.  Wait until you receive **Successful connection test** notification message with **Connection to input ‘TestInput’ succeeded** text.

### Create output for a Stream Analytics job

1.  In the left menu, click **+ Create a resource**, click **Storage**, and then click **Storage account - blob, file, table, queue**.
2.  On the **Create storage account** blade, enter the following details, and then click **Review + create**:
    -  **Resource group**: rgmodule10
    -  **Storage account**: blob\<*your initials*\>20775a
    -  **Location**: Your location
    -  **Performance**: Standard
    -  **Account kind**: BlobStorage
    -  **Replication**: Locally-redundant storage (LRS)
3.  On the **Create storage account** blade, click **Create**.
4.  Wait until you receive **Deployment succeeded** notification message.
5.  In the left menu, click **All resources**, and then click **job-\<*your initials*\>-20775A**.
6.  On the **job-\<*your initials*\>-20775A** blade, in the **Job jopology** section, click **Outputs**.
7.  On the **Outputs** blade, click **+ Add**, and then click **Blob storage**.
8.  On the **Blob storage** blade, enter the following details, and then click **Save**:
    -  **Output alias**: TestOutput
    -  **Select Blob storage from your subscriptions**: selected
    -  **Storage account**: blob\<*your initials*\>20775A
    -  **Container (Create new)**: output
9.  Wait until you receive **Successful connection test** notification message with **Connection to output ‘TestOutput’ succeeded** text.

### Manage a Stream Analytics job in the Azure Portal

1.  On the **job-\<*your initials*\>-20775A** blade, in the **Job topology** section, click **Query**.
2.  In the **Query** editor, modify the query to include an output as follows, and then click **Save**:
    ````sql
    SELECT
        dspl,
        avg(temp) as avgtemp
    INTO
        TestOutput
    FROM
        TestInput
    GROUP BY dspl, TUMBLINGWINDOW(ss, 30)
    ````
3.  In the **Save** dialog box, click **Yes**.
4.  On the **job-\<*your initials*\>-20775A** blade, click **Overview**.
5.  In the top row menu, click **Start** to start the job execution.
6.  On the **Start job** blade, click **Custom**, change the time to an hour before the current time, and then click **Start**.
7.  Observe the **Status** changing from **Starting** to **Running** after a couple of minutes.
8.  After a further 2-3 minutes, in the **Monitoring** section, observe the chart. Note the number of **Input Events**, **Output Events**, and **Runtime Errors**.
9.  Click the chart to edit it. 
10. On the **Metrics** blade, click **Classic explorer**.
11. Under **Available metrics**, select the **SU % Utilization** metric.
12. In the **Chart type** list, click **Bar**.
13. In the **Time range** list, click **Past hour**.
14. Observe that the chart changes to a bar chart, showing resource utilization for the past hour at regular intervals.
15. Close the **Metrics (classic)** blade, and then close the **Metrics** blade.

### Manage a Stream Analytics job using PowerShell

1.  Open **Windows PowerShell** command window.
2.  At the PowerShell prompt, run the following command to login to Azure Account :
    ````
    Login-AzureRmAccount
    ````
3.  If the **Select Y to enable data collection** meassage appears, type **n**, and then press Enter.
4.  Sign in using the Microsoft account associated with your Azure Learning Pass subscription, and select the **Keep me signed in** option.
5.  At the PowerShell prompt, run the following command to get information about the Stream Analytics job named **job-\<*your initials*\>-20775A** in the resource group **rgModule10**:
    ````
    Get-AzureRmStreamAnalyticsJob -ResourceGroupName rgModule10 -Name job-<your initials>-20775A
    ````
6.  Observe the various job properties, including **CreatedDate**, **JobState**, and **Properties** values with a JSON document that describes the job.
7.  Ensure that **JobState** is **Running** before continuing.
8.  At the PowerShell prompt, run the following command to stop the job execution:
    ````
    Stop-AzureRmStreamAnalyticsJob -ResourceGroupName rgModule10 -Name job-<your initials>-20775A
    ````
9.  After a couple of minutes observe the returned value **True**.
10. Switch to **Microsoft Edge** and note that the status of the job is **Stopped** in the top row menu.

### Monitor a job execution using Stream Analytics diagnostics logs

1.  In the Azure Portal, click **+ Create a resource**, click **Storage**, and then click **Storage account - blob, file, table, queue**.
2.  On the **Create storage account** blade, enter the following settings, and then click **Review + create**:
    -  **Subscription**: Your subscription
    -  **Resource group**: rgModule10
    -  **Storage account name**: st\<*your initials*\>20775a
3.  On the **Create storage account** blade, click **Create**.
4.  Wait until you receive **Deployment succeeded** notification message.
5. In the left menu, click **All resources**, and then click **job-\<*your initials*\>-20775A**.
6.  On the **job-\<*your initials*\>-20775A** blade, under **Monitoring**, click **Diagnostics logs**.
7.  On the **Diagnostics logs** blade, click the **Turn on diagnostics** link.
8.  On the **Diagnostics settings** blade, in the **Name** box, type **logs-\<*your inititals*\>**. 
9.  Select **Archive to a storage account**, and then click **Storage account**.
10. On the **Select a storage account** blade, enter the following, and then click **OK**:
    -  **Subscription**: Your subscription
    -  **Storage account**: st\<*your initials*\>20775a
11. On the **Diagnostics settings** blade, in the **Log** section, select the **Execution** check box, and then click **Save**.
12. Close the **Diagnostics settings** blade, and then refresh the **Diagnostics logs** blade. Verify that the new log is listed.
13. Return to the PowerShell window, and run the following command:
    ````
    Start-AzureRmStreamAnalyticsJob -ResourceGroupName rgModule10 -Name job-<your initials>-20775A
    ````
14. After a couple of minutes observe returned value **True**.
15. In the Azure Portal, click **All resources**, and then click **st\<*your initials*\>20775a**.
16. On the **st\<*your initials*\>20775a** blade, under **Blob service**, click **Blobs**.
17. On the **Blob** blade, click **insights-logs-execution**.
18. On the **insights-logs-execution** blade, click the **resourceId=** folder, and then click through the hierarchy of folders until you get to the **PT1H.json** file.
19. Click the **PT1H.json** file, and then click **Download**.
20. Download and open the file to view its contents; it should contain a history of the status of the job.
21. Close the Microsoft Edge tab, close the command prompt, and then close Windows PowerShell.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
