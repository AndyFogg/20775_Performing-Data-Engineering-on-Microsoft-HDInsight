INFO 2017-06-06 14:22:24,685 main.py:122 - loglevel=logging.INFO
INFO 2017-06-06 14:22:24,686 main.py:122 - loglevel=logging.INFO
INFO 2017-06-06 14:22:24,686 main.py:122 - loglevel=logging.INFO
INFO 2017-06-06 14:22:24,688 ExitHelper.py:53 - Performing cleanup before exiting...
INFO 2017-06-06 14:22:27,967 main.py:122 - loglevel=logging.INFO
INFO 2017-06-06 14:22:27,968 main.py:122 - loglevel=logging.INFO
INFO 2017-06-06 14:22:27,969 main.py:134 - Adding syslog handler to ambari agent logger
INFO 2017-06-06 14:22:27,970 DataCleaner.py:39 - Data cleanup thread started
INFO 2017-06-06 14:22:27,973 DataCleaner.py:120 - Data cleanup started
INFO 2017-06-06 14:22:27,976 DataCleaner.py:122 - Data cleanup finished
INFO 2017-06-06 14:22:28,142 PingPortListener.py:50 - Ping port listener started on port: 8670
INFO 2017-06-06 14:22:28,146 main.py:398 - Connecting to Ambari server at https://headnodehost:8440 (10.0.0.13)
INFO 2017-06-06 14:22:28,146 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
WARNING 2017-06-06 14:22:28,148 NetUtil.py:95 - Failed to connect to https://headnodehost:8440/ca due to [Errno 111] Connection refused  
WARNING 2017-06-06 14:22:28,148 NetUtil.py:118 - Server at https://headnodehost:8440 is not reachable, sleeping for 5 seconds...
INFO 2017-06-06 14:22:33,149 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
WARNING 2017-06-06 14:22:33,151 NetUtil.py:95 - Failed to connect to https://headnodehost:8440/ca due to [Errno 111] Connection refused  
WARNING 2017-06-06 14:22:33,151 NetUtil.py:118 - Server at https://headnodehost:8440 is not reachable, sleeping for 5 seconds...
INFO 2017-06-06 14:22:38,151 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
WARNING 2017-06-06 14:22:38,152 NetUtil.py:95 - Failed to connect to https://headnodehost:8440/ca due to [Errno 111] Connection refused  
WARNING 2017-06-06 14:22:38,153 NetUtil.py:118 - Server at https://headnodehost:8440 is not reachable, sleeping for 5 seconds...
INFO 2017-06-06 14:22:43,153 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
WARNING 2017-06-06 14:22:43,154 NetUtil.py:95 - Failed to connect to https://headnodehost:8440/ca due to [Errno 111] Connection refused  
WARNING 2017-06-06 14:22:43,155 NetUtil.py:118 - Server at https://headnodehost:8440 is not reachable, sleeping for 5 seconds...
INFO 2017-06-06 14:22:48,155 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
WARNING 2017-06-06 14:22:48,157 NetUtil.py:95 - Failed to connect to https://headnodehost:8440/ca due to [Errno 111] Connection refused  
WARNING 2017-06-06 14:22:48,157 NetUtil.py:118 - Server at https://headnodehost:8440 is not reachable, sleeping for 5 seconds...
INFO 2017-06-06 14:22:53,157 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
WARNING 2017-06-06 14:22:53,159 NetUtil.py:95 - Failed to connect to https://headnodehost:8440/ca due to [Errno 111] Connection refused  
WARNING 2017-06-06 14:22:53,159 NetUtil.py:118 - Server at https://headnodehost:8440 is not reachable, sleeping for 5 seconds...
INFO 2017-06-06 14:22:58,160 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
WARNING 2017-06-06 14:22:58,161 NetUtil.py:95 - Failed to connect to https://headnodehost:8440/ca due to [Errno 111] Connection refused  
WARNING 2017-06-06 14:22:58,161 NetUtil.py:118 - Server at https://headnodehost:8440 is not reachable, sleeping for 5 seconds...
INFO 2017-06-06 14:23:03,162 NetUtil.py:64 - Connecting to https://headnodehost:8440/ca
INFO 2017-06-06 14:23:03,666 main.py:408 - Connected to Ambari server headnodehost
INFO 2017-06-06 14:23:03,959 threadpool.py:52 - Started thread pool with 3 core threads and 20 maximum threads
WARNING 2017-06-06 14:23:03,959 AlertSchedulerHandler.py:261 - [AlertScheduler] /var/lib/ambari-agent/cache/alerts/definitions.json not found or invalid. No alerts will be scheduled until registration occurs.
INFO 2017-06-06 14:23:03,960 AlertSchedulerHandler.py:156 - [AlertScheduler] Starting <ambari_agent.apscheduler.scheduler.Scheduler object at 0x7ff83e5d1bd0>; currently running: False
INFO 2017-06-06 14:23:03,973 hostname.py:79 - Read public hostname 'hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net' using agent:public_hostname_script
INFO 2017-06-06 14:23:03,974 ActionQueue.py:93 - Parallel execution is enabled, will execute agent commands in parallel
INFO 2017-06-06 14:23:04,242 Facter.py:194 - Directory: '/etc/resource_overrides' does not exist - it won't be used for gathering system resources.
INFO 2017-06-06 14:23:06,874 Controller.py:167 - Registering with hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net (10.0.0.13) (agent='{"hardwareProfile": {"kernel": "Linux", "domain": "mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net", "physicalprocessorcount": 4, "kernelrelease": "4.4.0-78-generic", "uptime_days": "0", "memorytotal": 7134392, "swapfree": "0.00 GB", "memorysize": 7134392, "osfamily": "ubuntu", "swapsize": "0.00 GB", "processorcount": 4, "netmask": "255.255.240.0", "timezone": "UTC", "hardwareisa": "x86_64", "memoryfree": 5444504, "operatingsystem": "ubuntu", "kernelmajversion": "4.4", "kernelversion": "4.4.0", "macaddress": "00:0D:3A:2A:58:C4", "operatingsystemrelease": "16.04", "ipaddress": "10.0.0.13", "hostname": "hn0-davidm", "uptime_hours": "0", "fqdn": "hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net", "id": "root", "architecture": "x86_64", "selinux": false, "mounts": [{"available": "3547268", "used": "0", "percent": "0%", "device": "udev", "mountpoint": "/dev", "type": "devtmpfs", "size": "3547268"}, {"available": "704460", "used": "8980", "percent": "2%", "device": "tmpfs", "mountpoint": "/run", "type": "tmpfs", "size": "713440"}, {"available": "1000047096", "used": "16377076", "percent": "2%", "device": "/dev/sda1", "mountpoint": "/", "type": "ext4", "size": "1016440556"}, {"available": "3567160", "used": "36", "percent": "1%", "device": "tmpfs", "mountpoint": "/dev/shm", "type": "tmpfs", "size": "3567196"}, {"available": "5120", "used": "0", "percent": "0%", "device": "tmpfs", "mountpoint": "/run/lock", "type": "tmpfs", "size": "5120"}, {"available": "278999244", "used": "64412", "percent": "1%", "device": "/dev/sdb1", "mountpoint": "/mnt", "type": "ext4", "size": "294022144"}], "hardwaremodel": "x86_64", "uptime_seconds": "260", "interfaces": "eth0,lo"}, "currentPingPort": 8670, "prefix": "/var/lib/ambari-agent/data", "agentVersion": "2.4.0.4", "agentEnv": {"transparentHugePage": "never", "hostHealth": {"agentTimeStampAtReporting": 1496758986864, "activeJavaProcs": [{"command": "/usr/bin/java -cp /usr/lib/hdinsight-logging/*:/usr/lib/hdinsight-provisioning-agent/provisioning-agent.jar -Dlog4j.configuration=file:/etc/hdinsight-provisioning-agent/conf/log4j.properties com.microsoft.provisioning.ProvisioningAgent", "pid": 1512, "hadoop": false, "user": "root"}, {"command": "/usr/bin/java -Dlog4j.configuration=file:/etc/hdinsight-patchingagent/conf/log4j.properties -jar /usr/lib/hdinsight-patchingagent/hdinsight-patchingagent.jar", "pid": 3143, "hadoop": false, "user": "root"}, {"command": "/usr/bin/java -Djava.net.preferIPv4Stack=true -Dfailovercontroller.root.logger=INFO,CONSOLE,ROLLINGFILE,ETW,FilterLog -Dfailovercontroller.log.file=master-failover-controller.log -Dfailovercontroller.log.dir=/var/log/failover-controller -Dcomponent=master-failover-controller -cp /usr/hdp/current/failover-controller/*:/usr/hdp/current/failover-controller/lib/*:/usr/hdp/current/hadoop/*:/usr/hdp/current/zookeeper-server/*:/usr/lib/hdinsight-logging/*:/etc/failover-controller/conf: com.microsoft.hdinsight.master.MasterZKFailoverController", "pid": 4164, "hadoop": true, "user": "root"}, {"command": "/usr/bin/java -Dfailovercontroller.log.dir=/var/log/failover-controller -Dfailovercontroller.root.logger=INFO,CONSOLE,ROLLINGFILE,ETW,FilterLog -Dfailovercontroller.log.file=slave-failover-controller.log -Dcomponent=slave-failover-controller -Djava.net.preferIPv4Stack=true -cp /usr/hdp/current/failover-controller/*:/usr/hdp/current/failover-controller/lib/*:/usr/hdp/current/hadoop/*:/usr/hdp/current/zookeeper-server/*:/usr/lib/hdinsight-logging/*:/etc/failover-controller/conf: com.microsoft.hdinsight.slave.SlaveFailoverController", "pid": 4232, "hadoop": true, "user": "root"}, {"command": "/usr/bin/java -Dfailovercontroller.root.logger=INFO,CONSOLE,ROLLINGFILE,ETW,FilterLog -Dfailovercontroller.log.file=master-ha-service.log -Dfailovercontroller.log.dir=/var/log/failover-controller -Dcomponent=master-ha-service -cp /usr/hdp/current/failover-controller/*:/usr/hdp/current/failover-controller/lib/*:/usr/hdp/current/hadoop/*:/usr/hdp/current/zookeeper-server/*:/usr/lib/hdinsight-logging/*:/etc/failover-controller/conf: com.microsoft.hdinsight.haservices.MasterHAServiceHandler", "pid": 5051, "hadoop": true, "user": "root"}, {"command": "/usr/bin/java -Djava.net.preferIPv4Stack=true -Dfailovercontroller.root.logger=INFO,CONSOLE,ROLLINGFILE,ETW,FilterLog -Dfailovercontroller.log.file=slave-ha-service.log -Dfailovercontroller.log.dir=/var/log/failover-controller -Dcomponent=slave-ha-service -cp /usr/hdp/current/failover-controller/*:/usr/hdp/current/failover-controller/lib/*:/usr/hdp/current/hadoop/*:/usr/hdp/current/zookeeper-server/*:/usr/lib/hdinsight-logging/*:/etc/failover-controller/conf: com.microsoft.hdinsight.haservices.SlaveHAServiceHandler", "pid": 5233, "hadoop": true, "user": "root"}], "liveServices": [{"status": "Healthy", "name": "ntp", "desc": ""}]}, "reverseLookup": true, "alternatives": [], "umask": "18", "firewallName": "ufw", "stackFoldersAndFiles": [{"type": "directory", "name": "/etc/hadoop"}, {"type": "directory", "name": "/etc/hbase"}, {"type": "directory", "name": "/etc/hive"}, {"type": "directory", "name": "/etc/oozie"}, {"type": "directory", "name": "/etc/sqoop"}, {"type": "directory", "name": "/etc/zookeeper"}, {"type": "directory", "name": "/etc/storm"}, {"type": "directory", "name": "/etc/hive-hcatalog"}, {"type": "directory", "name": "/etc/tez"}, {"type": "directory", "name": "/etc/falcon"}, {"type": "directory", "name": "/etc/hive-webhcat"}, {"type": "directory", "name": "/etc/kafka"}, {"type": "directory", "name": "/etc/slider"}, {"type": "directory", "name": "/etc/storm-slider-client"}, {"type": "directory", "name": "/etc/mahout"}, {"type": "directory", "name": "/etc/spark"}, {"type": "directory", "name": "/etc/pig"}, {"type": "directory", "name": "/etc/ranger"}, {"type": "directory", "name": "/etc/ambari-metrics-collector"}, {"type": "directory", "name": "/etc/ambari-metrics-monitor"}, {"type": "directory", "name": "/etc/zeppelin"}, {"type": "directory", "name": "/var/log/hbase"}, {"type": "directory", "name": "/var/log/hive"}, {"type": "directory", "name": "/var/log/oozie"}, {"type": "directory", "name": "/var/log/sqoop"}, {"type": "directory", "name": "/var/log/zookeeper"}, {"type": "directory", "name": "/var/log/storm"}, {"type": "directory", "name": "/var/log/hive-hcatalog"}, {"type": "directory", "name": "/var/log/tez"}, {"type": "directory", "name": "/var/log/falcon"}, {"type": "directory", "name": "/var/log/hadoop-hdfs"}, {"type": "directory", "name": "/var/log/hadoop-yarn"}, {"type": "directory", "name": "/var/log/hadoop-mapreduce"}, {"type": "directory", "name": "/var/log/kafka"}, {"type": "directory", "name": "/var/log/spark"}, {"type": "directory", "name": "/var/log/ranger"}, {"type": "directory", "name": "/var/log/zeppelin"}, {"type": "directory", "name": "/usr/lib/flume"}, {"type": "directory", "name": "/usr/lib/storm"}, {"type": "directory", "name": "/usr/lib/ambari-metrics-collector"}, {"type": "directory", "name": "/var/lib/hive"}, {"type": "directory", "name": "/var/lib/oozie"}, {"type": "directory", "name": "/var/lib/hive-hcatalog"}, {"type": "directory", "name": "/var/lib/hadoop-hdfs"}, {"type": "directory", "name": "/var/lib/hadoop-yarn"}, {"type": "directory", "name": "/var/lib/hadoop-mapreduce"}, {"type": "directory", "name": "/var/lib/slider"}, {"type": "directory", "name": "/var/lib/ranger"}, {"type": "directory", "name": "/var/lib/ambari-metrics-collector"}, {"type": "directory", "name": "/var/tmp/oozie"}, {"type": "directory", "name": "/var/tmp/sqoop"}, {"type": "directory", "name": "/var/tmp/spark"}], "existingUsers": [{"status": "Available", "name": "mapred", "homeDir": "/home/mapred"}, {"status": "Available", "name": "hdfs", "homeDir": "/home/hdfs"}, {"status": "Available", "name": "yarn", "homeDir": "/home/yarn"}, {"status": "Available", "name": "oozie", "homeDir": "/home/oozie"}, {"status": "Available", "name": "hive", "homeDir": "/home/hive"}, {"status": "Available", "name": "ambari-qa", "homeDir": "/home/ambari-qa"}, {"status": "Available", "name": "zookeeper", "homeDir": "/home/zookeeper"}, {"status": "Available", "name": "tez", "homeDir": "/home/tez"}, {"status": "Available", "name": "sqoop", "homeDir": "/home/sqoop"}, {"status": "Available", "name": "hcat", "homeDir": "/home/hcat"}, {"status": "Available", "name": "ams", "homeDir": "/home/ams"}, {"status": "Available", "name": "hbase", "homeDir": "/var/lib/hbase"}, {"status": "Available", "name": "storm", "homeDir": "/home/storm"}, {"status": "Available", "name": "kafka", "homeDir": "/home/kafka"}, {"status": "Available", "name": "spark", "homeDir": "/home/spark"}, {"status": "Available", "name": "falcon", "homeDir": "/home/falcon"}, {"status": "Available", "name": "ranger", "homeDir": "/home/ranger"}, {"status": "Available", "name": "kms", "homeDir": "/home/kms"}, {"status": "Available", "name": "zeppelin", "homeDir": "/var/lib/zeppelin"}], "firewallRunning": false}, "timestamp": 1496758984250, "hostname": "hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net", "responseId": -1, "publicHostname": "hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net"}')
INFO 2017-06-06 14:23:06,876 NetUtil.py:64 - Connecting to https://headnodehost:8440/connection_info
INFO 2017-06-06 14:23:07,067 security.py:100 - SSL Connect being called.. connecting to the server
INFO 2017-06-06 14:23:07,553 security.py:61 - SSL connection established. Two-way SSL authentication is turned off on the server.
INFO 2017-06-06 14:23:07,935 Controller.py:193 - Registration Successful (response id = 0)
INFO 2017-06-06 14:23:07,936 AmbariConfig.py:273 - Updating config property (agent.check.remote.mounts) with value (false)
INFO 2017-06-06 14:23:07,936 AmbariConfig.py:273 - Updating config property (agent.auto.cache.update) with value (false)
INFO 2017-06-06 14:23:07,937 AmbariConfig.py:273 - Updating config property (agent.check.mounts.timeout) with value (0)
INFO 2017-06-06 14:23:07,937 Controller.py:484 - Spawning statusCommandsExecutor
WARNING 2017-06-06 14:23:07,939 AlertSchedulerHandler.py:104 - There are no alert definition commands in the heartbeat; unable to update definitions
INFO 2017-06-06 14:23:07,940 Controller.py:534 - Registration response from headnodehost was OK
INFO 2017-06-06 14:23:07,941 Controller.py:539 - Resetting ActionQueue...
INFO 2017-06-06 14:23:07,945 StatusCommandsExecutor.py:55 - StatusCommandsExecutor starting
INFO 2017-06-06 14:23:17,951 Controller.py:297 - Heartbeat (response id = 0) with server is running...
INFO 2017-06-06 14:23:17,951 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:23:17,953 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:23:18,316 Controller.py:313 - Sending Heartbeat (id = 0)
INFO 2017-06-06 14:23:18,382 Controller.py:325 - Heartbeat response received (id = 1)
INFO 2017-06-06 14:23:18,383 Controller.py:334 - Heartbeat interval is 10 seconds
INFO 2017-06-06 14:23:18,383 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:23:18,383 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:23:18,383 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:23:18,384 Controller.py:456 - Waiting 9.9 for next heartbeat
INFO 2017-06-06 14:23:28,288 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:23:49,972 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,014 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,051 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,086 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,127 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,164 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,204 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,242 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,276 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,311 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,346 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,381 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,414 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:23:50,451 Controller.py:246 - Adding 12 commands. Heartbeat id = 4
INFO 2017-06-06 14:23:50,458 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role APP_TIMELINE_SERVER for service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,459 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role HCAT for service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,459 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role HDFS_CLIENT for service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,460 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role HISTORYSERVER for service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,460 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role HIVE_CLIENT for service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,460 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role MAPREDUCE2_CLIENT for service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,461 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role OOZIE_CLIENT for service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,461 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role PIG for service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,461 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role SLIDER for service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,462 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role SQOOP for service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,462 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role TEZ_CLIENT for service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,462 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role YARN_CLIENT for service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:50,464 AlertSchedulerHandler.py:219 - [AlertScheduler] Rescheduling all jobs...
INFO 2017-06-06 14:23:50,465 AlertSchedulerHandler.py:271 - [AlertScheduler] Caching cluster davidmod05cluster with alert hash a7d04dfcccf63f8686d6e8d034c70c3f
INFO 2017-06-06 14:23:50,466 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling ambari_agent_disk_usage with UUID 4957ceac-cd9c-47bf-aa12-7c352dc4881a
INFO 2017-06-06 14:23:50,467 AlertSchedulerHandler.py:240 - [AlertScheduler] Reschedule Summary: 0 unscheduled, 0 rescheduled
INFO 2017-06-06 14:23:50,468 RecoveryManager.py:577 - RecoverConfig = {u'components': u'HIVE_METASTORE,MAPREDUCE2_CLIENT,OOZIE_CLIENT,HIVE_CLIENT,SLIDER,APP_TIMELINE_SERVER,HIVE_SERVER,METRICS_MONITOR,RESOURCEMANAGER,HDFS_CLIENT,ZKFC,PIG,WEBHCAT_SERVER,YARN_CLIENT,METRICS_COLLECTOR,NAMENODE,OOZIE_SERVER,SQOOP,TEZ_CLIENT,HISTORYSERVER,HCAT',
 u'maxCount': u'6',
 u'maxLifetimeCount': u'1024',
 u'recoveryTimestamp': 1496759028121,
 u'retryGap': u'5',
 u'type': u'AUTO_START',
 u'windowInMinutes': u'60'}
INFO 2017-06-06 14:23:50,469 RecoveryManager.py:677 - ==> Auto recovery is enabled with maximum 6 in 60 minutes with gap of 5 minutes between and lifetime max being 1024. Enabled components - HIVE_METASTORE, MAPREDUCE2_CLIENT, OOZIE_CLIENT, HIVE_CLIENT, SLIDER, APP_TIMELINE_SERVER, HIVE_SERVER, METRICS_MONITOR, RESOURCEMANAGER, HDFS_CLIENT, ZKFC, PIG, WEBHCAT_SERVER, YARN_CLIENT, METRICS_COLLECTOR, NAMENODE, OOZIE_SERVER, SQOOP, TEZ_CLIENT, HISTORYSERVER, HCAT
INFO 2017-06-06 14:23:50,504 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=45
INFO 2017-06-06 14:23:50,505 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 45 for role = APP_TIMELINE_SERVER of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,505 ActionQueue.py:316 - Command execution metadata - taskId = 45, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,505 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=46
INFO 2017-06-06 14:23:50,523 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 46 for role = HCAT of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,523 ActionQueue.py:316 - Command execution metadata - taskId = 46, retry enabled = True, max retry duration (sec) = 600, log_output = True
WARNING 2017-06-06 14:23:50,536 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-45.txt'
INFO 2017-06-06 14:23:50,540 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=47
WARNING 2017-06-06 14:23:50,544 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-46.txt'
INFO 2017-06-06 14:23:50,559 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=48
INFO 2017-06-06 14:23:50,559 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 47 for role = HDFS_CLIENT of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,561 ActionQueue.py:316 - Command execution metadata - taskId = 47, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,576 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=49
WARNING 2017-06-06 14:23:50,579 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-45.txt'
WARNING 2017-06-06 14:23:50,580 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-46.txt'
WARNING 2017-06-06 14:23:50,580 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-47.txt'
INFO 2017-06-06 14:23:50,582 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 48 for role = HISTORYSERVER of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,586 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 49 for role = HIVE_CLIENT of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,587 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=50
INFO 2017-06-06 14:23:50,589 ActionQueue.py:316 - Command execution metadata - taskId = 48, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,591 ActionQueue.py:316 - Command execution metadata - taskId = 49, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,595 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 50 for role = MAPREDUCE2_CLIENT of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,597 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=51
INFO 2017-06-06 14:23:50,610 ActionQueue.py:316 - Command execution metadata - taskId = 50, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,625 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=52
INFO 2017-06-06 14:23:50,627 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 51 for role = OOZIE_CLIENT of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,636 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 52 for role = PIG of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,640 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=53
INFO 2017-06-06 14:23:50,642 ActionQueue.py:316 - Command execution metadata - taskId = 51, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,652 ActionQueue.py:316 - Command execution metadata - taskId = 52, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,662 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 53 for role = SLIDER of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,663 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=54
INFO 2017-06-06 14:23:50,673 ActionQueue.py:316 - Command execution metadata - taskId = 53, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,681 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 54 for role = SQOOP of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,687 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=55
INFO 2017-06-06 14:23:50,688 ActionQueue.py:316 - Command execution metadata - taskId = 54, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,700 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 55 for role = TEZ_CLIENT of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,702 ActionQueue.py:186 - Kicking off a thread for the command, id=12-0 taskId=56
INFO 2017-06-06 14:23:50,730 ActionQueue.py:316 - Command execution metadata - taskId = 55, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:50,740 ActionQueue.py:275 - Executing command with id = 12-0, taskId = 56 for role = YARN_CLIENT of cluster davidmod05cluster.
INFO 2017-06-06 14:23:50,758 ActionQueue.py:316 - Command execution metadata - taskId = 56, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:23:59,328 Controller.py:255 - Adding 9 status commands. Heartbeat id = 13
INFO 2017-06-06 14:23:59,332 RecoveryManager.py:204 - New status, desired status is set to STARTED for HIVE_METASTORE
INFO 2017-06-06 14:23:59,333 RecoveryManager.py:204 - New status, desired status is set to STARTED for HIVE_SERVER
INFO 2017-06-06 14:23:59,335 RecoveryManager.py:204 - New status, desired status is set to STARTED for METRICS_MONITOR
INFO 2017-06-06 14:23:59,340 RecoveryManager.py:204 - New status, desired status is set to STARTED for RESOURCEMANAGER
INFO 2017-06-06 14:23:59,340 RecoveryManager.py:204 - New status, desired status is set to STARTED for ZKFC
INFO 2017-06-06 14:23:59,340 RecoveryManager.py:204 - New status, desired status is set to STARTED for WEBHCAT_SERVER
INFO 2017-06-06 14:23:59,344 RecoveryManager.py:204 - New status, desired status is set to STARTED for METRICS_COLLECTOR
INFO 2017-06-06 14:23:59,345 RecoveryManager.py:204 - New status, desired status is set to STARTED for NAMENODE
INFO 2017-06-06 14:23:59,345 RecoveryManager.py:204 - New status, desired status is set to STARTED for OOZIE_SERVER
INFO 2017-06-06 14:23:59,348 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,428 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,487 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,615 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,665 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,723 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,766 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,799 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:23:59,856 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:00,745 RecoveryManager.py:185 - current status is set to INSTALLED for HIVE_METASTORE
INFO 2017-06-06 14:24:00,746 RecoveryManager.py:255 - HIVE_METASTORE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:02,748 RecoveryManager.py:185 - current status is set to INSTALLED for HIVE_SERVER
INFO 2017-06-06 14:24:02,750 RecoveryManager.py:255 - HIVE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:02,752 RecoveryManager.py:185 - current status is set to INSTALLED for METRICS_MONITOR
INFO 2017-06-06 14:24:02,754 RecoveryManager.py:255 - METRICS_MONITOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:04,766 RecoveryManager.py:185 - current status is set to INSTALLED for RESOURCEMANAGER
INFO 2017-06-06 14:24:04,768 RecoveryManager.py:255 - RESOURCEMANAGER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:04,770 RecoveryManager.py:185 - current status is set to INSTALLED for ZKFC
INFO 2017-06-06 14:24:04,771 RecoveryManager.py:255 - ZKFC needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:04,773 RecoveryManager.py:185 - current status is set to INSTALLED for WEBHCAT_SERVER
INFO 2017-06-06 14:24:04,775 RecoveryManager.py:255 - WEBHCAT_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:04,777 RecoveryManager.py:185 - current status is set to INSTALLED for METRICS_COLLECTOR
INFO 2017-06-06 14:24:04,777 RecoveryManager.py:255 - METRICS_COLLECTOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:04,798 RecoveryManager.py:185 - current status is set to INSTALLED for NAMENODE
INFO 2017-06-06 14:24:04,799 RecoveryManager.py:255 - NAMENODE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:04,801 RecoveryManager.py:185 - current status is set to INSTALLED for OOZIE_SERVER
INFO 2017-06-06 14:24:04,801 RecoveryManager.py:255 - OOZIE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:16,889 ActionQueue.py:358 - Quit retrying for command id 55. Status: COMPLETED, retryAble: True, retryDuration (sec): 574, last delay (sec): 1
INFO 2017-06-06 14:24:16,889 ActionQueue.py:363 - Command 55 completed successfully!
INFO 2017-06-06 14:24:16,890 ActionQueue.py:379 - Begin command output log for command with id = 55, role = TEZ_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:16,892 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 1/14 of log for command: 
2017-06-06 14:23:55,519 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:55,540 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:55,540 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:55,540 - FS Type: 
2017-06-06 14:23:55,558 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:55,685 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:55,718 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:23:58,878 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:58,960 - Node has all packages pre-installed. Skipping.
2017-06-06 14:23:58,960 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:23:58,960 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:23:58,984 - Directory['/etc/tez'] {'mode': 0755}
2017-06-06 14:23:58,999 - Directory['/etc/tez/conf'] {'owner': 'tez', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:23:59,006 - Changing owner for /etc/tez/conf from 0 to tez
2017-06-06 14:23:59,010 - Changing group for /etc/tez/conf from 0 to hadoop
2017-06-06 14:23:59,010 - XmlConfig['tez-site.xml'] {'group': 'hadoop', 'conf_dir': '/etc/tez/conf', 'mode': 0664, 'configuration_attributes': {}, 'owner': 'tez', 'configurations': ...}
2017-06-06 14:23:59,236 - Generating config: /etc/tez/conf/tez-site.xml
2017-06-06 14:23:59,236 - File['/etc/tez/conf/tez-site.xml'] {'owner': 'tez', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0664, 'encoding': 'UTF-8'}
2017-06-06 14:23:59,903 - Writing File['/etc/tez/conf/tez-site.xml'] because it doesn't exist
2017-06-06 14:23:59,909 - Changing owner for /etc/tez/conf/tez-site.xml from 0 to tez
2017-06-06 14:23:59,913 - Changing group for /etc/tez/conf/tez-site.xml from 0 to hadoop
2017-06-06 14:23:59,914 - Changing permission for /etc/tez/conf/tez-site.xml from 644 to 664
2017-06-06 14:23:59,929 - File['/etc/tez/conf/tez-env.sh'] {'content': InlineTemplate(...), 'owner': 'tez', 'mode': 0555}
2017-06-06 14:23:59,931 - Writing File['/etc/tez/conf/tez-env.sh'] because it doesn't exist
2017-06-06 14:23:59,936 - Changing owner for /etc/tez/conf/tez-env.sh from 0 to tez
2017-06-06 14:23:59,936 - Changing permission for /etc/tez/conf/tez-env.sh from 644 to 555
2017-06-06 14:23:59,936 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:02,863 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:02,868 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:02,869 - FS Type: 
2017-06-06 14:24:02,869 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:03,021 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:03,022 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:03,121 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:05,074 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:05,075 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:05,079 - Backing up /etc/ranger/kms/conf to /etc/ranger/kms/conf.backup if destination doesn't exist already.
2017-06-06 14:24:05,080 - Execute[('cp', '-R', '-p', '/etc/ranger/kms/conf', '/etc/ranger/kms/conf.backup')] {'not_if': 'test -e /etc/ranger/kms/conf.backup', 'sudo': True}
2017-06-06 14:24:05,127 - Checking if need to create versioned conf dir /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:05,132 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'ranger-kms', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:05,226 - call returned (0, '/etc/ranger-kms/2.5.4.2-7/0', '')
2017-06-06 14:24:05,226 - Package ranger-kms will have new conf directories: /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:05,226 - Checking if need to create versioned conf dir /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:05,231 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-kms', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:05,353 - call returned (0, '/etc/ranger-kms/2.5.4.2-7/0', '')
2017-06-06 14:24:05,354 - Directory['/etc/ranger-kms/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:05,355 - Seeding versioned configuration directories for ranger-kms
2017-06-06 14:24:05,356 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/ranger-kms/conf/* /etc/ranger-kms/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/ranger-kms/conf/dbks-site.xml' -> '/etc/ranger-kms/2.5.4.2-7/0/dbks-site.xml'
'/usr/hdp/current/ranger-kms/conf/kms-log4j.properties' -> '/etc/ranger-kms/2.5.4.2-7/0/kms-log4j.properties'
'/usr/hdp/current/ranger-kms/conf/kms-site.xml' -> '/etc/ranger-kms/2.5.4.2-7/0/kms-site.xml'
'/usr/hdp/current/ranger-kms/conf/ranger-kms-site.xml' -> '/etc/ranger-kms/2.5.4.2-7/0/ranger-kms-site.xml'
2017-06-06 14:24:05,384 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/ranger/kms/conf/* /etc/ranger-kms/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/ranger/kms/conf/*'}
2017-06-06 14:24:05,486 - Checking if need to create versioned conf dir /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:05,496 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-kms', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:05,633 - call returned (1, '/etc/ranger-kms/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:05,635 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'ranger-kms', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:05,787 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/ranger-kms/conf -> /etc/ranger-kms/2.5.4.2-7/0')
2017-06-06 14:24:05,788 - Ensuring that ranger-kms has the correct symlink structure
2017-06-06 14:24:05,794 - Execute[('cp', '-R', '-p', '/etc/ranger/kms/conf', '/etc/ranger/kms/conf.backup')] {'not_if': 'test -e /etc/ranger/kms/conf.backup', 'sudo': True}
2017-06-06 14:24:05,839 - Skipping Execute[('cp', '-R', '-p', '/etc/ranger/kms/conf', '/etc/ranger/kms/conf.backup')] due to not_if
2017-06-06 14:24:05,839 - Directory['/etc/ranger/kms/conf'] {'action': ['delete']}
2017-06-06 14:24:05,839 - Removing directory Directory['/etc/ranger/kms/conf'] and all its content
2017-06-06 14:24:05,842 - Link['/etc/ranger/kms/conf'] {'to': '/etc/ranger/kms/conf.backup'}
2017-06-06 14:24:05,842 - Creating symbolic Link['/etc/ranger/kms/conf'] to /etc/ranger/kms/conf.backup
2017-06-06 14:24:05,842 - Link['/etc/ranger/kms/conf'] {'action': ['delete']}
2017-06-06 14:24:05,843 - Deleting Link['/etc/ranger/kms/conf']
2017-06-06 14:24:05,843 - Link['/etc/ranger/kms/conf'] {'to': '/usr/hdp/current/ranger-kms/conf'}
INFO 2017-06-06 14:24:16,895 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 2/14 of log for command: 
2017-06-06 14:24:05,843 - Creating symbolic Link['/etc/ranger/kms/conf'] to /usr/hdp/current/ranger-kms/conf
2017-06-06 14:24:05,913 - Backing up /etc/hive2/conf to /etc/hive2/conf.backup if destination doesn't exist already.
2017-06-06 14:24:05,914 - Execute[('cp', '-R', '-p', '/etc/hive2/conf', '/etc/hive2/conf.backup')] {'not_if': 'test -e /etc/hive2/conf.backup', 'sudo': True}
2017-06-06 14:24:06,353 - Checking if need to create versioned conf dir /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:06,360 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'hive2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:06,400 - call returned (0, '/etc/hive2/2.5.4.2-7/0', '')
2017-06-06 14:24:06,401 - Package hive2 will have new conf directories: /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:06,401 - Checking if need to create versioned conf dir /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:06,407 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hive2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:06,744 - call returned (0, '/etc/hive2/2.5.4.2-7/0', '')
2017-06-06 14:24:06,745 - Directory['/etc/hive2/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:06,746 - Seeding versioned configuration directories for hive2
2017-06-06 14:24:06,746 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/hive-server2-hive2/conf/* /etc/hive2/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/hive-server2-hive2/conf/beeline-log4j2.properties.template' -> '/etc/hive2/2.5.4.2-7/0/beeline-log4j2.properties.template'
'/usr/hdp/current/hive-server2-hive2/conf/hive-default.xml.template' -> '/etc/hive2/2.5.4.2-7/0/hive-default.xml.template'
'/usr/hdp/current/hive-server2-hive2/conf/hive-env.sh.template' -> '/etc/hive2/2.5.4.2-7/0/hive-env.sh.template'
'/usr/hdp/current/hive-server2-hive2/conf/hive-exec-log4j2.properties.template' -> '/etc/hive2/2.5.4.2-7/0/hive-exec-log4j2.properties.template'
'/usr/hdp/current/hive-server2-hive2/conf/hive-log4j2.properties.template' -> '/etc/hive2/2.5.4.2-7/0/hive-log4j2.properties.template'
'/usr/hdp/current/hive-server2-hive2/conf/hive-site.xml' -> '/etc/hive2/2.5.4.2-7/0/hive-site.xml'
'/usr/hdp/current/hive-server2-hive2/conf/ivysettings.xml' -> '/etc/hive2/2.5.4.2-7/0/ivysettings.xml'
'/usr/hdp/current/hive-server2-hive2/conf/llap-cli-log4j2.properties.template' -> '/etc/hive2/2.5.4.2-7/0/llap-cli-log4j2.properties.template'
'/usr/hdp/current/hive-server2-hive2/conf/llap-daemon-log4j2.properties.template' -> '/etc/hive2/2.5.4.2-7/0/llap-daemon-log4j2.properties.template'
'/usr/hdp/current/hive-server2-hive2/conf/parquet-logging.properties' -> '/etc/hive2/2.5.4.2-7/0/parquet-logging.properties'
2017-06-06 14:24:06,763 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/hive2/conf/* /etc/hive2/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/hive2/conf/*'}
2017-06-06 14:24:06,792 - Checking if need to create versioned conf dir /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:06,797 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hive2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:06,842 - call returned (1, '/etc/hive2/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:06,843 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hive2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:06,889 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/hive2/conf -> /etc/hive2/2.5.4.2-7/0')
2017-06-06 14:24:06,891 - Ensuring that hive2 has the correct symlink structure
2017-06-06 14:24:06,892 - Execute[('cp', '-R', '-p', '/etc/hive2/conf', '/etc/hive2/conf.backup')] {'not_if': 'test -e /etc/hive2/conf.backup', 'sudo': True}
2017-06-06 14:24:06,897 - Skipping Execute[('cp', '-R', '-p', '/etc/hive2/conf', '/etc/hive2/conf.backup')] due to not_if
2017-06-06 14:24:06,898 - Directory['/etc/hive2/conf'] {'action': ['delete']}
2017-06-06 14:24:06,898 - Removing directory Directory['/etc/hive2/conf'] and all its content
2017-06-06 14:24:06,899 - Link['/etc/hive2/conf'] {'to': '/etc/hive2/conf.backup'}
2017-06-06 14:24:06,899 - Creating symbolic Link['/etc/hive2/conf'] to /etc/hive2/conf.backup
2017-06-06 14:24:06,900 - Link['/etc/hive2/conf'] {'action': ['delete']}
2017-06-06 14:24:06,900 - Deleting Link['/etc/hive2/conf']
2017-06-06 14:24:06,900 - Link['/etc/hive2/conf'] {'to': '/usr/hdp/current/hive-server2-hive2/conf'}
2017-06-06 14:24:06,900 - Creating symbolic Link['/etc/hive2/conf'] to /usr/hdp/current/hive-server2-hive2/conf
2017-06-06 14:24:06,901 - Backing up /etc/zookeeper/conf to /etc/zookeeper/conf.backup if destination doesn't exist already.
2017-06-06 14:24:06,901 - Execute[('cp', '-R', '-p', '/etc/zookeeper/conf', '/etc/zookeeper/conf.backup')] {'not_if': 'test -e /etc/zookeeper/conf.backup', 'sudo': True}
2017-06-06 14:24:07,037 - Checking if need to create versioned conf dir /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:07,043 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'zookeeper', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:07,087 - call returned (0, '/etc/zookeeper/2.5.4.2-7/0', '')
2017-06-06 14:24:07,087 - Package zookeeper will have new conf directories: /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:07,087 - Checking if need to create versioned conf dir /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:07,092 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'zookeeper', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:07,136 - call returned (0, '/etc/zookeeper/2.5.4.2-7/0', '')
2017-06-06 14:24:07,136 - Directory['/etc/zookeeper/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:07,138 - Seeding versioned configuration directories for zookeeper
2017-06-06 14:24:07,138 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/zookeeper-client/conf/* /etc/zookeeper/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/zookeeper-client/conf/configuration.xsl' -> '/etc/zookeeper/2.5.4.2-7/0/configuration.xsl'
'/usr/hdp/current/zookeeper-client/conf/log4j.properties' -> '/etc/zookeeper/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/zookeeper-client/conf/zoo.cfg' -> '/etc/zookeeper/2.5.4.2-7/0/zoo.cfg'
'/usr/hdp/current/zookeeper-client/conf/zoo_sample.cfg' -> '/etc/zookeeper/2.5.4.2-7/0/zoo_sample.cfg'
'/usr/hdp/current/zookeeper-client/conf/zookeeper-env.cmd' -> '/etc/zookeeper/2.5.4.2-7/0/zookeeper-env.cmd'
'/usr/hdp/current/zookeeper-client/conf/zookeeper-env.sh' -> '/etc/zookeeper/2.5.4.2-7/0/zookeeper-env.sh'
2017-06-06 14:24:07,151 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/zookeeper/conf/* /etc/zookeeper/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/zookeeper/conf/*'}
2017-06-06 14:24:07,172 - Checking if need to create versioned conf dir /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:07,179 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'zookeeper', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:07,224 - call returned (1, '/etc/zookeeper/2.5.4.2-7/0 exist already', '')
INFO 2017-06-06 14:24:16,897 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 3/14 of log for command: 
2017-06-06 14:24:07,224 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'zookeeper', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:07,264 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/zookeeper/conf -> /etc/zookeeper/2.5.4.2-7/0')
2017-06-06 14:24:07,266 - Ensuring that zookeeper has the correct symlink structure
2017-06-06 14:24:07,267 - Execute[('cp', '-R', '-p', '/etc/zookeeper/conf', '/etc/zookeeper/conf.backup')] {'not_if': 'test -e /etc/zookeeper/conf.backup', 'sudo': True}
2017-06-06 14:24:07,272 - Skipping Execute[('cp', '-R', '-p', '/etc/zookeeper/conf', '/etc/zookeeper/conf.backup')] due to not_if
2017-06-06 14:24:07,273 - Directory['/etc/zookeeper/conf'] {'action': ['delete']}
2017-06-06 14:24:07,273 - Removing directory Directory['/etc/zookeeper/conf'] and all its content
2017-06-06 14:24:07,274 - Link['/etc/zookeeper/conf'] {'to': '/etc/zookeeper/conf.backup'}
2017-06-06 14:24:07,274 - Creating symbolic Link['/etc/zookeeper/conf'] to /etc/zookeeper/conf.backup
2017-06-06 14:24:07,274 - Link['/etc/zookeeper/conf'] {'action': ['delete']}
2017-06-06 14:24:07,275 - Deleting Link['/etc/zookeeper/conf']
2017-06-06 14:24:07,275 - Link['/etc/zookeeper/conf'] {'to': '/usr/hdp/current/zookeeper-client/conf'}
2017-06-06 14:24:07,275 - Creating symbolic Link['/etc/zookeeper/conf'] to /usr/hdp/current/zookeeper-client/conf
2017-06-06 14:24:07,276 - Backing up /etc/kafka/conf to /etc/kafka/conf.backup if destination doesn't exist already.
2017-06-06 14:24:07,276 - Execute[('cp', '-R', '-p', '/etc/kafka/conf', '/etc/kafka/conf.backup')] {'not_if': 'test -e /etc/kafka/conf.backup', 'sudo': True}
2017-06-06 14:24:07,614 - Checking if need to create versioned conf dir /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:07,619 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'kafka', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:07,665 - call returned (0, '/etc/kafka/2.5.4.2-7/0', '')
2017-06-06 14:24:07,665 - Package kafka will have new conf directories: /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:07,665 - Checking if need to create versioned conf dir /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:07,670 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'kafka', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:07,754 - call returned (0, '/etc/kafka/2.5.4.2-7/0', '')
2017-06-06 14:24:07,755 - Directory['/etc/kafka/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:07,756 - Seeding versioned configuration directories for kafka
2017-06-06 14:24:07,756 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/kafka-broker/conf/* /etc/kafka/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/kafka-broker/conf/connect-console-sink.properties' -> '/etc/kafka/2.5.4.2-7/0/connect-console-sink.properties'
'/usr/hdp/current/kafka-broker/conf/connect-console-source.properties' -> '/etc/kafka/2.5.4.2-7/0/connect-console-source.properties'
'/usr/hdp/current/kafka-broker/conf/connect-distributed.properties' -> '/etc/kafka/2.5.4.2-7/0/connect-distributed.properties'
'/usr/hdp/current/kafka-broker/conf/connect-file-sink.properties' -> '/etc/kafka/2.5.4.2-7/0/connect-file-sink.properties'
'/usr/hdp/current/kafka-broker/conf/connect-file-source.properties' -> '/etc/kafka/2.5.4.2-7/0/connect-file-source.properties'
'/usr/hdp/current/kafka-broker/conf/connect-log4j.properties' -> '/etc/kafka/2.5.4.2-7/0/connect-log4j.properties'
'/usr/hdp/current/kafka-broker/conf/connect-standalone.properties' -> '/etc/kafka/2.5.4.2-7/0/connect-standalone.properties'
'/usr/hdp/current/kafka-broker/conf/consumer.properties' -> '/etc/kafka/2.5.4.2-7/0/consumer.properties'
'/usr/hdp/current/kafka-broker/conf/kafka-env.sh' -> '/etc/kafka/2.5.4.2-7/0/kafka-env.sh'
'/usr/hdp/current/kafka-broker/conf/kafka_client_jaas.conf' -> '/etc/kafka/2.5.4.2-7/0/kafka_client_jaas.conf'
'/usr/hdp/current/kafka-broker/conf/log4j.properties' -> '/etc/kafka/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/kafka-broker/conf/producer.properties' -> '/etc/kafka/2.5.4.2-7/0/producer.properties'
'/usr/hdp/current/kafka-broker/conf/server.properties' -> '/etc/kafka/2.5.4.2-7/0/server.properties'
'/usr/hdp/current/kafka-broker/conf/test-log4j.properties' -> '/etc/kafka/2.5.4.2-7/0/test-log4j.properties'
'/usr/hdp/current/kafka-broker/conf/tools-log4j.properties' -> '/etc/kafka/2.5.4.2-7/0/tools-log4j.properties'
'/usr/hdp/current/kafka-broker/conf/zookeeper.properties' -> '/etc/kafka/2.5.4.2-7/0/zookeeper.properties'
2017-06-06 14:24:07,781 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/kafka/conf/* /etc/kafka/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/kafka/conf/*'}
2017-06-06 14:24:07,803 - Checking if need to create versioned conf dir /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:07,807 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'kafka', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:07,865 - call returned (1, '/etc/kafka/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:07,866 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'kafka', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:07,908 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/kafka/conf -> /etc/kafka/2.5.4.2-7/0')
2017-06-06 14:24:07,909 - Ensuring that kafka has the correct symlink structure
2017-06-06 14:24:07,909 - Execute[('cp', '-R', '-p', '/etc/kafka/conf', '/etc/kafka/conf.backup')] {'not_if': 'test -e /etc/kafka/conf.backup', 'sudo': True}
2017-06-06 14:24:07,915 - Skipping Execute[('cp', '-R', '-p', '/etc/kafka/conf', '/etc/kafka/conf.backup')] due to not_if
2017-06-06 14:24:07,915 - Directory['/etc/kafka/conf'] {'action': ['delete']}
2017-06-06 14:24:07,915 - Removing directory Directory['/etc/kafka/conf'] and all its content
2017-06-06 14:24:07,929 - Link['/etc/kafka/conf'] {'to': '/etc/kafka/conf.backup'}
2017-06-06 14:24:07,929 - Creating symbolic Link['/etc/kafka/conf'] to /etc/kafka/conf.backup
2017-06-06 14:24:07,929 - Link['/etc/kafka/conf'] {'action': ['delete']}
2017-06-06 14:24:07,930 - Deleting Link['/etc/kafka/conf']
2017-06-06 14:24:07,930 - Link['/etc/kafka/conf'] {'to': '/usr/hdp/current/kafka-broker/conf'}
2017-06-06 14:24:07,930 - Creating symbolic Link['/etc/kafka/conf'] to /usr/hdp/current/kafka-broker/conf
2017-06-06 14:24:07,932 - Backing up /etc/tez/conf to /etc/tez/conf.backup if destination doesn't exist already.
2017-06-06 14:24:07,933 - Execute[('cp', '-R', '-p', '/etc/tez/conf', '/etc/tez/conf.backup')] {'not_if': 'test -e /etc/tez/conf.backup', 'sudo': True}
2017-06-06 14:24:07,946 - Checking if need to create versioned conf dir /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:07,950 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'tez', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:08,001 - call returned (0, '/etc/tez/2.5.4.2-7/0', '')
2017-06-06 14:24:08,001 - Package tez will have new conf directories: /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:08,001 - Checking if need to create versioned conf dir /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:08,006 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'tez', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
INFO 2017-06-06 14:24:16,899 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 4/14 of log for command: 
2017-06-06 14:24:08,072 - call returned (0, '/etc/tez/2.5.4.2-7/0', '')
2017-06-06 14:24:08,073 - Directory['/etc/tez/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:08,075 - Seeding versioned configuration directories for tez
2017-06-06 14:24:08,075 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/tez-client/conf/* /etc/tez/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/tez-client/conf/tez-env.sh' -> '/etc/tez/2.5.4.2-7/0/tez-env.sh'
'/usr/hdp/current/tez-client/conf/tez-site.xml' -> '/etc/tez/2.5.4.2-7/0/tez-site.xml'
2017-06-06 14:24:08,103 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/tez/conf/* /etc/tez/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/tez/conf/*'}
2017-06-06 14:24:08,124 - Checking if need to create versioned conf dir /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:08,129 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'tez', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:08,176 - call returned (1, '/etc/tez/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:08,177 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'tez', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:08,218 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/tez/conf -> /etc/tez/2.5.4.2-7/0')
2017-06-06 14:24:08,219 - Ensuring that tez has the correct symlink structure
2017-06-06 14:24:08,219 - Execute[('cp', '-R', '-p', '/etc/tez/conf', '/etc/tez/conf.backup')] {'not_if': 'test -e /etc/tez/conf.backup', 'sudo': True}
2017-06-06 14:24:08,224 - Skipping Execute[('cp', '-R', '-p', '/etc/tez/conf', '/etc/tez/conf.backup')] due to not_if
2017-06-06 14:24:08,225 - Directory['/etc/tez/conf'] {'action': ['delete']}
2017-06-06 14:24:08,225 - Removing directory Directory['/etc/tez/conf'] and all its content
2017-06-06 14:24:08,226 - Link['/etc/tez/conf'] {'to': '/etc/tez/conf.backup'}
2017-06-06 14:24:08,226 - Creating symbolic Link['/etc/tez/conf'] to /etc/tez/conf.backup
2017-06-06 14:24:08,227 - Link['/etc/tez/conf'] {'action': ['delete']}
2017-06-06 14:24:08,227 - Deleting Link['/etc/tez/conf']
2017-06-06 14:24:08,227 - Link['/etc/tez/conf'] {'to': '/usr/hdp/current/tez-client/conf'}
2017-06-06 14:24:08,228 - Creating symbolic Link['/etc/tez/conf'] to /usr/hdp/current/tez-client/conf
2017-06-06 14:24:08,252 - Backing up /etc/oozie/conf to /etc/oozie/conf.backup if destination doesn't exist already.
2017-06-06 14:24:08,253 - Execute[('cp', '-R', '-p', '/etc/oozie/conf', '/etc/oozie/conf.backup')] {'not_if': 'test -e /etc/oozie/conf.backup', 'sudo': True}
2017-06-06 14:24:08,876 - Checking if need to create versioned conf dir /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:08,881 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'oozie', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:08,927 - call returned (0, '/etc/oozie/2.5.4.2-7/0', '')
2017-06-06 14:24:08,928 - Package oozie will have new conf directories: /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:08,928 - Checking if need to create versioned conf dir /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:08,940 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'oozie', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:08,979 - call returned (0, '/etc/oozie/2.5.4.2-7/0', '')
2017-06-06 14:24:08,979 - Directory['/etc/oozie/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:08,981 - Seeding versioned configuration directories for oozie
2017-06-06 14:24:08,981 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/oozie-client/conf/* /etc/oozie/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/oozie-client/conf/action-conf' -> '/etc/oozie/2.5.4.2-7/0/action-conf'
'/usr/hdp/current/oozie-client/conf/action-conf/hive.xml' -> '/etc/oozie/2.5.4.2-7/0/action-conf/hive.xml'
'/usr/hdp/current/oozie-client/conf/adminusers.txt' -> '/etc/oozie/2.5.4.2-7/0/adminusers.txt'
'/usr/hdp/current/oozie-client/conf/hadoop-conf' -> '/etc/oozie/2.5.4.2-7/0/hadoop-conf'
'/usr/hdp/current/oozie-client/conf/hadoop-conf/core-site.xml' -> '/etc/oozie/2.5.4.2-7/0/hadoop-conf/core-site.xml'
'/usr/hdp/current/oozie-client/conf/hadoop-config.xml' -> '/etc/oozie/2.5.4.2-7/0/hadoop-config.xml'
'/usr/hdp/current/oozie-client/conf/oozie-default.xml.reference' -> '/etc/oozie/2.5.4.2-7/0/oozie-default.xml.reference'
'/usr/hdp/current/oozie-client/conf/oozie-env.cmd' -> '/etc/oozie/2.5.4.2-7/0/oozie-env.cmd'
'/usr/hdp/current/oozie-client/conf/oozie-env.sh' -> '/etc/oozie/2.5.4.2-7/0/oozie-env.sh'
'/usr/hdp/current/oozie-client/conf/oozie-log4j.properties' -> '/etc/oozie/2.5.4.2-7/0/oozie-log4j.properties'
'/usr/hdp/current/oozie-client/conf/oozie-site.xml' -> '/etc/oozie/2.5.4.2-7/0/oozie-site.xml'
2017-06-06 14:24:09,049 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/oozie/conf/* /etc/oozie/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/oozie/conf/*'}
2017-06-06 14:24:09,080 - Checking if need to create versioned conf dir /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:09,084 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'oozie', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:09,129 - call returned (1, '/etc/oozie/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:09,129 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'oozie', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:09,168 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/oozie/conf -> /etc/oozie/2.5.4.2-7/0')
2017-06-06 14:24:09,169 - Ensuring that oozie has the correct symlink structure
2017-06-06 14:24:09,170 - Execute[('cp', '-R', '-p', '/etc/oozie/conf', '/etc/oozie/conf.backup')] {'not_if': 'test -e /etc/oozie/conf.backup', 'sudo': True}
2017-06-06 14:24:09,175 - Skipping Execute[('cp', '-R', '-p', '/etc/oozie/conf', '/etc/oozie/conf.backup')] due to not_if
2017-06-06 14:24:09,176 - Directory['/etc/oozie/conf'] {'action': ['delete']}
2017-06-06 14:24:09,176 - Removing directory Directory['/etc/oozie/conf'] and all its content
2017-06-06 14:24:09,241 - Link['/etc/oozie/conf'] {'to': '/etc/oozie/conf.backup'}
2017-06-06 14:24:09,241 - Creating symbolic Link['/etc/oozie/conf'] to /etc/oozie/conf.backup
2017-06-06 14:24:09,242 - Link['/etc/oozie/conf'] {'action': ['delete']}
2017-06-06 14:24:09,242 - Deleting Link['/etc/oozie/conf']
2017-06-06 14:24:09,242 - Link['/etc/oozie/conf'] {'to': '/usr/hdp/current/oozie-client/conf'}
2017-06-06 14:24:09,243 - Creating symbolic Link['/etc/oozie/conf'] to /usr/hdp/current/oozie-client/conf
2017-06-06 14:24:09,243 - Backing up /etc/hbase/conf to /etc/hbase/conf.backup if destination doesn't exist already.
2017-06-06 14:24:09,244 - Execute[('cp', '-R', '-p', '/etc/hbase/conf', '/etc/hbase/conf.backup')] {'not_if': 'test -e /etc/hbase/conf.backup', 'sudo': True}
2017-06-06 14:24:09,370 - Checking if need to create versioned conf dir /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:09,375 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'hbase', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:09,412 - call returned (0, '/etc/hbase/2.5.4.2-7/0', '')
2017-06-06 14:24:09,413 - Package hbase will have new conf directories: /etc/hbase/2.5.4.2-7/0
INFO 2017-06-06 14:24:16,901 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 5/14 of log for command: 
2017-06-06 14:24:09,413 - Checking if need to create versioned conf dir /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:09,417 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hbase', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:09,461 - call returned (0, '/etc/hbase/2.5.4.2-7/0', '')
2017-06-06 14:24:09,462 - Directory['/etc/hbase/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:09,463 - Seeding versioned configuration directories for hbase
2017-06-06 14:24:09,464 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/hbase-client/conf/* /etc/hbase/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/hbase-client/conf/hadoop-metrics2-hbase.properties' -> '/etc/hbase/2.5.4.2-7/0/hadoop-metrics2-hbase.properties'
'/usr/hdp/current/hbase-client/conf/hbase-env.cmd' -> '/etc/hbase/2.5.4.2-7/0/hbase-env.cmd'
'/usr/hdp/current/hbase-client/conf/hbase-env.sh' -> '/etc/hbase/2.5.4.2-7/0/hbase-env.sh'
'/usr/hdp/current/hbase-client/conf/hbase-policy.xml' -> '/etc/hbase/2.5.4.2-7/0/hbase-policy.xml'
'/usr/hdp/current/hbase-client/conf/hbase-site.xml' -> '/etc/hbase/2.5.4.2-7/0/hbase-site.xml'
'/usr/hdp/current/hbase-client/conf/log4j.properties' -> '/etc/hbase/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/hbase-client/conf/regionservers' -> '/etc/hbase/2.5.4.2-7/0/regionservers'
2017-06-06 14:24:09,490 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/hbase/conf/* /etc/hbase/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/hbase/conf/*'}
2017-06-06 14:24:09,511 - Checking if need to create versioned conf dir /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:09,517 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hbase', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:09,557 - call returned (1, '/etc/hbase/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:09,558 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hbase', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:09,602 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/hbase/conf -> /etc/hbase/2.5.4.2-7/0')
2017-06-06 14:24:09,603 - Ensuring that hbase has the correct symlink structure
2017-06-06 14:24:09,604 - Execute[('cp', '-R', '-p', '/etc/hbase/conf', '/etc/hbase/conf.backup')] {'not_if': 'test -e /etc/hbase/conf.backup', 'sudo': True}
2017-06-06 14:24:09,619 - Skipping Execute[('cp', '-R', '-p', '/etc/hbase/conf', '/etc/hbase/conf.backup')] due to not_if
2017-06-06 14:24:09,619 - Directory['/etc/hbase/conf'] {'action': ['delete']}
2017-06-06 14:24:09,620 - Removing directory Directory['/etc/hbase/conf'] and all its content
2017-06-06 14:24:09,624 - Link['/etc/hbase/conf'] {'to': '/etc/hbase/conf.backup'}
2017-06-06 14:24:09,624 - Creating symbolic Link['/etc/hbase/conf'] to /etc/hbase/conf.backup
2017-06-06 14:24:09,624 - Link['/etc/hbase/conf'] {'action': ['delete']}
2017-06-06 14:24:09,625 - Deleting Link['/etc/hbase/conf']
2017-06-06 14:24:09,625 - Link['/etc/hbase/conf'] {'to': '/usr/hdp/current/hbase-client/conf'}
2017-06-06 14:24:09,625 - Creating symbolic Link['/etc/hbase/conf'] to /usr/hdp/current/hbase-client/conf
2017-06-06 14:24:09,627 - Backing up /etc/spark/conf to /etc/spark/conf.backup if destination doesn't exist already.
2017-06-06 14:24:09,627 - Execute[('cp', '-R', '-p', '/etc/spark/conf', '/etc/spark/conf.backup')] {'not_if': 'test -e /etc/spark/conf.backup', 'sudo': True}
2017-06-06 14:24:09,873 - Checking if need to create versioned conf dir /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:09,879 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'spark', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:09,918 - call returned (0, '/etc/spark/2.5.4.2-7/0', '')
2017-06-06 14:24:09,919 - Package spark will have new conf directories: /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:09,919 - Checking if need to create versioned conf dir /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:09,926 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'spark', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:09,970 - call returned (0, '/etc/spark/2.5.4.2-7/0', '')
2017-06-06 14:24:09,971 - Directory['/etc/spark/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:09,973 - Seeding versioned configuration directories for spark
2017-06-06 14:24:09,973 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/spark-client/conf/* /etc/spark/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/spark-client/conf/docker.properties.template' -> '/etc/spark/2.5.4.2-7/0/docker.properties.template'
'/usr/hdp/current/spark-client/conf/fairscheduler.xml.template' -> '/etc/spark/2.5.4.2-7/0/fairscheduler.xml.template'
'/usr/hdp/current/spark-client/conf/log4j.properties.template' -> '/etc/spark/2.5.4.2-7/0/log4j.properties.template'
'/usr/hdp/current/spark-client/conf/metrics.properties.template' -> '/etc/spark/2.5.4.2-7/0/metrics.properties.template'
'/usr/hdp/current/spark-client/conf/slaves.template' -> '/etc/spark/2.5.4.2-7/0/slaves.template'
'/usr/hdp/current/spark-client/conf/spark-defaults.conf' -> '/etc/spark/2.5.4.2-7/0/spark-defaults.conf'
'/usr/hdp/current/spark-client/conf/spark-defaults.conf.template' -> '/etc/spark/2.5.4.2-7/0/spark-defaults.conf.template'
'/usr/hdp/current/spark-client/conf/spark-env.sh' -> '/etc/spark/2.5.4.2-7/0/spark-env.sh'
'/usr/hdp/current/spark-client/conf/spark-env.sh.template' -> '/etc/spark/2.5.4.2-7/0/spark-env.sh.template'
2017-06-06 14:24:09,987 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/spark/conf/* /etc/spark/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/spark/conf/*'}
2017-06-06 14:24:10,014 - Checking if need to create versioned conf dir /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:10,019 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'spark', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:10,070 - call returned (1, '/etc/spark/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:10,071 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'spark', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:10,110 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/spark/conf -> /etc/spark/2.5.4.2-7/0')
2017-06-06 14:24:10,111 - Ensuring that spark has the correct symlink structure
2017-06-06 14:24:10,111 - Execute[('cp', '-R', '-p', '/etc/spark/conf', '/etc/spark/conf.backup')] {'not_if': 'test -e /etc/spark/conf.backup', 'sudo': True}
2017-06-06 14:24:10,125 - Skipping Execute[('cp', '-R', '-p', '/etc/spark/conf', '/etc/spark/conf.backup')] due to not_if
2017-06-06 14:24:10,125 - Directory['/etc/spark/conf'] {'action': ['delete']}
2017-06-06 14:24:10,125 - Removing directory Directory['/etc/spark/conf'] and all its content
2017-06-06 14:24:10,127 - Link['/etc/spark/conf'] {'to': '/etc/spark/conf.backup'}
2017-06-06 14:24:10,127 - Creating symbolic Link['/etc/spark/conf'] to /etc/spark/conf.backup
2017-06-06 14:24:10,128 - Link['/etc/spark/conf'] {'action': ['delete']}
2017-06-06 14:24:10,128 - Deleting Link['/etc/spark/conf']
2017-06-06 14:24:10,128 - Link['/etc/spark/conf'] {'to': '/usr/hdp/current/spark-client/conf'}
INFO 2017-06-06 14:24:16,903 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 6/14 of log for command: 
2017-06-06 14:24:10,129 - Creating symbolic Link['/etc/spark/conf'] to /usr/hdp/current/spark-client/conf
2017-06-06 14:24:10,135 - Backing up /etc/ranger/tagsync/conf to /etc/ranger/tagsync/conf.backup if destination doesn't exist already.
2017-06-06 14:24:10,136 - Execute[('cp', '-R', '-p', '/etc/ranger/tagsync/conf', '/etc/ranger/tagsync/conf.backup')] {'not_if': 'test -e /etc/ranger/tagsync/conf.backup', 'sudo': True}
2017-06-06 14:24:10,470 - Checking if need to create versioned conf dir /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:10,476 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'ranger-tagsync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:10,515 - call returned (0, '/etc/ranger-tagsync/2.5.4.2-7/0', '')
2017-06-06 14:24:10,516 - Package ranger-tagsync will have new conf directories: /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:10,516 - Checking if need to create versioned conf dir /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:10,526 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-tagsync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:10,565 - call returned (0, '/etc/ranger-tagsync/2.5.4.2-7/0', '')
2017-06-06 14:24:10,566 - Directory['/etc/ranger-tagsync/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:10,568 - Seeding versioned configuration directories for ranger-tagsync
2017-06-06 14:24:10,568 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/ranger-tagsync/conf/* /etc/ranger-tagsync/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/ranger-tagsync/conf/etc' -> '/etc/ranger-tagsync/2.5.4.2-7/0/etc'
'/usr/hdp/current/ranger-tagsync/conf/etc/ranger' -> '/etc/ranger-tagsync/2.5.4.2-7/0/etc/ranger'
'/usr/hdp/current/ranger-tagsync/conf/etc/ranger/data' -> '/etc/ranger-tagsync/2.5.4.2-7/0/etc/ranger/data'
'/usr/hdp/current/ranger-tagsync/conf/etc/ranger/data/tags.json' -> '/etc/ranger-tagsync/2.5.4.2-7/0/etc/ranger/data/tags.json'
'/usr/hdp/current/ranger-tagsync/conf/log4j.properties' -> '/etc/ranger-tagsync/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/ranger-tagsync/conf/log4j.xml' -> '/etc/ranger-tagsync/2.5.4.2-7/0/log4j.xml'
'/usr/hdp/current/ranger-tagsync/conf/ranger-tagsync-env-setup-hadoop-home.sh' -> '/etc/ranger-tagsync/2.5.4.2-7/0/ranger-tagsync-env-setup-hadoop-home.sh'
2017-06-06 14:24:10,581 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/ranger/tagsync/conf/* /etc/ranger-tagsync/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/ranger/tagsync/conf/*'}
2017-06-06 14:24:10,604 - Checking if need to create versioned conf dir /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:10,608 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-tagsync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:10,646 - call returned (1, '/etc/ranger-tagsync/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:10,647 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'ranger-tagsync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:10,711 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/ranger-tagsync/conf -> /etc/ranger-tagsync/2.5.4.2-7/0')
2017-06-06 14:24:10,712 - Ensuring that ranger-tagsync has the correct symlink structure
2017-06-06 14:24:10,712 - Execute[('cp', '-R', '-p', '/etc/ranger/tagsync/conf', '/etc/ranger/tagsync/conf.backup')] {'not_if': 'test -e /etc/ranger/tagsync/conf.backup', 'sudo': True}
2017-06-06 14:24:10,717 - Skipping Execute[('cp', '-R', '-p', '/etc/ranger/tagsync/conf', '/etc/ranger/tagsync/conf.backup')] due to not_if
2017-06-06 14:24:10,717 - Directory['/etc/ranger/tagsync/conf'] {'action': ['delete']}
2017-06-06 14:24:10,718 - Removing directory Directory['/etc/ranger/tagsync/conf'] and all its content
2017-06-06 14:24:10,718 - Link['/etc/ranger/tagsync/conf'] {'to': '/etc/ranger/tagsync/conf.backup'}
2017-06-06 14:24:10,719 - Creating symbolic Link['/etc/ranger/tagsync/conf'] to /etc/ranger/tagsync/conf.backup
2017-06-06 14:24:10,719 - Link['/etc/ranger/tagsync/conf'] {'action': ['delete']}
2017-06-06 14:24:10,719 - Deleting Link['/etc/ranger/tagsync/conf']
2017-06-06 14:24:10,719 - Link['/etc/ranger/tagsync/conf'] {'to': '/usr/hdp/current/ranger-tagsync/conf'}
2017-06-06 14:24:10,720 - Creating symbolic Link['/etc/ranger/tagsync/conf'] to /usr/hdp/current/ranger-tagsync/conf
2017-06-06 14:24:10,720 - Backing up /etc/ranger/usersync/conf to /etc/ranger/usersync/conf.backup if destination doesn't exist already.
2017-06-06 14:24:10,721 - Execute[('cp', '-R', '-p', '/etc/ranger/usersync/conf', '/etc/ranger/usersync/conf.backup')] {'not_if': 'test -e /etc/ranger/usersync/conf.backup', 'sudo': True}
2017-06-06 14:24:10,749 - Checking if need to create versioned conf dir /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:10,755 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'ranger-usersync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:10,801 - call returned (0, '/etc/ranger-usersync/2.5.4.2-7/0', '')
2017-06-06 14:24:10,801 - Package ranger-usersync will have new conf directories: /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:10,807 - Checking if need to create versioned conf dir /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:10,812 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-usersync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:10,849 - call returned (0, '/etc/ranger-usersync/2.5.4.2-7/0', '')
2017-06-06 14:24:10,851 - Directory['/etc/ranger-usersync/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:10,852 - Seeding versioned configuration directories for ranger-usersync
2017-06-06 14:24:10,853 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/ranger-usersync/conf/* /etc/ranger-usersync/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/ranger-usersync/conf/log4j.properties' -> '/etc/ranger-usersync/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/ranger-usersync/conf/log4j.xml' -> '/etc/ranger-usersync/2.5.4.2-7/0/log4j.xml'
'/usr/hdp/current/ranger-usersync/conf/ranger-ugsync-default.xml' -> '/etc/ranger-usersync/2.5.4.2-7/0/ranger-ugsync-default.xml'
2017-06-06 14:24:10,865 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/ranger/usersync/conf/* /etc/ranger-usersync/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/ranger/usersync/conf/*'}
2017-06-06 14:24:10,885 - Checking if need to create versioned conf dir /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:10,889 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-usersync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:10,929 - call returned (1, '/etc/ranger-usersync/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:10,930 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'ranger-usersync', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:10,974 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/ranger-usersync/conf -> /etc/ranger-usersync/2.5.4.2-7/0')
INFO 2017-06-06 14:24:16,905 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 7/14 of log for command: 
2017-06-06 14:24:10,976 - Ensuring that ranger-usersync has the correct symlink structure
2017-06-06 14:24:10,977 - Execute[('cp', '-R', '-p', '/etc/ranger/usersync/conf', '/etc/ranger/usersync/conf.backup')] {'not_if': 'test -e /etc/ranger/usersync/conf.backup', 'sudo': True}
2017-06-06 14:24:10,981 - Skipping Execute[('cp', '-R', '-p', '/etc/ranger/usersync/conf', '/etc/ranger/usersync/conf.backup')] due to not_if
2017-06-06 14:24:10,981 - Directory['/etc/ranger/usersync/conf'] {'action': ['delete']}
2017-06-06 14:24:10,982 - Removing directory Directory['/etc/ranger/usersync/conf'] and all its content
2017-06-06 14:24:10,982 - Link['/etc/ranger/usersync/conf'] {'to': '/etc/ranger/usersync/conf.backup'}
2017-06-06 14:24:10,982 - Creating symbolic Link['/etc/ranger/usersync/conf'] to /etc/ranger/usersync/conf.backup
2017-06-06 14:24:10,983 - Link['/etc/ranger/usersync/conf'] {'action': ['delete']}
2017-06-06 14:24:10,983 - Deleting Link['/etc/ranger/usersync/conf']
2017-06-06 14:24:10,983 - Link['/etc/ranger/usersync/conf'] {'to': '/usr/hdp/current/ranger-usersync/conf'}
2017-06-06 14:24:10,983 - Creating symbolic Link['/etc/ranger/usersync/conf'] to /usr/hdp/current/ranger-usersync/conf
2017-06-06 14:24:10,983 - Backing up /etc/hadoop/conf to /etc/hadoop/conf.backup if destination doesn't exist already.
2017-06-06 14:24:10,984 - Execute[('cp', '-R', '-p', '/etc/hadoop/conf', '/etc/hadoop/conf.backup')] {'not_if': 'test -e /etc/hadoop/conf.backup', 'sudo': True}
2017-06-06 14:24:11,216 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:11,220 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'hadoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:11,264 - call returned (0, '/etc/hadoop/2.5.4.2-7/0', '')
2017-06-06 14:24:11,264 - Package hadoop will have new conf directories: /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:11,265 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:11,269 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:11,313 - call returned (0, '/etc/hadoop/2.5.4.2-7/0', '')
2017-06-06 14:24:11,314 - Directory['/etc/hadoop/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:11,316 - Seeding versioned configuration directories for hadoop
2017-06-06 14:24:11,316 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/hadoop-client/conf/* /etc/hadoop/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml' -> '/etc/hadoop/2.5.4.2-7/0/capacity-scheduler.xml'
'/usr/hdp/current/hadoop-client/conf/configuration.xsl' -> '/etc/hadoop/2.5.4.2-7/0/configuration.xsl'
'/usr/hdp/current/hadoop-client/conf/container-executor.cfg' -> '/etc/hadoop/2.5.4.2-7/0/container-executor.cfg'
'/usr/hdp/current/hadoop-client/conf/core-site.xml' -> '/etc/hadoop/2.5.4.2-7/0/core-site.xml'
'/usr/hdp/current/hadoop-client/conf/hadoop-env.sh' -> '/etc/hadoop/2.5.4.2-7/0/hadoop-env.sh'
'/usr/hdp/current/hadoop-client/conf/hadoop-metrics.properties' -> '/etc/hadoop/2.5.4.2-7/0/hadoop-metrics.properties'
'/usr/hdp/current/hadoop-client/conf/hadoop-metrics2-adl-file-system.properties' -> '/etc/hadoop/2.5.4.2-7/0/hadoop-metrics2-adl-file-system.properties'
'/usr/hdp/current/hadoop-client/conf/hadoop-metrics2-azure-file-system.properties' -> '/etc/hadoop/2.5.4.2-7/0/hadoop-metrics2-azure-file-system.properties'
'/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties' -> '/etc/hadoop/2.5.4.2-7/0/hadoop-metrics2.properties'
'/usr/hdp/current/hadoop-client/conf/hadoop-policy.xml' -> '/etc/hadoop/2.5.4.2-7/0/hadoop-policy.xml'
'/usr/hdp/current/hadoop-client/conf/hdfs-site.xml' -> '/etc/hadoop/2.5.4.2-7/0/hdfs-site.xml'
'/usr/hdp/current/hadoop-client/conf/log4j.properties' -> '/etc/hadoop/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/hadoop-client/conf/mapred-env.sh' -> '/etc/hadoop/2.5.4.2-7/0/mapred-env.sh'
'/usr/hdp/current/hadoop-client/conf/mapred-queues.xml.template' -> '/etc/hadoop/2.5.4.2-7/0/mapred-queues.xml.template'
'/usr/hdp/current/hadoop-client/conf/mapred-site.xml' -> '/etc/hadoop/2.5.4.2-7/0/mapred-site.xml'
'/usr/hdp/current/hadoop-client/conf/mapred-site.xml.template' -> '/etc/hadoop/2.5.4.2-7/0/mapred-site.xml.template'
'/usr/hdp/current/hadoop-client/conf/secure' -> '/etc/hadoop/2.5.4.2-7/0/secure'
'/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml' -> '/etc/hadoop/2.5.4.2-7/0/secure/ssl-client.xml'
'/usr/hdp/current/hadoop-client/conf/slaves' -> '/etc/hadoop/2.5.4.2-7/0/slaves'
'/usr/hdp/current/hadoop-client/conf/ssl-client.xml' -> '/etc/hadoop/2.5.4.2-7/0/ssl-client.xml'
'/usr/hdp/current/hadoop-client/conf/ssl-client.xml.example' -> '/etc/hadoop/2.5.4.2-7/0/ssl-client.xml.example'
'/usr/hdp/current/hadoop-client/conf/ssl-server.xml' -> '/etc/hadoop/2.5.4.2-7/0/ssl-server.xml'
'/usr/hdp/current/hadoop-client/conf/ssl-server.xml.example' -> '/etc/hadoop/2.5.4.2-7/0/ssl-server.xml.example'
'/usr/hdp/current/hadoop-client/conf/taskcontroller.cfg' -> '/etc/hadoop/2.5.4.2-7/0/taskcontroller.cfg'
'/usr/hdp/current/hadoop-client/conf/yarn-env.sh' -> '/etc/hadoop/2.5.4.2-7/0/yarn-env.sh'
'/usr/hdp/current/hadoop-client/conf/yarn-site.xml' -> '/etc/hadoop/2.5.4.2-7/0/yarn-site.xml'
2017-06-06 14:24:11,328 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/hadoop/conf/* /etc/hadoop/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/hadoop/conf/*'}
2017-06-06 14:24:11,350 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:11,355 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:11,396 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:11,397 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:11,438 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/hadoop/conf -> /etc/hadoop/2.5.4.2-7/0')
2017-06-06 14:24:11,439 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:24:11,440 - Execute[('cp', '-R', '-p', '/etc/hadoop/conf', '/etc/hadoop/conf.backup')] {'not_if': 'test -e /etc/hadoop/conf.backup', 'sudo': True}
2017-06-06 14:24:11,445 - Skipping Execute[('cp', '-R', '-p', '/etc/hadoop/conf', '/etc/hadoop/conf.backup')] due to not_if
2017-06-06 14:24:11,445 - Directory['/etc/hadoop/conf'] {'action': ['delete']}
2017-06-06 14:24:11,445 - Removing directory Directory['/etc/hadoop/conf'] and all its content
2017-06-06 14:24:11,447 - Link['/etc/hadoop/conf'] {'to': '/etc/hadoop/conf.backup'}
2017-06-06 14:24:11,447 - Creating symbolic Link['/etc/hadoop/conf'] to /etc/hadoop/conf.backup
2017-06-06 14:24:11,447 - Link['/etc/hadoop/conf'] {'action': ['delete']}
2017-06-06 14:24:11,448 - Deleting Link['/etc/hadoop/conf']
2017-06-06 14:24:11,448 - Link['/etc/hadoop/conf'] {'to': '/usr/hdp/current/hadoop-client/conf'}
2017-06-06 14:24:11,448 - Creating symbolic Link['/etc/hadoop/conf'] to /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:11,449 - Backing up /etc/mahout/conf to /etc/mahout/conf.backup if destination doesn't exist already.
2017-06-06 14:24:11,449 - Execute[('cp', '-R', '-p', '/etc/mahout/conf', '/etc/mahout/conf.backup')] {'not_if': 'test -e /etc/mahout/conf.backup', 'sudo': True}
INFO 2017-06-06 14:24:16,906 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 8/14 of log for command: 
2017-06-06 14:24:11,464 - Checking if need to create versioned conf dir /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:11,468 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'mahout', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:11,687 - call returned (0, '/etc/mahout/2.5.4.2-7/0', '')
2017-06-06 14:24:11,687 - Package mahout will have new conf directories: /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:11,687 - Checking if need to create versioned conf dir /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:11,692 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'mahout', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:11,734 - call returned (0, '/etc/mahout/2.5.4.2-7/0', '')
2017-06-06 14:24:11,736 - Directory['/etc/mahout/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:11,739 - Seeding versioned configuration directories for mahout
2017-06-06 14:24:11,740 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/mahout-client/conf/* /etc/mahout/2.5.4.2-7/0'] {'logoutput': True}
cp: cannot stat '/usr/hdp/current/mahout-client/conf/*': No such file or directory
2017-06-06 14:24:11,778 - Unable to seed new configuration directories for mahout. Execution of 'ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/mahout-client/conf/* /etc/mahout/2.5.4.2-7/0' returned 1. cp: cannot stat '/usr/hdp/current/mahout-client/conf/*': No such file or directory
2017-06-06 14:24:11,779 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/mahout/conf/* /etc/mahout/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/mahout/conf/*'}
2017-06-06 14:24:11,787 - Skipping Execute['ambari-sudo.sh  -H -E cp -R -p /etc/mahout/conf/* /etc/mahout/2.5.4.2-7/0'] due to only_if
2017-06-06 14:24:11,792 - Checking if need to create versioned conf dir /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:11,796 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'mahout', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:11,853 - call returned (1, '/etc/mahout/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:11,853 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'mahout', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:11,896 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/mahout/conf -> /etc/mahout/2.5.4.2-7/0')
2017-06-06 14:24:11,897 - Ensuring that mahout has the correct symlink structure
2017-06-06 14:24:11,898 - Execute[('cp', '-R', '-p', '/etc/mahout/conf', '/etc/mahout/conf.backup')] {'not_if': 'test -e /etc/mahout/conf.backup', 'sudo': True}
2017-06-06 14:24:11,903 - Skipping Execute[('cp', '-R', '-p', '/etc/mahout/conf', '/etc/mahout/conf.backup')] due to not_if
2017-06-06 14:24:11,904 - Directory['/etc/mahout/conf'] {'action': ['delete']}
2017-06-06 14:24:11,905 - Removing directory Directory['/etc/mahout/conf'] and all its content
2017-06-06 14:24:11,906 - Link['/etc/mahout/conf'] {'to': '/etc/mahout/conf.backup'}
2017-06-06 14:24:11,906 - Creating symbolic Link['/etc/mahout/conf'] to /etc/mahout/conf.backup
2017-06-06 14:24:11,907 - Link['/etc/mahout/conf'] {'action': ['delete']}
2017-06-06 14:24:11,907 - Deleting Link['/etc/mahout/conf']
2017-06-06 14:24:11,907 - Link['/etc/mahout/conf'] {'to': '/usr/hdp/current/mahout-client/conf'}
2017-06-06 14:24:11,908 - Creating symbolic Link['/etc/mahout/conf'] to /usr/hdp/current/mahout-client/conf
2017-06-06 14:24:11,909 - Backing up /etc/storm/conf to /etc/storm/conf.backup if destination doesn't exist already.
2017-06-06 14:24:11,910 - Execute[('cp', '-R', '-p', '/etc/storm/conf', '/etc/storm/conf.backup')] {'not_if': 'test -e /etc/storm/conf.backup', 'sudo': True}
2017-06-06 14:24:11,928 - Checking if need to create versioned conf dir /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:11,933 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'storm', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:11,972 - call returned (0, '/etc/storm/2.5.4.2-7/0', '')
2017-06-06 14:24:11,972 - Package storm will have new conf directories: /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:11,972 - Checking if need to create versioned conf dir /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:11,977 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'storm', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,022 - call returned (0, '/etc/storm/2.5.4.2-7/0', '')
2017-06-06 14:24:12,022 - Directory['/etc/storm/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:12,024 - Seeding versioned configuration directories for storm
2017-06-06 14:24:12,024 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/storm-client/conf/* /etc/storm/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/storm-client/conf/core-site.xml' -> '/etc/storm/2.5.4.2-7/0/core-site.xml'
'/usr/hdp/current/storm-client/conf/storm-env.sh' -> '/etc/storm/2.5.4.2-7/0/storm-env.sh'
'/usr/hdp/current/storm-client/conf/storm-slider-env.sh' -> '/etc/storm/2.5.4.2-7/0/storm-slider-env.sh'
'/usr/hdp/current/storm-client/conf/storm.yaml' -> '/etc/storm/2.5.4.2-7/0/storm.yaml'
'/usr/hdp/current/storm-client/conf/storm_env.ini' -> '/etc/storm/2.5.4.2-7/0/storm_env.ini'
2017-06-06 14:24:12,043 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/storm/conf/* /etc/storm/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/storm/conf/*'}
2017-06-06 14:24:12,064 - Checking if need to create versioned conf dir /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:12,069 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'storm', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,117 - call returned (1, '/etc/storm/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:12,117 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'storm', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:12,163 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/storm/conf -> /etc/storm/2.5.4.2-7/0')
2017-06-06 14:24:12,164 - Ensuring that storm has the correct symlink structure
2017-06-06 14:24:12,165 - Execute[('cp', '-R', '-p', '/etc/storm/conf', '/etc/storm/conf.backup')] {'not_if': 'test -e /etc/storm/conf.backup', 'sudo': True}
2017-06-06 14:24:12,170 - Skipping Execute[('cp', '-R', '-p', '/etc/storm/conf', '/etc/storm/conf.backup')] due to not_if
2017-06-06 14:24:12,171 - Directory['/etc/storm/conf'] {'action': ['delete']}
2017-06-06 14:24:12,171 - Removing directory Directory['/etc/storm/conf'] and all its content
2017-06-06 14:24:12,172 - Link['/etc/storm/conf'] {'to': '/etc/storm/conf.backup'}
2017-06-06 14:24:12,173 - Creating symbolic Link['/etc/storm/conf'] to /etc/storm/conf.backup
2017-06-06 14:24:12,173 - Link['/etc/storm/conf'] {'action': ['delete']}
2017-06-06 14:24:12,173 - Deleting Link['/etc/storm/conf']
2017-06-06 14:24:12,174 - Link['/etc/storm/conf'] {'to': '/usr/hdp/current/storm-client/conf'}
2017-06-06 14:24:12,174 - Creating symbolic Link['/etc/storm/conf'] to /usr/hdp/current/storm-client/conf
2017-06-06 14:24:12,174 - Skipping /etc/atlas/conf as it does not exist.
INFO 2017-06-06 14:24:16,910 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 9/14 of log for command: 
2017-06-06 14:24:12,175 - Backing up /etc/ranger/admin/conf to /etc/ranger/admin/conf.backup if destination doesn't exist already.
2017-06-06 14:24:12,175 - Execute[('cp', '-R', '-p', '/etc/ranger/admin/conf', '/etc/ranger/admin/conf.backup')] {'not_if': 'test -e /etc/ranger/admin/conf.backup', 'sudo': True}
2017-06-06 14:24:12,298 - Checking if need to create versioned conf dir /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:12,303 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'ranger-admin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,345 - call returned (0, '/etc/ranger-admin/2.5.4.2-7/0', '')
2017-06-06 14:24:12,347 - Package ranger-admin will have new conf directories: /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:12,347 - Checking if need to create versioned conf dir /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:12,354 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-admin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,395 - call returned (0, '/etc/ranger-admin/2.5.4.2-7/0', '')
2017-06-06 14:24:12,396 - Directory['/etc/ranger-admin/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:12,397 - Seeding versioned configuration directories for ranger-admin
2017-06-06 14:24:12,397 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/ranger-admin/conf/* /etc/ranger-admin/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/ranger-admin/conf/ranger-admin-default-site.xml' -> '/etc/ranger-admin/2.5.4.2-7/0/ranger-admin-default-site.xml'
'/usr/hdp/current/ranger-admin/conf/ranger-admin-site.xml' -> '/etc/ranger-admin/2.5.4.2-7/0/ranger-admin-site.xml'
'/usr/hdp/current/ranger-admin/conf/security-applicationContext.xml' -> '/etc/ranger-admin/2.5.4.2-7/0/security-applicationContext.xml'
2017-06-06 14:24:12,431 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/ranger/admin/conf/* /etc/ranger-admin/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/ranger/admin/conf/*'}
2017-06-06 14:24:12,453 - Checking if need to create versioned conf dir /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:12,458 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'ranger-admin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,501 - call returned (1, '/etc/ranger-admin/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:12,502 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'ranger-admin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:12,553 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/ranger-admin/conf -> /etc/ranger-admin/2.5.4.2-7/0')
2017-06-06 14:24:12,555 - Ensuring that ranger-admin has the correct symlink structure
2017-06-06 14:24:12,556 - Execute[('cp', '-R', '-p', '/etc/ranger/admin/conf', '/etc/ranger/admin/conf.backup')] {'not_if': 'test -e /etc/ranger/admin/conf.backup', 'sudo': True}
2017-06-06 14:24:12,561 - Skipping Execute[('cp', '-R', '-p', '/etc/ranger/admin/conf', '/etc/ranger/admin/conf.backup')] due to not_if
2017-06-06 14:24:12,562 - Directory['/etc/ranger/admin/conf'] {'action': ['delete']}
2017-06-06 14:24:12,562 - Removing directory Directory['/etc/ranger/admin/conf'] and all its content
2017-06-06 14:24:12,563 - Link['/etc/ranger/admin/conf'] {'to': '/etc/ranger/admin/conf.backup'}
2017-06-06 14:24:12,563 - Creating symbolic Link['/etc/ranger/admin/conf'] to /etc/ranger/admin/conf.backup
2017-06-06 14:24:12,563 - Link['/etc/ranger/admin/conf'] {'action': ['delete']}
2017-06-06 14:24:12,564 - Deleting Link['/etc/ranger/admin/conf']
2017-06-06 14:24:12,564 - Link['/etc/ranger/admin/conf'] {'to': '/usr/hdp/current/ranger-admin/conf'}
2017-06-06 14:24:12,564 - Creating symbolic Link['/etc/ranger/admin/conf'] to /usr/hdp/current/ranger-admin/conf
2017-06-06 14:24:12,565 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:12,565 - Backing up /etc/sqoop/conf to /etc/sqoop/conf.backup if destination doesn't exist already.
2017-06-06 14:24:12,566 - Execute[('cp', '-R', '-p', '/etc/sqoop/conf', '/etc/sqoop/conf.backup')] {'not_if': 'test -e /etc/sqoop/conf.backup', 'sudo': True}
2017-06-06 14:24:12,632 - Checking if need to create versioned conf dir /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:12,637 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'sqoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,677 - call returned (0, '/etc/sqoop/2.5.4.2-7/0', '')
2017-06-06 14:24:12,677 - Package sqoop will have new conf directories: /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:12,678 - Checking if need to create versioned conf dir /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:12,682 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'sqoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,741 - call returned (0, '/etc/sqoop/2.5.4.2-7/0', '')
2017-06-06 14:24:12,742 - Directory['/etc/sqoop/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:12,743 - Seeding versioned configuration directories for sqoop
2017-06-06 14:24:12,743 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/sqoop-client/conf/* /etc/sqoop/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/sqoop-client/conf/oraoop-site-template.xml' -> '/etc/sqoop/2.5.4.2-7/0/oraoop-site-template.xml'
'/usr/hdp/current/sqoop-client/conf/sqoop-env-template.cmd' -> '/etc/sqoop/2.5.4.2-7/0/sqoop-env-template.cmd'
'/usr/hdp/current/sqoop-client/conf/sqoop-env-template.sh' -> '/etc/sqoop/2.5.4.2-7/0/sqoop-env-template.sh'
'/usr/hdp/current/sqoop-client/conf/sqoop-site-template.xml' -> '/etc/sqoop/2.5.4.2-7/0/sqoop-site-template.xml'
'/usr/hdp/current/sqoop-client/conf/sqoop-site.xml' -> '/etc/sqoop/2.5.4.2-7/0/sqoop-site.xml'
2017-06-06 14:24:12,776 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/sqoop/conf/* /etc/sqoop/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/sqoop/conf/*'}
2017-06-06 14:24:12,800 - Checking if need to create versioned conf dir /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:12,807 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'sqoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:12,846 - call returned (1, '/etc/sqoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:12,847 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'sqoop', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:12,898 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/sqoop/conf -> /etc/sqoop/2.5.4.2-7/0')
2017-06-06 14:24:12,899 - Ensuring that sqoop has the correct symlink structure
2017-06-06 14:24:12,901 - Execute[('cp', '-R', '-p', '/etc/sqoop/conf', '/etc/sqoop/conf.backup')] {'not_if': 'test -e /etc/sqoop/conf.backup', 'sudo': True}
2017-06-06 14:24:12,907 - Skipping Execute[('cp', '-R', '-p', '/etc/sqoop/conf', '/etc/sqoop/conf.backup')] due to not_if
2017-06-06 14:24:12,908 - Directory['/etc/sqoop/conf'] {'action': ['delete']}
2017-06-06 14:24:12,909 - Removing directory Directory['/etc/sqoop/conf'] and all its content
2017-06-06 14:24:12,910 - Link['/etc/sqoop/conf'] {'to': '/etc/sqoop/conf.backup'}
INFO 2017-06-06 14:24:16,912 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 10/14 of log for command: 
2017-06-06 14:24:12,910 - Creating symbolic Link['/etc/sqoop/conf'] to /etc/sqoop/conf.backup
2017-06-06 14:24:12,910 - Link['/etc/sqoop/conf'] {'action': ['delete']}
2017-06-06 14:24:12,910 - Deleting Link['/etc/sqoop/conf']
2017-06-06 14:24:12,911 - Link['/etc/sqoop/conf'] {'to': '/usr/hdp/current/sqoop-client/conf'}
2017-06-06 14:24:12,911 - Creating symbolic Link['/etc/sqoop/conf'] to /usr/hdp/current/sqoop-client/conf
2017-06-06 14:24:12,911 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:12,912 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:12,912 - Backing up /etc/storm-slider-client/conf to /etc/storm-slider-client/conf.backup if destination doesn't exist already.
2017-06-06 14:24:12,913 - Execute[('cp', '-R', '-p', '/etc/storm-slider-client/conf', '/etc/storm-slider-client/conf.backup')] {'not_if': 'test -e /etc/storm-slider-client/conf.backup', 'sudo': True}
2017-06-06 14:24:13,069 - Checking if need to create versioned conf dir /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:13,075 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'storm-slider-client', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:13,119 - call returned (0, '/etc/storm-slider-client/2.5.4.2-7/0', '')
2017-06-06 14:24:13,120 - Package storm-slider-client will have new conf directories: /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:13,120 - Checking if need to create versioned conf dir /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:13,126 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'storm-slider-client', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:13,174 - call returned (0, '/etc/storm-slider-client/2.5.4.2-7/0', '')
2017-06-06 14:24:13,175 - Directory['/etc/storm-slider-client/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:13,177 - Seeding versioned configuration directories for storm-slider-client
2017-06-06 14:24:13,177 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/storm-slider-client/conf/* /etc/storm-slider-client/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/storm-slider-client/conf/storm-slider-env.sh' -> '/etc/storm-slider-client/2.5.4.2-7/0/storm-slider-env.sh'
2017-06-06 14:24:13,239 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/storm-slider-client/conf/* /etc/storm-slider-client/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/storm-slider-client/conf/*'}
2017-06-06 14:24:13,261 - Checking if need to create versioned conf dir /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:13,267 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'storm-slider-client', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:13,307 - call returned (1, '/etc/storm-slider-client/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:13,308 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'storm-slider-client', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:13,431 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/storm-slider-client/conf -> /etc/storm-slider-client/2.5.4.2-7/0')
2017-06-06 14:24:13,432 - Ensuring that storm-slider-client has the correct symlink structure
2017-06-06 14:24:13,433 - Execute[('cp', '-R', '-p', '/etc/storm-slider-client/conf', '/etc/storm-slider-client/conf.backup')] {'not_if': 'test -e /etc/storm-slider-client/conf.backup', 'sudo': True}
2017-06-06 14:24:13,437 - Skipping Execute[('cp', '-R', '-p', '/etc/storm-slider-client/conf', '/etc/storm-slider-client/conf.backup')] due to not_if
2017-06-06 14:24:13,438 - Directory['/etc/storm-slider-client/conf'] {'action': ['delete']}
2017-06-06 14:24:13,438 - Removing directory Directory['/etc/storm-slider-client/conf'] and all its content
2017-06-06 14:24:13,439 - Link['/etc/storm-slider-client/conf'] {'to': '/etc/storm-slider-client/conf.backup'}
2017-06-06 14:24:13,439 - Creating symbolic Link['/etc/storm-slider-client/conf'] to /etc/storm-slider-client/conf.backup
2017-06-06 14:24:13,440 - Link['/etc/storm-slider-client/conf'] {'action': ['delete']}
2017-06-06 14:24:13,440 - Deleting Link['/etc/storm-slider-client/conf']
2017-06-06 14:24:13,441 - Link['/etc/storm-slider-client/conf'] {'to': '/usr/hdp/current/storm-slider-client/conf'}
2017-06-06 14:24:13,441 - Creating symbolic Link['/etc/storm-slider-client/conf'] to /usr/hdp/current/storm-slider-client/conf
2017-06-06 14:24:13,442 - Backing up /etc/slider/conf to /etc/slider/conf.backup if destination doesn't exist already.
2017-06-06 14:24:13,442 - Execute[('cp', '-R', '-p', '/etc/slider/conf', '/etc/slider/conf.backup')] {'not_if': 'test -e /etc/slider/conf.backup', 'sudo': True}
2017-06-06 14:24:13,633 - Checking if need to create versioned conf dir /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:13,643 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'slider', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:13,715 - call returned (0, '/etc/slider/2.5.4.2-7/0', '')
2017-06-06 14:24:13,715 - Package slider will have new conf directories: /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:13,715 - Checking if need to create versioned conf dir /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:13,721 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'slider', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:13,804 - call returned (0, '/etc/slider/2.5.4.2-7/0', '')
2017-06-06 14:24:13,804 - Directory['/etc/slider/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:13,806 - Seeding versioned configuration directories for slider
2017-06-06 14:24:13,806 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/slider-client/conf/* /etc/slider/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/slider-client/conf/log4j-server.properties' -> '/etc/slider/2.5.4.2-7/0/log4j-server.properties'
'/usr/hdp/current/slider-client/conf/log4j.properties' -> '/etc/slider/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/slider-client/conf/slider-client.xml' -> '/etc/slider/2.5.4.2-7/0/slider-client.xml'
'/usr/hdp/current/slider-client/conf/slider-env.sh' -> '/etc/slider/2.5.4.2-7/0/slider-env.sh'
'/usr/hdp/current/slider-client/conf/slider-server.xml' -> '/etc/slider/2.5.4.2-7/0/slider-server.xml'
2017-06-06 14:24:13,816 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/slider/conf/* /etc/slider/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/slider/conf/*'}
2017-06-06 14:24:13,842 - Checking if need to create versioned conf dir /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:13,849 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'slider', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:13,912 - call returned (1, '/etc/slider/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:13,913 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'slider', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:13,958 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/slider/conf -> /etc/slider/2.5.4.2-7/0')
2017-06-06 14:24:13,959 - Ensuring that slider has the correct symlink structure
INFO 2017-06-06 14:24:16,912 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 11/14 of log for command: 
2017-06-06 14:24:13,960 - Execute[('cp', '-R', '-p', '/etc/slider/conf', '/etc/slider/conf.backup')] {'not_if': 'test -e /etc/slider/conf.backup', 'sudo': True}
2017-06-06 14:24:13,966 - Skipping Execute[('cp', '-R', '-p', '/etc/slider/conf', '/etc/slider/conf.backup')] due to not_if
2017-06-06 14:24:13,966 - Directory['/etc/slider/conf'] {'action': ['delete']}
2017-06-06 14:24:13,966 - Removing directory Directory['/etc/slider/conf'] and all its content
2017-06-06 14:24:13,967 - Link['/etc/slider/conf'] {'to': '/etc/slider/conf.backup'}
2017-06-06 14:24:13,968 - Creating symbolic Link['/etc/slider/conf'] to /etc/slider/conf.backup
2017-06-06 14:24:13,968 - Link['/etc/slider/conf'] {'action': ['delete']}
2017-06-06 14:24:13,968 - Deleting Link['/etc/slider/conf']
2017-06-06 14:24:13,969 - Link['/etc/slider/conf'] {'to': '/usr/hdp/current/slider-client/conf'}
2017-06-06 14:24:13,969 - Creating symbolic Link['/etc/slider/conf'] to /usr/hdp/current/slider-client/conf
2017-06-06 14:24:13,984 - Backing up /etc/zeppelin/conf to /etc/zeppelin/conf.backup if destination doesn't exist already.
2017-06-06 14:24:13,985 - Execute[('cp', '-R', '-p', '/etc/zeppelin/conf', '/etc/zeppelin/conf.backup')] {'not_if': 'test -e /etc/zeppelin/conf.backup', 'sudo': True}
2017-06-06 14:24:14,102 - Checking if need to create versioned conf dir /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:14,107 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'zeppelin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:14,146 - call returned (0, '/etc/zeppelin/2.5.4.2-7/0', '')
2017-06-06 14:24:14,146 - Package zeppelin will have new conf directories: /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:14,146 - Checking if need to create versioned conf dir /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:14,150 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'zeppelin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:14,194 - call returned (0, '/etc/zeppelin/2.5.4.2-7/0', '')
2017-06-06 14:24:14,195 - Directory['/etc/zeppelin/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:14,196 - Seeding versioned configuration directories for zeppelin
2017-06-06 14:24:14,197 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/zeppelin-server/conf/* /etc/zeppelin/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/zeppelin-server/conf/README.md' -> '/etc/zeppelin/2.5.4.2-7/0/README.md'
'/usr/hdp/current/zeppelin-server/conf/configuration.xsl' -> '/etc/zeppelin/2.5.4.2-7/0/configuration.xsl'
'/usr/hdp/current/zeppelin-server/conf/interpreter-list' -> '/etc/zeppelin/2.5.4.2-7/0/interpreter-list'
'/usr/hdp/current/zeppelin-server/conf/log4j.properties' -> '/etc/zeppelin/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/zeppelin-server/conf/shiro.ini' -> '/etc/zeppelin/2.5.4.2-7/0/shiro.ini'
'/usr/hdp/current/zeppelin-server/conf/zeppelin-env.cmd.template' -> '/etc/zeppelin/2.5.4.2-7/0/zeppelin-env.cmd.template'
'/usr/hdp/current/zeppelin-server/conf/zeppelin-env.sh' -> '/etc/zeppelin/2.5.4.2-7/0/zeppelin-env.sh'
'/usr/hdp/current/zeppelin-server/conf/zeppelin-env.sh.template' -> '/etc/zeppelin/2.5.4.2-7/0/zeppelin-env.sh.template'
'/usr/hdp/current/zeppelin-server/conf/zeppelin-site.xml.template' -> '/etc/zeppelin/2.5.4.2-7/0/zeppelin-site.xml.template'
2017-06-06 14:24:14,409 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/zeppelin/conf/* /etc/zeppelin/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/zeppelin/conf/*'}
2017-06-06 14:24:14,431 - Checking if need to create versioned conf dir /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:14,436 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'zeppelin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:14,476 - call returned (1, '/etc/zeppelin/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:14,477 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'zeppelin', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:14,518 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/zeppelin/conf -> /etc/zeppelin/2.5.4.2-7/0')
2017-06-06 14:24:14,521 - Ensuring that zeppelin has the correct symlink structure
2017-06-06 14:24:14,522 - Execute[('cp', '-R', '-p', '/etc/zeppelin/conf', '/etc/zeppelin/conf.backup')] {'not_if': 'test -e /etc/zeppelin/conf.backup', 'sudo': True}
2017-06-06 14:24:14,526 - Skipping Execute[('cp', '-R', '-p', '/etc/zeppelin/conf', '/etc/zeppelin/conf.backup')] due to not_if
2017-06-06 14:24:14,526 - Directory['/etc/zeppelin/conf'] {'action': ['delete']}
2017-06-06 14:24:14,527 - Removing directory Directory['/etc/zeppelin/conf'] and all its content
2017-06-06 14:24:14,528 - Link['/etc/zeppelin/conf'] {'to': '/etc/zeppelin/conf.backup'}
2017-06-06 14:24:14,528 - Creating symbolic Link['/etc/zeppelin/conf'] to /etc/zeppelin/conf.backup
2017-06-06 14:24:14,528 - Link['/etc/zeppelin/conf'] {'action': ['delete']}
2017-06-06 14:24:14,529 - Deleting Link['/etc/zeppelin/conf']
2017-06-06 14:24:14,529 - Link['/etc/zeppelin/conf'] {'to': '/usr/hdp/current/zeppelin-server/conf'}
2017-06-06 14:24:14,529 - Creating symbolic Link['/etc/zeppelin/conf'] to /usr/hdp/current/zeppelin-server/conf
2017-06-06 14:24:14,530 - Backing up /etc/hive-webhcat/conf to /etc/hive-webhcat/conf.backup if destination doesn't exist already.
2017-06-06 14:24:14,531 - Execute[('cp', '-R', '-p', '/etc/hive-webhcat/conf', '/etc/hive-webhcat/conf.backup')] {'not_if': 'test -e /etc/hive-webhcat/conf.backup', 'sudo': True}
2017-06-06 14:24:14,547 - Backing up /etc/hive-hcatalog/conf to /etc/hive-hcatalog/conf.backup if destination doesn't exist already.
2017-06-06 14:24:14,548 - Execute[('cp', '-R', '-p', '/etc/hive-hcatalog/conf', '/etc/hive-hcatalog/conf.backup')] {'not_if': 'test -e /etc/hive-hcatalog/conf.backup', 'sudo': True}
2017-06-06 14:24:14,565 - Checking if need to create versioned conf dir /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:14,569 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'hive-hcatalog', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:14,608 - call returned (0, '/etc/hive-webhcat/2.5.4.2-7/0\n/etc/hive-hcatalog/2.5.4.2-7/0', '')
2017-06-06 14:24:14,608 - Package hive-hcatalog will have new conf directories: /etc/hive-webhcat/2.5.4.2-7/0, /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:14,608 - Checking if need to create versioned conf dir /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:14,613 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hive-hcatalog', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:14,666 - call returned (0, '/etc/hive-webhcat/2.5.4.2-7/0\n/etc/hive-hcatalog/2.5.4.2-7/0', '')
2017-06-06 14:24:14,667 - Directory['/etc/hive-webhcat/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:14,668 - Directory['/etc/hive-hcatalog/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:14,669 - Seeding versioned configuration directories for hive-hcatalog
2017-06-06 14:24:14,669 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/hive-webhcat/etc/webhcat/* /etc/hive-webhcat/2.5.4.2-7/0'] {'logoutput': True}
INFO 2017-06-06 14:24:16,912 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 12/14 of log for command: 
'/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-default.xml' -> '/etc/hive-webhcat/2.5.4.2-7/0/webhcat-default.xml'
'/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-log4j.properties' -> '/etc/hive-webhcat/2.5.4.2-7/0/webhcat-log4j.properties'
2017-06-06 14:24:14,705 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/hive-webhcat/etc/hcatalog/* /etc/hive-hcatalog/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/hive-webhcat/etc/hcatalog/jndi.properties' -> '/etc/hive-hcatalog/2.5.4.2-7/0/jndi.properties'
'/usr/hdp/current/hive-webhcat/etc/hcatalog/proto-hive-site.xml' -> '/etc/hive-hcatalog/2.5.4.2-7/0/proto-hive-site.xml'
2017-06-06 14:24:14,725 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/hive-webhcat/conf/* /etc/hive-webhcat/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/hive-webhcat/conf/*'}
2017-06-06 14:24:14,761 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/hive-hcatalog/conf/* /etc/hive-hcatalog/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/hive-hcatalog/conf/*'}
2017-06-06 14:24:14,783 - Checking if need to create versioned conf dir /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:14,788 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hive-hcatalog', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:14,827 - call returned (1, '/etc/hive-hcatalog/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:14,829 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hive-hcatalog', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:14,868 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/hive-hcatalog/etc/webhcat -> /etc/hive-webhcat/2.5.4.2-7/0\n/usr/hdp/2.5.4.2-7/hive-hcatalog/etc/hcatalog -> /etc/hive-hcatalog/2.5.4.2-7/0')
2017-06-06 14:24:14,869 - Ensuring that hive-hcatalog has the correct symlink structure
2017-06-06 14:24:14,870 - Execute[('cp', '-R', '-p', '/etc/hive-webhcat/conf', '/etc/hive-webhcat/conf.backup')] {'not_if': 'test -e /etc/hive-webhcat/conf.backup', 'sudo': True}
2017-06-06 14:24:14,876 - Skipping Execute[('cp', '-R', '-p', '/etc/hive-webhcat/conf', '/etc/hive-webhcat/conf.backup')] due to not_if
2017-06-06 14:24:14,877 - Directory['/etc/hive-webhcat/conf'] {'action': ['delete']}
2017-06-06 14:24:14,877 - Removing directory Directory['/etc/hive-webhcat/conf'] and all its content
2017-06-06 14:24:14,878 - Link['/etc/hive-webhcat/conf'] {'to': '/etc/hive-webhcat/conf.backup'}
2017-06-06 14:24:14,879 - Creating symbolic Link['/etc/hive-webhcat/conf'] to /etc/hive-webhcat/conf.backup
2017-06-06 14:24:14,879 - Execute[('cp', '-R', '-p', '/etc/hive-hcatalog/conf', '/etc/hive-hcatalog/conf.backup')] {'not_if': 'test -e /etc/hive-hcatalog/conf.backup', 'sudo': True}
2017-06-06 14:24:14,884 - Skipping Execute[('cp', '-R', '-p', '/etc/hive-hcatalog/conf', '/etc/hive-hcatalog/conf.backup')] due to not_if
2017-06-06 14:24:14,885 - Directory['/etc/hive-hcatalog/conf'] {'action': ['delete']}
2017-06-06 14:24:14,886 - Removing directory Directory['/etc/hive-hcatalog/conf'] and all its content
2017-06-06 14:24:14,886 - Link['/etc/hive-hcatalog/conf'] {'to': '/etc/hive-hcatalog/conf.backup'}
2017-06-06 14:24:14,887 - Creating symbolic Link['/etc/hive-hcatalog/conf'] to /etc/hive-hcatalog/conf.backup
2017-06-06 14:24:14,887 - Link['/etc/hive-webhcat/conf'] {'action': ['delete']}
2017-06-06 14:24:14,888 - Deleting Link['/etc/hive-webhcat/conf']
2017-06-06 14:24:14,888 - Link['/etc/hive-webhcat/conf'] {'to': '/usr/hdp/current/hive-webhcat/etc/webhcat'}
2017-06-06 14:24:14,889 - Creating symbolic Link['/etc/hive-webhcat/conf'] to /usr/hdp/current/hive-webhcat/etc/webhcat
2017-06-06 14:24:14,889 - Link['/etc/hive-hcatalog/conf'] {'action': ['delete']}
2017-06-06 14:24:14,889 - Deleting Link['/etc/hive-hcatalog/conf']
2017-06-06 14:24:14,890 - Link['/etc/hive-hcatalog/conf'] {'to': '/usr/hdp/current/hive-webhcat/etc/hcatalog'}
2017-06-06 14:24:14,890 - Creating symbolic Link['/etc/hive-hcatalog/conf'] to /usr/hdp/current/hive-webhcat/etc/hcatalog
2017-06-06 14:24:14,891 - Backing up /etc/falcon/conf to /etc/falcon/conf.backup if destination doesn't exist already.
2017-06-06 14:24:14,892 - Execute[('cp', '-R', '-p', '/etc/falcon/conf', '/etc/falcon/conf.backup')] {'not_if': 'test -e /etc/falcon/conf.backup', 'sudo': True}
2017-06-06 14:24:14,912 - Checking if need to create versioned conf dir /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:14,918 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'falcon', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:14,973 - call returned (0, '/etc/falcon/2.5.4.2-7/0', '')
2017-06-06 14:24:14,973 - Package falcon will have new conf directories: /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:14,973 - Checking if need to create versioned conf dir /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:14,978 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'falcon', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:15,041 - call returned (0, '/etc/falcon/2.5.4.2-7/0', '')
2017-06-06 14:24:15,042 - Directory['/etc/falcon/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:15,045 - Seeding versioned configuration directories for falcon
2017-06-06 14:24:15,045 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/falcon-client/conf/* /etc/falcon/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/falcon-client/conf/client.properties' -> '/etc/falcon/2.5.4.2-7/0/client.properties'
'/usr/hdp/current/falcon-client/conf/falcon-env.sh' -> '/etc/falcon/2.5.4.2-7/0/falcon-env.sh'
'/usr/hdp/current/falcon-client/conf/falcon_env.ini' -> '/etc/falcon/2.5.4.2-7/0/falcon_env.ini'
'/usr/hdp/current/falcon-client/conf/hbase-site.xml.template' -> '/etc/falcon/2.5.4.2-7/0/hbase-site.xml.template'
'/usr/hdp/current/falcon-client/conf/log4j.xml' -> '/etc/falcon/2.5.4.2-7/0/log4j.xml'
'/usr/hdp/current/falcon-client/conf/prism.keystore' -> '/etc/falcon/2.5.4.2-7/0/prism.keystore'
'/usr/hdp/current/falcon-client/conf/runtime.properties' -> '/etc/falcon/2.5.4.2-7/0/runtime.properties'
'/usr/hdp/current/falcon-client/conf/startup.properties' -> '/etc/falcon/2.5.4.2-7/0/startup.properties'
'/usr/hdp/current/falcon-client/conf/statestore.credentials' -> '/etc/falcon/2.5.4.2-7/0/statestore.credentials'
'/usr/hdp/current/falcon-client/conf/statestore.properties' -> '/etc/falcon/2.5.4.2-7/0/statestore.properties'
2017-06-06 14:24:15,087 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/falcon/conf/* /etc/falcon/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/falcon/conf/*'}
2017-06-06 14:24:15,108 - Checking if need to create versioned conf dir /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:15,112 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'falcon', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:15,150 - call returned (1, '/etc/falcon/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:15,151 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'falcon', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:15,192 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/falcon/conf -> /etc/falcon/2.5.4.2-7/0')
2017-06-06 14:24:15,194 - Ensuring that falcon has the correct symlink structure
INFO 2017-06-06 14:24:16,912 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 13/14 of log for command: 
2017-06-06 14:24:15,195 - Execute[('cp', '-R', '-p', '/etc/falcon/conf', '/etc/falcon/conf.backup')] {'not_if': 'test -e /etc/falcon/conf.backup', 'sudo': True}
2017-06-06 14:24:15,201 - Skipping Execute[('cp', '-R', '-p', '/etc/falcon/conf', '/etc/falcon/conf.backup')] due to not_if
2017-06-06 14:24:15,202 - Directory['/etc/falcon/conf'] {'action': ['delete']}
2017-06-06 14:24:15,202 - Removing directory Directory['/etc/falcon/conf'] and all its content
2017-06-06 14:24:15,208 - Link['/etc/falcon/conf'] {'to': '/etc/falcon/conf.backup'}
2017-06-06 14:24:15,208 - Creating symbolic Link['/etc/falcon/conf'] to /etc/falcon/conf.backup
2017-06-06 14:24:15,209 - Link['/etc/falcon/conf'] {'action': ['delete']}
2017-06-06 14:24:15,209 - Deleting Link['/etc/falcon/conf']
2017-06-06 14:24:15,209 - Link['/etc/falcon/conf'] {'to': '/usr/hdp/current/falcon-client/conf'}
2017-06-06 14:24:15,209 - Creating symbolic Link['/etc/falcon/conf'] to /usr/hdp/current/falcon-client/conf
2017-06-06 14:24:15,210 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:15,210 - Backing up /etc/pig/conf to /etc/pig/conf.backup if destination doesn't exist already.
2017-06-06 14:24:15,210 - Execute[('cp', '-R', '-p', '/etc/pig/conf', '/etc/pig/conf.backup')] {'not_if': 'test -e /etc/pig/conf.backup', 'sudo': True}
2017-06-06 14:24:15,237 - Checking if need to create versioned conf dir /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:15,242 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'pig', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:15,284 - call returned (0, '/etc/pig/2.5.4.2-7/0', '')
2017-06-06 14:24:15,284 - Package pig will have new conf directories: /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:15,284 - Checking if need to create versioned conf dir /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:15,288 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'pig', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:15,333 - call returned (0, '/etc/pig/2.5.4.2-7/0', '')
2017-06-06 14:24:15,334 - Directory['/etc/pig/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:15,335 - Seeding versioned configuration directories for pig
2017-06-06 14:24:15,336 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/pig-client/conf/* /etc/pig/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/pig-client/conf/log4j.properties' -> '/etc/pig/2.5.4.2-7/0/log4j.properties'
'/usr/hdp/current/pig-client/conf/pig-env.sh' -> '/etc/pig/2.5.4.2-7/0/pig-env.sh'
'/usr/hdp/current/pig-client/conf/pig.properties' -> '/etc/pig/2.5.4.2-7/0/pig.properties'
'/usr/hdp/current/pig-client/conf/test-log4j.properties' -> '/etc/pig/2.5.4.2-7/0/test-log4j.properties'
2017-06-06 14:24:15,348 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/pig/conf/* /etc/pig/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/pig/conf/*'}
2017-06-06 14:24:15,369 - Checking if need to create versioned conf dir /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:15,373 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'pig', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:15,418 - call returned (1, '/etc/pig/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:15,418 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'pig', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:15,457 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/pig/conf -> /etc/pig/2.5.4.2-7/0')
2017-06-06 14:24:15,458 - Ensuring that pig has the correct symlink structure
2017-06-06 14:24:15,459 - Execute[('cp', '-R', '-p', '/etc/pig/conf', '/etc/pig/conf.backup')] {'not_if': 'test -e /etc/pig/conf.backup', 'sudo': True}
2017-06-06 14:24:15,463 - Skipping Execute[('cp', '-R', '-p', '/etc/pig/conf', '/etc/pig/conf.backup')] due to not_if
2017-06-06 14:24:15,464 - Directory['/etc/pig/conf'] {'action': ['delete']}
2017-06-06 14:24:15,464 - Removing directory Directory['/etc/pig/conf'] and all its content
2017-06-06 14:24:15,465 - Link['/etc/pig/conf'] {'to': '/etc/pig/conf.backup'}
2017-06-06 14:24:15,465 - Creating symbolic Link['/etc/pig/conf'] to /etc/pig/conf.backup
2017-06-06 14:24:15,466 - Link['/etc/pig/conf'] {'action': ['delete']}
2017-06-06 14:24:15,466 - Deleting Link['/etc/pig/conf']
2017-06-06 14:24:15,466 - Link['/etc/pig/conf'] {'to': '/usr/hdp/current/pig-client/conf'}
2017-06-06 14:24:15,466 - Creating symbolic Link['/etc/pig/conf'] to /usr/hdp/current/pig-client/conf
2017-06-06 14:24:15,479 - Backing up /etc/spark2/conf to /etc/spark2/conf.backup if destination doesn't exist already.
2017-06-06 14:24:15,480 - Execute[('cp', '-R', '-p', '/etc/spark2/conf', '/etc/spark2/conf.backup')] {'not_if': 'test -e /etc/spark2/conf.backup', 'sudo': True}
2017-06-06 14:24:15,895 - Checking if need to create versioned conf dir /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:15,901 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'spark2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:15,940 - call returned (0, '/etc/spark2/2.5.4.2-7/0', '')
2017-06-06 14:24:15,941 - Package spark2 will have new conf directories: /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:15,941 - Checking if need to create versioned conf dir /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:15,945 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'spark2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:16,127 - call returned (0, '/etc/spark2/2.5.4.2-7/0', '')
2017-06-06 14:24:16,127 - Directory['/etc/spark2/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:16,128 - Seeding versioned configuration directories for spark2
2017-06-06 14:24:16,129 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/spark2-client/conf/* /etc/spark2/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/spark2-client/conf/docker.properties.template' -> '/etc/spark2/2.5.4.2-7/0/docker.properties.template'
'/usr/hdp/current/spark2-client/conf/fairscheduler.xml.template' -> '/etc/spark2/2.5.4.2-7/0/fairscheduler.xml.template'
'/usr/hdp/current/spark2-client/conf/log4j.properties.template' -> '/etc/spark2/2.5.4.2-7/0/log4j.properties.template'
'/usr/hdp/current/spark2-client/conf/metrics.properties.template' -> '/etc/spark2/2.5.4.2-7/0/metrics.properties.template'
'/usr/hdp/current/spark2-client/conf/slaves.template' -> '/etc/spark2/2.5.4.2-7/0/slaves.template'
'/usr/hdp/current/spark2-client/conf/spark-defaults.conf' -> '/etc/spark2/2.5.4.2-7/0/spark-defaults.conf'
'/usr/hdp/current/spark2-client/conf/spark-defaults.conf.template' -> '/etc/spark2/2.5.4.2-7/0/spark-defaults.conf.template'
'/usr/hdp/current/spark2-client/conf/spark-env.sh' -> '/etc/spark2/2.5.4.2-7/0/spark-env.sh'
'/usr/hdp/current/spark2-client/conf/spark-env.sh.template' -> '/etc/spark2/2.5.4.2-7/0/spark-env.sh.template'
2017-06-06 14:24:16,140 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/spark2/conf/* /etc/spark2/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/spark2/conf/*'}
2017-06-06 14:24:16,167 - Checking if need to create versioned conf dir /etc/spark2/2.5.4.2-7/0
INFO 2017-06-06 14:24:16,913 ActionQueue.py:471 - Cmd log for taskId=55 and chunk 14/14 of log for command: 
2017-06-06 14:24:16,171 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'spark2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:16,211 - call returned (1, '/etc/spark2/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:16,212 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'spark2', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:16,255 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/spark2/conf -> /etc/spark2/2.5.4.2-7/0')
2017-06-06 14:24:16,256 - Ensuring that spark2 has the correct symlink structure
2017-06-06 14:24:16,257 - Execute[('cp', '-R', '-p', '/etc/spark2/conf', '/etc/spark2/conf.backup')] {'not_if': 'test -e /etc/spark2/conf.backup', 'sudo': True}
2017-06-06 14:24:16,263 - Skipping Execute[('cp', '-R', '-p', '/etc/spark2/conf', '/etc/spark2/conf.backup')] due to not_if
2017-06-06 14:24:16,263 - Directory['/etc/spark2/conf'] {'action': ['delete']}
2017-06-06 14:24:16,264 - Removing directory Directory['/etc/spark2/conf'] and all its content
2017-06-06 14:24:16,265 - Link['/etc/spark2/conf'] {'to': '/etc/spark2/conf.backup'}
2017-06-06 14:24:16,265 - Creating symbolic Link['/etc/spark2/conf'] to /etc/spark2/conf.backup
2017-06-06 14:24:16,266 - Link['/etc/spark2/conf'] {'action': ['delete']}
2017-06-06 14:24:16,266 - Deleting Link['/etc/spark2/conf']
2017-06-06 14:24:16,267 - Link['/etc/spark2/conf'] {'to': '/usr/hdp/current/spark2-client/conf'}
2017-06-06 14:24:16,267 - Creating symbolic Link['/etc/spark2/conf'] to /usr/hdp/current/spark2-client/conf
2017-06-06 14:24:16,270 - Backing up /etc/hive/conf to /etc/hive/conf.backup if destination doesn't exist already.
2017-06-06 14:24:16,270 - Execute[('cp', '-R', '-p', '/etc/hive/conf', '/etc/hive/conf.backup')] {'not_if': 'test -e /etc/hive/conf.backup', 'sudo': True}
2017-06-06 14:24:16,489 - Checking if need to create versioned conf dir /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:16,493 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'dry-run-create', '--package', 'hive', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:16,544 - call returned (0, '/etc/hive/2.5.4.2-7/0', '')
2017-06-06 14:24:16,545 - Package hive will have new conf directories: /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:16,545 - Checking if need to create versioned conf dir /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:16,550 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hive', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:16,603 - call returned (0, '/etc/hive/2.5.4.2-7/0', '')
2017-06-06 14:24:16,604 - Directory['/etc/hive/2.5.4.2-7/0'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:16,605 - Seeding versioned configuration directories for hive
2017-06-06 14:24:16,606 - Execute['ambari-sudo.sh  -H -E cp -R -p -v /usr/hdp/current/hive-client/conf/* /etc/hive/2.5.4.2-7/0'] {'logoutput': True}
'/usr/hdp/current/hive-client/conf/beeline-log4j.properties.template' -> '/etc/hive/2.5.4.2-7/0/beeline-log4j.properties.template'
'/usr/hdp/current/hive-client/conf/hive-default.xml.template' -> '/etc/hive/2.5.4.2-7/0/hive-default.xml.template'
'/usr/hdp/current/hive-client/conf/hive-env.sh.template' -> '/etc/hive/2.5.4.2-7/0/hive-env.sh.template'
'/usr/hdp/current/hive-client/conf/hive-exec-log4j.properties' -> '/etc/hive/2.5.4.2-7/0/hive-exec-log4j.properties'
'/usr/hdp/current/hive-client/conf/hive-log4j.properties' -> '/etc/hive/2.5.4.2-7/0/hive-log4j.properties'
'/usr/hdp/current/hive-client/conf/hive-site.xml' -> '/etc/hive/2.5.4.2-7/0/hive-site.xml'
'/usr/hdp/current/hive-client/conf/ivysettings.xml' -> '/etc/hive/2.5.4.2-7/0/ivysettings.xml'
'/usr/hdp/current/hive-client/conf/parquet-logging.properties' -> '/etc/hive/2.5.4.2-7/0/parquet-logging.properties'
2017-06-06 14:24:16,618 - Execute['ambari-sudo.sh  -H -E cp -R -p /etc/hive/conf/* /etc/hive/2.5.4.2-7/0'] {'only_if': 'ls -d /etc/hive/conf/*'}
2017-06-06 14:24:16,647 - Checking if need to create versioned conf dir /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:16,651 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hive', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:24:16,696 - call returned (1, '/etc/hive/2.5.4.2-7/0 exist already', '')
2017-06-06 14:24:16,697 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hive', '--stack-version', u'2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:24:16,760 - checked_call returned (0, '/usr/hdp/2.5.4.2-7/hive/conf -> /etc/hive/2.5.4.2-7/0')
2017-06-06 14:24:16,761 - Ensuring that hive has the correct symlink structure
2017-06-06 14:24:16,761 - Execute[('cp', '-R', '-p', '/etc/hive/conf', '/etc/hive/conf.backup')] {'not_if': 'test -e /etc/hive/conf.backup', 'sudo': True}
2017-06-06 14:24:16,767 - Skipping Execute[('cp', '-R', '-p', '/etc/hive/conf', '/etc/hive/conf.backup')] due to not_if
2017-06-06 14:24:16,768 - Directory['/etc/hive/conf'] {'action': ['delete']}
2017-06-06 14:24:16,768 - Removing directory Directory['/etc/hive/conf'] and all its content
2017-06-06 14:24:16,769 - Link['/etc/hive/conf'] {'to': '/etc/hive/conf.backup'}
2017-06-06 14:24:16,769 - Creating symbolic Link['/etc/hive/conf'] to /etc/hive/conf.backup
2017-06-06 14:24:16,769 - Link['/etc/hive/conf'] {'action': ['delete']}
2017-06-06 14:24:16,769 - Deleting Link['/etc/hive/conf']
2017-06-06 14:24:16,770 - Link['/etc/hive/conf'] {'to': '/usr/hdp/current/hive-client/conf'}
2017-06-06 14:24:16,770 - Creating symbolic Link['/etc/hive/conf'] to /usr/hdp/current/hive-client/conf
2017-06-06 14:24:16,770 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!
INFO 2017-06-06 14:24:16,921 ActionQueue.py:382 - End command output log for command with id = 55, role = TEZ_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:16,921 RecoveryManager.py:179 - New status, current status is set to INSTALLED for TEZ_CLIENT
INFO 2017-06-06 14:24:16,921 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=55, current state of TEZ_CLIENT to INSTALLED
INFO 2017-06-06 14:24:17,890 ActionQueue.py:358 - Quit retrying for command id 48. Status: COMPLETED, retryAble: True, retryDuration (sec): 573, last delay (sec): 1
INFO 2017-06-06 14:24:17,891 ActionQueue.py:363 - Command 48 completed successfully!
INFO 2017-06-06 14:24:17,891 ActionQueue.py:379 - Begin command output log for command with id = 48, role = HISTORYSERVER, roleCommand = INSTALL
INFO 2017-06-06 14:24:17,891 ActionQueue.py:473 - Cmd log for taskId=48: 2017-06-06 14:23:58,541 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:58,587 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:58,587 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:58,587 - FS Type: 
2017-06-06 14:23:58,587 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:58,655 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:58,662 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:01,524 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:03,838 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:03,839 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:03,839 - FS Type: 
2017-06-06 14:24:03,839 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:03,900 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:03,901 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:03,956 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,624 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,625 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:17,625 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:17,626 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:17,626 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:17,626 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:17,626 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:17,627 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:17,627 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:17,627 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:17,628 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:17,629 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:17,629 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:17,629 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:17,644 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:17,644 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:17,644 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:17,645 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:17,645 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:17,645 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:17,645 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:17,645 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:17,646 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:17,646 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:17,646 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:17,646 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:17,646 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:17,647 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:17,647 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:17,647 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:17,647 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:17,647 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!

INFO 2017-06-06 14:24:17,891 ActionQueue.py:382 - End command output log for command with id = 48, role = HISTORYSERVER, roleCommand = INSTALL
INFO 2017-06-06 14:24:17,892 RecoveryManager.py:179 - New status, current status is set to INSTALLED for HISTORYSERVER
INFO 2017-06-06 14:24:17,893 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=48, current state of HISTORYSERVER to INSTALLED
INFO 2017-06-06 14:24:18,805 Controller.py:297 - Heartbeat (response id = 30) with server is running...
INFO 2017-06-06 14:24:18,805 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:24:19,037 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:24:19,784 Controller.py:313 - Sending Heartbeat (id = 30)
INFO 2017-06-06 14:24:19,835 Controller.py:325 - Heartbeat response received (id = 31)
INFO 2017-06-06 14:24:19,836 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:24:19,836 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:24:19,837 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:24:19,838 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:24:19,838 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:24:20,739 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:24:21,242 ActionQueue.py:358 - Quit retrying for command id 45. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,244 ActionQueue.py:363 - Command 45 completed successfully!
INFO 2017-06-06 14:24:21,245 ActionQueue.py:379 - Begin command output log for command with id = 45, role = APP_TIMELINE_SERVER, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,246 ActionQueue.py:473 - Cmd log for taskId=45: 2017-06-06 14:23:55,074 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:55,085 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:55,085 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:55,085 - FS Type: 
2017-06-06 14:23:55,085 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:55,226 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:55,255 - Writing File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] because contents don't match
2017-06-06 14:23:55,282 - Changing owner for /usr/hdp/current/hadoop-client/conf/hadoop-env.sh from 0 to hdfs
2017-06-06 14:23:55,288 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:23:55,294 - Creating directory Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] since it doesn't exist.
2017-06-06 14:23:55,302 - Changing owner for /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir from 0 to hdfs
2017-06-06 14:23:55,306 - Changing group for /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir from 0 to hadoop
2017-06-06 14:23:55,306 - Changing permission for /var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir from 755 to 1777
2017-06-06 14:24:00,207 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:03,272 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:03,387 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:03,388 - FS Type: 
2017-06-06 14:24:03,391 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:03,496 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:03,498 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:03,618 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,838 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,840 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,840 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,840 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,841 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,841 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,841 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,842 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,842 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,842 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,843 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:20,843 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,843 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,844 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,844 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,844 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,844 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,845 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,845 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,845 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,845 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,846 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,847 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,847 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,847 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,848 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,848 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,848 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,850 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,850 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:20,850 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,851 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!

INFO 2017-06-06 14:24:21,248 ActionQueue.py:382 - End command output log for command with id = 45, role = APP_TIMELINE_SERVER, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,249 RecoveryManager.py:179 - New status, current status is set to INSTALLED for APP_TIMELINE_SERVER
INFO 2017-06-06 14:24:21,250 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=45, current state of APP_TIMELINE_SERVER to INSTALLED
INFO 2017-06-06 14:24:21,263 ActionQueue.py:358 - Quit retrying for command id 54. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,263 ActionQueue.py:363 - Command 54 completed successfully!
INFO 2017-06-06 14:24:21,263 ActionQueue.py:379 - Begin command output log for command with id = 54, role = SQOOP, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,264 ActionQueue.py:471 - Cmd log for taskId=54 and chunk 1/2 of log for command: 
2017-06-06 14:23:58,809 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:58,853 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:58,853 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:58,853 - FS Type: 
2017-06-06 14:23:58,858 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:58,988 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:58,997 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:03,268 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:03,387 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,218 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,237 - Link['/usr/hdp/current/sqoop-client/lib/mysql-connector-java.jar'] {'to': '/usr/share/java/mysql-connector-java.jar'}
2017-06-06 14:24:17,302 - Warning: linking to nonexistent location /usr/share/java/mysql-connector-java.jar
2017-06-06 14:24:17,302 - Creating symbolic Link['/usr/hdp/current/sqoop-client/lib/mysql-connector-java.jar'] to /usr/share/java/mysql-connector-java.jar
2017-06-06 14:24:17,303 - Directory['/usr/hdp/current/sqoop-client/conf'] {'owner': 'sqoop', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:17,306 - Changing owner for /usr/hdp/current/sqoop-client/conf from 0 to sqoop
2017-06-06 14:24:17,309 - Changing group for /usr/hdp/current/sqoop-client/conf from 0 to hadoop
2017-06-06 14:24:17,310 - XmlConfig['sqoop-site.xml'] {'owner': 'sqoop', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/sqoop-client/conf', 'configuration_attributes': {}, 'configurations': {}}
2017-06-06 14:24:17,367 - Generating config: /usr/hdp/current/sqoop-client/conf/sqoop-site.xml
2017-06-06 14:24:17,368 - File['/usr/hdp/current/sqoop-client/conf/sqoop-site.xml'] {'owner': 'sqoop', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:17,368 - Writing File['/usr/hdp/current/sqoop-client/conf/sqoop-site.xml'] because contents don't match
2017-06-06 14:24:17,369 - Changing owner for /usr/hdp/current/sqoop-client/conf/sqoop-site.xml from 0 to sqoop
2017-06-06 14:24:17,373 - Changing group for /usr/hdp/current/sqoop-client/conf/sqoop-site.xml from 0 to hadoop
2017-06-06 14:24:17,376 - File['/usr/hdp/current/sqoop-client/conf/sqoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'sqoop', 'group': 'hadoop'}
2017-06-06 14:24:17,377 - Writing File['/usr/hdp/current/sqoop-client/conf/sqoop-env.sh'] because it doesn't exist
2017-06-06 14:24:17,377 - Changing owner for /usr/hdp/current/sqoop-client/conf/sqoop-env.sh from 0 to sqoop
2017-06-06 14:24:17,384 - Changing group for /usr/hdp/current/sqoop-client/conf/sqoop-env.sh from 0 to hadoop
2017-06-06 14:24:17,385 - File['/usr/hdp/current/sqoop-client/conf/sqoop-env-template.sh'] {'owner': 'sqoop', 'only_if': 'test -e /usr/hdp/current/sqoop-client/conf/sqoop-env-template.sh', 'group': 'hadoop'}
2017-06-06 14:24:17,411 - Changing owner for /usr/hdp/current/sqoop-client/conf/sqoop-env-template.sh from 0 to sqoop
2017-06-06 14:24:17,413 - Changing group for /usr/hdp/current/sqoop-client/conf/sqoop-env-template.sh from 0 to hadoop
2017-06-06 14:24:17,414 - File['/usr/hdp/current/sqoop-client/conf/sqoop-site-template.xml'] {'owner': 'sqoop', 'only_if': 'test -e /usr/hdp/current/sqoop-client/conf/sqoop-site-template.xml', 'group': 'hadoop'}
2017-06-06 14:24:17,441 - Changing owner for /usr/hdp/current/sqoop-client/conf/sqoop-site-template.xml from 0 to sqoop
2017-06-06 14:24:17,442 - Changing group for /usr/hdp/current/sqoop-client/conf/sqoop-site-template.xml from 0 to hadoop
2017-06-06 14:24:17,443 - File['/usr/hdp/current/sqoop-client/conf/sqoop-site.xml'] {'owner': 'sqoop', 'only_if': 'test -e /usr/hdp/current/sqoop-client/conf/sqoop-site.xml', 'group': 'hadoop'}
2017-06-06 14:24:17,456 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:18,926 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:18,926 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:18,927 - FS Type: 
2017-06-06 14:24:18,927 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:18,983 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:18,985 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,180 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,920 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,921 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,921 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,921 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,922 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,922 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,922 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,922 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,923 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,923 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,923 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:20,924 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,925 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,926 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,926 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,926 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,927 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,927 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,927 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,927 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,928 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,928 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,928 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,929 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,929 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,929 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,930 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,930 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,930 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,930 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
INFO 2017-06-06 14:24:21,264 ActionQueue.py:471 - Cmd log for taskId=54 and chunk 2/2 of log for command: 
2017-06-06 14:24:20,935 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,936 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!
INFO 2017-06-06 14:24:21,264 ActionQueue.py:382 - End command output log for command with id = 54, role = SQOOP, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,264 RecoveryManager.py:179 - New status, current status is set to INSTALLED for SQOOP
INFO 2017-06-06 14:24:21,264 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=54, current state of SQOOP to INSTALLED
INFO 2017-06-06 14:24:21,267 ActionQueue.py:358 - Quit retrying for command id 46. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,267 ActionQueue.py:363 - Command 46 completed successfully!
INFO 2017-06-06 14:24:21,268 ActionQueue.py:379 - Begin command output log for command with id = 46, role = HCAT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,268 ActionQueue.py:473 - Cmd log for taskId=46: 2017-06-06 14:23:57,636 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:57,669 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:57,673 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:57,673 - FS Type: 
2017-06-06 14:23:57,674 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:57,795 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:57,810 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:02,296 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:02,473 - call['ambari-python-wrap /usr/bin/hdp-select status hive-server2'] {'timeout': 20}
2017-06-06 14:24:02,764 - call returned (0, 'hive-server2 - 2.5.4.2-7')
2017-06-06 14:24:02,765 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:02,890 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:02,892 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:16,770 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:16,778 - Directory['/usr/hdp/current/hive-client/conf/conf.server'] {'owner': 'hcat', 'create_parents': True, 'group': 'hadoop'}
2017-06-06 14:24:16,786 - Creating directory Directory['/usr/hdp/current/hive-client/conf/conf.server'] since it doesn't exist.
2017-06-06 14:24:16,789 - Changing owner for /usr/hdp/current/hive-client/conf/conf.server from 0 to hcat
2017-06-06 14:24:16,791 - Changing group for /usr/hdp/current/hive-client/conf/conf.server from 0 to hadoop
2017-06-06 14:24:16,792 - Directory['/usr/hdp/current/hive-webhcat/etc/hcatalog'] {'owner': 'hcat', 'create_parents': True, 'group': 'hadoop'}
2017-06-06 14:24:16,795 - Changing owner for /usr/hdp/current/hive-webhcat/etc/hcatalog from 0 to hcat
2017-06-06 14:24:16,795 - Changing group for /usr/hdp/current/hive-webhcat/etc/hcatalog from 0 to hadoop
2017-06-06 14:24:16,795 - Directory['/var/run/webhcat'] {'owner': 'hcat', 'create_parents': True}
2017-06-06 14:24:16,796 - Creating directory Directory['/var/run/webhcat'] since it doesn't exist.
2017-06-06 14:24:16,796 - Changing owner for /var/run/webhcat from 0 to hcat
2017-06-06 14:24:16,797 - XmlConfig['hive-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-client/conf', 'mode': 0644, 'configuration_attributes': {u'hidden': {u'javax.jdo.option.ConnectionPassword': u'HIVE_CLIENT,WEBHCAT_SERVER,HCAT,CONFIG_DOWNLOAD'}}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:16,819 - Generating config: /usr/hdp/current/hive-client/conf/hive-site.xml
2017-06-06 14:24:16,825 - File['/usr/hdp/current/hive-client/conf/hive-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:17,194 - Writing File['/usr/hdp/current/hive-client/conf/hive-site.xml'] because contents don't match
2017-06-06 14:24:17,197 - Changing owner for /usr/hdp/current/hive-client/conf/hive-site.xml from 0 to hive
2017-06-06 14:24:17,198 - Changing group for /usr/hdp/current/hive-client/conf/hive-site.xml from 0 to hadoop
2017-06-06 14:24:17,202 - File['/usr/hdp/current/hive-webhcat/etc/hcatalog/hcat-env.sh'] {'content': InlineTemplate(...), 'owner': 'hcat', 'group': 'hadoop'}
2017-06-06 14:24:17,203 - Writing File['/usr/hdp/current/hive-webhcat/etc/hcatalog/hcat-env.sh'] because it doesn't exist
2017-06-06 14:24:17,204 - Changing owner for /usr/hdp/current/hive-webhcat/etc/hcatalog/hcat-env.sh from 0 to hcat
2017-06-06 14:24:17,204 - Changing group for /usr/hdp/current/hive-webhcat/etc/hcatalog/hcat-env.sh from 0 to hadoop
2017-06-06 14:24:17,217 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:18,971 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:18,972 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:18,972 - FS Type: 
2017-06-06 14:24:18,973 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:19,084 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:19,085 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,219 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,947 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,949 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,949 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,949 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,950 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,950 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,950 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,951 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,951 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,951 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,951 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:20,952 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,952 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,953 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,953 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,953 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,953 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,954 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,955 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,955 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,955 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,956 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,956 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,956 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,957 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,957 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,958 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,958 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,958 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,958 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:20,959 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,959 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!

INFO 2017-06-06 14:24:21,268 ActionQueue.py:382 - End command output log for command with id = 46, role = HCAT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,268 RecoveryManager.py:179 - New status, current status is set to INSTALLED for HCAT
INFO 2017-06-06 14:24:21,269 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=46, current state of HCAT to INSTALLED
INFO 2017-06-06 14:24:21,297 ActionQueue.py:358 - Quit retrying for command id 53. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,298 ActionQueue.py:363 - Command 53 completed successfully!
INFO 2017-06-06 14:24:21,298 ActionQueue.py:379 - Begin command output log for command with id = 53, role = SLIDER, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,298 ActionQueue.py:473 - Cmd log for taskId=53: 2017-06-06 14:23:58,345 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:58,386 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:58,386 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:58,386 - FS Type: 
2017-06-06 14:23:58,407 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:58,593 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:58,610 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:01,983 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:01,983 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,456 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,481 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:17,494 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:17,495 - Directory['/usr/hdp/current/slider-client/conf'] {'create_parents': True}
2017-06-06 14:24:17,498 - XmlConfig['slider-client.xml'] {'mode': 0644, 'conf_dir': '/usr/hdp/current/slider-client/conf', 'configurations': {}}
2017-06-06 14:24:17,541 - Generating config: /usr/hdp/current/slider-client/conf/slider-client.xml
2017-06-06 14:24:17,546 - File['/usr/hdp/current/slider-client/conf/slider-client.xml'] {'owner': None, 'content': InlineTemplate(...), 'group': None, 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:17,547 - Writing File['/usr/hdp/current/slider-client/conf/slider-client.xml'] because contents don't match
2017-06-06 14:24:17,551 - File['/usr/hdp/current/slider-client/conf/slider-env.sh'] {'content': InlineTemplate(...), 'mode': 0755}
2017-06-06 14:24:17,551 - Writing File['/usr/hdp/current/slider-client/conf/slider-env.sh'] because contents don't match
2017-06-06 14:24:17,552 - Changing permission for /usr/hdp/current/slider-client/conf/slider-env.sh from 644 to 755
2017-06-06 14:24:17,553 - Directory['/usr/hdp/current/storm-slider-client/conf'] {'create_parents': True}
2017-06-06 14:24:17,585 - File['/usr/hdp/current/storm-slider-client/conf/storm-slider-env.sh'] {'content': Template('storm-slider-env.sh.j2'), 'mode': 0755}
2017-06-06 14:24:17,586 - Writing File['/usr/hdp/current/storm-slider-client/conf/storm-slider-env.sh'] because contents don't match
2017-06-06 14:24:17,589 - File['/usr/hdp/current/slider-client/conf/log4j.properties'] {'content': ..., 'mode': 0644}
2017-06-06 14:24:17,591 - Writing File['/usr/hdp/current/slider-client/conf/log4j.properties'] because contents don't match
2017-06-06 14:24:17,606 - File['/usr/hdp/current/slider-client/lib/slider.tar.gz'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:17,615 - Changing owner for /usr/hdp/current/slider-client/lib/slider.tar.gz from 0 to hdfs
2017-06-06 14:24:17,623 - Changing group for /usr/hdp/current/slider-client/lib/slider.tar.gz from 0 to hadoop
2017-06-06 14:24:17,624 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:19,242 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:19,243 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:19,243 - FS Type: 
2017-06-06 14:24:19,243 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:19,327 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:19,328 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,408 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,937 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,938 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,938 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,938 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,939 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,939 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,940 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,940 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,940 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,940 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,941 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:20,941 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,941 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,942 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,942 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,942 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,942 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,943 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,943 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,943 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,943 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,943 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,944 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,945 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,945 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,946 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,946 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,946 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,946 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,947 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:20,947 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,947 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!

INFO 2017-06-06 14:24:21,298 ActionQueue.py:382 - End command output log for command with id = 53, role = SLIDER, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,299 RecoveryManager.py:179 - New status, current status is set to INSTALLED for SLIDER
INFO 2017-06-06 14:24:21,299 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=53, current state of SLIDER to INSTALLED
INFO 2017-06-06 14:24:21,302 ActionQueue.py:358 - Quit retrying for command id 47. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,302 ActionQueue.py:363 - Command 47 completed successfully!
INFO 2017-06-06 14:24:21,303 ActionQueue.py:379 - Begin command output log for command with id = 47, role = HDFS_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,303 ActionQueue.py:471 - Cmd log for taskId=47 and chunk 1/2 of log for command: 
2017-06-06 14:23:56,099 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:56,154 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:56,154 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:56,154 - FS Type: 
2017-06-06 14:23:56,155 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:56,296 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:56,322 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:00,743 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:00,815 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:00,997 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:01,157 - checked_call['dpkg -s hdp-select | grep Version | awk '{print $2}''] {'stderr': -1}
2017-06-06 14:24:01,334 - checked_call returned (0, '2.5.4.2-7', '')
2017-06-06 14:24:01,338 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:01,339 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:04,362 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:04,364 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:04,382 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:04,383 - Writing File['/etc/security/limits.d/hdfs.conf'] because it doesn't exist
2017-06-06 14:24:04,384 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,401 - Generating config: /usr/hdp/current/hadoop-client/conf/hadoop-policy.xml
2017-06-06 14:24:04,402 - File['/usr/hdp/current/hadoop-client/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,427 - Writing File['/usr/hdp/current/hadoop-client/conf/hadoop-policy.xml'] because contents don't match
2017-06-06 14:24:04,428 - Changing owner for /usr/hdp/current/hadoop-client/conf/hadoop-policy.xml from 0 to hdfs
2017-06-06 14:24:04,429 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,459 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:24:04,460 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,472 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:04,474 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,492 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:24:04,493 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,503 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,517 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:24:04,518 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,530 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'configurations': ...}
2017-06-06 14:24:04,573 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:24:04,574 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,671 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:04,685 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:04,686 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,733 - File['/usr/hdp/current/hadoop-client/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:04,741 - Writing File['/usr/hdp/current/hadoop-client/conf/slaves'] because contents don't match
2017-06-06 14:24:04,742 - Changing owner for /usr/hdp/current/hadoop-client/conf/slaves from 0 to hdfs
2017-06-06 14:24:04,742 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:05,726 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:05,727 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:05,727 - FS Type: 
2017-06-06 14:24:05,728 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:05,765 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:05,765 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:05,842 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,874 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,876 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,876 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,877 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,877 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,878 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,878 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,879 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,879 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,879 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,880 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
INFO 2017-06-06 14:24:21,303 ActionQueue.py:471 - Cmd log for taskId=47 and chunk 2/2 of log for command: 
2017-06-06 14:24:20,880 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,880 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,881 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,881 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,881 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,882 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,882 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,882 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,883 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,883 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,883 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,883 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,887 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,889 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,890 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,890 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,890 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,894 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,897 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:20,897 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,897 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!
INFO 2017-06-06 14:24:21,303 ActionQueue.py:382 - End command output log for command with id = 47, role = HDFS_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,304 RecoveryManager.py:179 - New status, current status is set to INSTALLED for HDFS_CLIENT
INFO 2017-06-06 14:24:21,305 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=47, current state of HDFS_CLIENT to INSTALLED
INFO 2017-06-06 14:24:21,312 ActionQueue.py:358 - Quit retrying for command id 50. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,313 ActionQueue.py:358 - Quit retrying for command id 52. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,313 ActionQueue.py:363 - Command 50 completed successfully!
INFO 2017-06-06 14:24:21,317 ActionQueue.py:363 - Command 52 completed successfully!
INFO 2017-06-06 14:24:21,318 ActionQueue.py:379 - Begin command output log for command with id = 50, role = MAPREDUCE2_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,321 ActionQueue.py:379 - Begin command output log for command with id = 52, role = PIG, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,321 ActionQueue.py:358 - Quit retrying for command id 56. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,324 ActionQueue.py:471 - Cmd log for taskId=50 and chunk 1/2 of log for command: 
2017-06-06 14:23:58,567 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:58,572 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:58,572 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:58,572 - FS Type: 
2017-06-06 14:23:58,573 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:58,592 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:58,596 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:02,087 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:02,088 - call['ambari-python-wrap /usr/bin/hdp-select status hadoop-yarn-resourcemanager'] {'timeout': 20}
2017-06-06 14:24:02,362 - call returned (0, 'hadoop-yarn-resourcemanager - 2.5.4.2-7')
2017-06-06 14:24:02,379 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:02,535 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:02,559 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:02,559 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,650 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:17,688 - Directory['/var/log/hadoop-yarn/nodemanager/recovery-state'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:17,711 - Directory['/var/run/hadoop-yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:17,715 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:17,718 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:17,731 - Directory['/var/run/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:17,738 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:17,742 - Directory['/var/log/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:17,743 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:17,753 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'group': 'hadoop', 'ignore_failures': True, 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:17,766 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:17,839 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:17,839 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:17,967 - XmlConfig['hdfs-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:18,013 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:24:18,014 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:18,475 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:18,512 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:24:18,512 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:18,664 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 201 to yarn
2017-06-06 14:24:18,668 - XmlConfig['yarn-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:18,700 - Generating config: /usr/hdp/current/hadoop-client/conf/yarn-site.xml
2017-06-06 14:24:18,702 - File['/usr/hdp/current/hadoop-client/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,191 - XmlConfig['capacity-scheduler.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:19,229 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:24:19,229 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,273 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 202 to yarn
2017-06-06 14:24:19,290 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}
2017-06-06 14:24:19,301 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}
2017-06-06 14:24:19,333 - File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] {'content': InlineTemplate(...), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}
2017-06-06 14:24:19,346 - File['/usr/hdp/current/hadoop-yarn-client/bin/container-executor'] {'group': 'hadoop', 'mode': 02050}
2017-06-06 14:24:19,350 - File['/usr/hdp/current/hadoop-client/conf/container-executor.cfg'] {'content': Template('container-executor.cfg.j2'), 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:19,351 - Directory['/cgroups_test/cpu'] {'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:19,354 - File['/usr/hdp/current/hadoop-client/conf/mapred-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'mode': 0755}
2017-06-06 14:24:19,369 - File['/usr/hdp/current/hadoop-client/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:19,372 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:19,402 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:24:19,403 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,480 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 203 to mapred
2017-06-06 14:24:19,481 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
INFO 2017-06-06 14:24:21,328 ActionQueue.py:471 - Cmd log for taskId=50 and chunk 2/2 of log for command: 
2017-06-06 14:24:19,497 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:24:19,497 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,549 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 203 to hdfs
2017-06-06 14:24:19,550 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:19,574 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:24:19,574 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,593 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:19,599 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:19,630 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:24:19,630 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,642 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:19,660 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:24:19,660 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,672 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:24:19,675 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:24:19,678 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,723 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:20,724 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:20,724 - FS Type: 
2017-06-06 14:24:20,724 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:20,772 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:20,773 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:20,818 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,965 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,966 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,966 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,967 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,967 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,967 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,968 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,968 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,968 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,969 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,969 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:20,969 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,970 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,970 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,971 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,971 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,971 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,971 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,972 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,972 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,972 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,973 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,975 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,975 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,975 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,976 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,976 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,976 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,976 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,978 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:20,979 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,979 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!
INFO 2017-06-06 14:24:21,327 ActionQueue.py:363 - Command 56 completed successfully!
INFO 2017-06-06 14:24:21,325 ActionQueue.py:473 - Cmd log for taskId=52: 2017-06-06 14:23:59,332 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:59,389 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:59,389 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:59,389 - FS Type: 
2017-06-06 14:23:59,400 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:59,482 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:59,487 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:02,290 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:02,296 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:04,742 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:04,770 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:04,791 - Directory['/usr/hdp/current/pig-client/conf'] {'owner': 'hdfs', 'create_parents': True, 'group': 'hadoop'}
2017-06-06 14:24:04,903 - Changing owner for /usr/hdp/current/pig-client/conf from 0 to hdfs
2017-06-06 14:24:04,904 - Changing group for /usr/hdp/current/pig-client/conf from 0 to hadoop
2017-06-06 14:24:04,910 - File['/usr/hdp/current/pig-client/conf/pig-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'mode': 0755}
2017-06-06 14:24:04,914 - Writing File['/usr/hdp/current/pig-client/conf/pig-env.sh'] because it doesn't exist
2017-06-06 14:24:04,914 - Changing owner for /usr/hdp/current/pig-client/conf/pig-env.sh from 0 to hdfs
2017-06-06 14:24:04,915 - Changing permission for /usr/hdp/current/pig-client/conf/pig-env.sh from 644 to 755
2017-06-06 14:24:04,915 - File['/usr/hdp/current/pig-client/conf/pig.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:05,054 - Writing File['/usr/hdp/current/pig-client/conf/pig.properties'] because contents don't match
2017-06-06 14:24:05,060 - Changing owner for /usr/hdp/current/pig-client/conf/pig.properties from 0 to hdfs
2017-06-06 14:24:05,061 - Changing group for /usr/hdp/current/pig-client/conf/pig.properties from 0 to hadoop
2017-06-06 14:24:05,063 - File['/usr/hdp/current/pig-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:05,063 - Writing File['/usr/hdp/current/pig-client/conf/log4j.properties'] because it doesn't exist
2017-06-06 14:24:05,073 - Changing owner for /usr/hdp/current/pig-client/conf/log4j.properties from 0 to hdfs
2017-06-06 14:24:05,073 - Changing group for /usr/hdp/current/pig-client/conf/log4j.properties from 0 to hadoop
2017-06-06 14:24:05,074 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:06,151 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:06,152 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:06,152 - FS Type: 
2017-06-06 14:24:06,153 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:06,204 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:06,206 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:06,244 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,901 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,902 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,903 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,903 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,904 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,904 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,905 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,906 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,906 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,907 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,907 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:20,907 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,908 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,908 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,909 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,909 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,909 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,909 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,910 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,910 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,910 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,910 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,911 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,911 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,911 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,911 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,913 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,914 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,915 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,916 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:20,916 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,916 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!

INFO 2017-06-06 14:24:21,330 ActionQueue.py:382 - End command output log for command with id = 50, role = MAPREDUCE2_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,332 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:21,332 ActionQueue.py:379 - Begin command output log for command with id = 56, role = YARN_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,333 ActionQueue.py:382 - End command output log for command with id = 52, role = PIG, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,335 RecoveryManager.py:179 - New status, current status is set to INSTALLED for MAPREDUCE2_CLIENT
INFO 2017-06-06 14:24:21,337 ActionQueue.py:471 - Cmd log for taskId=56 and chunk 1/3 of log for command: 
2017-06-06 14:23:57,016 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:57,022 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:57,022 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:57,022 - FS Type: 
2017-06-06 14:23:57,022 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:57,170 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:57,206 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:00,645 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:00,646 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:00,646 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:00,839 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:00,859 - call['ambari-python-wrap /usr/bin/hdp-select status hadoop-yarn-resourcemanager'] {'timeout': 20}
2017-06-06 14:24:01,180 - call returned (0, 'hadoop-yarn-resourcemanager - 2.5.4.2-7')
2017-06-06 14:24:01,193 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:01,477 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:01,549 - Directory['/var/log/hadoop-yarn/nodemanager/recovery-state'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:01,614 - Creating directory Directory['/var/log/hadoop-yarn/nodemanager/recovery-state'] since it doesn't exist.
2017-06-06 14:24:01,616 - Changing owner for /var/log/hadoop-yarn/nodemanager/recovery-state from 0 to yarn
2017-06-06 14:24:01,616 - Changing group for /var/log/hadoop-yarn/nodemanager/recovery-state from 0 to hadoop
2017-06-06 14:24:01,618 - Directory['/var/run/hadoop-yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:01,618 - Creating directory Directory['/var/run/hadoop-yarn'] since it doesn't exist.
2017-06-06 14:24:01,624 - Changing owner for /var/run/hadoop-yarn from 0 to yarn
2017-06-06 14:24:01,625 - Changing group for /var/run/hadoop-yarn from 0 to hadoop
2017-06-06 14:24:01,625 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:01,625 - Creating directory Directory['/var/run/hadoop-yarn/yarn'] since it doesn't exist.
2017-06-06 14:24:01,627 - Changing owner for /var/run/hadoop-yarn/yarn from 0 to yarn
2017-06-06 14:24:01,628 - Changing group for /var/run/hadoop-yarn/yarn from 0 to hadoop
2017-06-06 14:24:01,629 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:01,630 - Creating directory Directory['/var/log/hadoop-yarn/yarn'] since it doesn't exist.
2017-06-06 14:24:01,686 - Changing owner for /var/log/hadoop-yarn/yarn from 0 to yarn
2017-06-06 14:24:01,698 - Changing group for /var/log/hadoop-yarn/yarn from 0 to hadoop
2017-06-06 14:24:01,699 - Directory['/var/run/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:01,699 - Creating directory Directory['/var/run/hadoop-mapreduce'] since it doesn't exist.
2017-06-06 14:24:01,701 - Changing owner for /var/run/hadoop-mapreduce from 0 to mapred
2017-06-06 14:24:01,706 - Changing group for /var/run/hadoop-mapreduce from 0 to hadoop
2017-06-06 14:24:01,707 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:01,707 - Creating directory Directory['/var/run/hadoop-mapreduce/mapred'] since it doesn't exist.
2017-06-06 14:24:01,708 - Changing owner for /var/run/hadoop-mapreduce/mapred from 0 to mapred
2017-06-06 14:24:01,708 - Changing group for /var/run/hadoop-mapreduce/mapred from 0 to hadoop
2017-06-06 14:24:01,708 - Directory['/var/log/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:01,718 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:01,730 - Creating directory Directory['/var/log/hadoop-mapreduce/mapred'] since it doesn't exist.
2017-06-06 14:24:01,732 - Changing owner for /var/log/hadoop-mapreduce/mapred from 0 to mapred
2017-06-06 14:24:01,733 - Changing group for /var/log/hadoop-mapreduce/mapred from 0 to hadoop
2017-06-06 14:24:01,736 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'group': 'hadoop', 'ignore_failures': True, 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:01,751 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:01,844 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:01,845 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:02,009 - Writing File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] because contents don't match
2017-06-06 14:24:02,010 - Changing owner for /usr/hdp/current/hadoop-client/conf/core-site.xml from 0 to hdfs
2017-06-06 14:24:02,010 - XmlConfig['hdfs-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:02,096 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:24:02,097 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:02,801 - Writing File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] because contents don't match
2017-06-06 14:24:02,802 - Changing owner for /usr/hdp/current/hadoop-client/conf/hdfs-site.xml from 0 to hdfs
2017-06-06 14:24:02,805 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:02,888 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:24:02,888 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:03,010 - Writing File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] because contents don't match
2017-06-06 14:24:03,014 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 0 to yarn
2017-06-06 14:24:03,017 - XmlConfig['yarn-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:03,075 - Generating config: /usr/hdp/current/hadoop-client/conf/yarn-site.xml
2017-06-06 14:24:03,078 - File['/usr/hdp/current/hadoop-client/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
INFO 2017-06-06 14:24:21,340 RecoveryManager.py:179 - New status, current status is set to INSTALLED for PIG
INFO 2017-06-06 14:24:21,340 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=52, current state of PIG to INSTALLED
INFO 2017-06-06 14:24:21,339 ActionQueue.py:471 - Cmd log for taskId=56 and chunk 2/3 of log for command: 
2017-06-06 14:24:03,467 - Writing File['/usr/hdp/current/hadoop-client/conf/yarn-site.xml'] because contents don't match
2017-06-06 14:24:03,473 - Changing owner for /usr/hdp/current/hadoop-client/conf/yarn-site.xml from 0 to yarn
2017-06-06 14:24:03,474 - XmlConfig['capacity-scheduler.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:03,542 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:24:03,546 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:03,722 - Writing File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] because contents don't match
2017-06-06 14:24:03,725 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 0 to yarn
2017-06-06 14:24:03,737 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}
2017-06-06 14:24:03,740 - Writing File['/etc/security/limits.d/yarn.conf'] because it doesn't exist
2017-06-06 14:24:03,746 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}
2017-06-06 14:24:03,748 - Writing File['/etc/security/limits.d/mapreduce.conf'] because it doesn't exist
2017-06-06 14:24:03,764 - File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] {'content': InlineTemplate(...), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}
2017-06-06 14:24:03,765 - Writing File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] because contents don't match
2017-06-06 14:24:03,765 - Changing owner for /usr/hdp/current/hadoop-client/conf/yarn-env.sh from 0 to yarn
2017-06-06 14:24:03,775 - Changing permission for /usr/hdp/current/hadoop-client/conf/yarn-env.sh from 644 to 755
2017-06-06 14:24:03,776 - File['/usr/hdp/current/hadoop-yarn-client/bin/container-executor'] {'group': 'hadoop', 'mode': 02050}
2017-06-06 14:24:03,779 - Changing group for /usr/hdp/current/hadoop-yarn-client/bin/container-executor from 124 to hadoop
2017-06-06 14:24:03,780 - Changing permission for /usr/hdp/current/hadoop-yarn-client/bin/container-executor from 50 to 2050
2017-06-06 14:24:03,794 - File['/usr/hdp/current/hadoop-client/conf/container-executor.cfg'] {'content': Template('container-executor.cfg.j2'), 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:03,837 - Writing File['/usr/hdp/current/hadoop-client/conf/container-executor.cfg'] because contents don't match
2017-06-06 14:24:03,838 - Directory['/cgroups_test/cpu'] {'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:03,839 - Creating directory Directory['/cgroups_test/cpu'] since it doesn't exist.
2017-06-06 14:24:04,029 - Changing group for /cgroups_test/cpu from 0 to hadoop
2017-06-06 14:24:04,031 - File['/usr/hdp/current/hadoop-client/conf/mapred-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'mode': 0755}
2017-06-06 14:24:04,081 - Writing File['/usr/hdp/current/hadoop-client/conf/mapred-env.sh'] because contents don't match
2017-06-06 14:24:04,082 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-env.sh from 0 to hdfs
2017-06-06 14:24:04,082 - Changing permission for /usr/hdp/current/hadoop-client/conf/mapred-env.sh from 644 to 755
2017-06-06 14:24:04,096 - File['/usr/hdp/current/hadoop-client/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:04,097 - Writing File['/usr/hdp/current/hadoop-client/conf/taskcontroller.cfg'] because it doesn't exist
2017-06-06 14:24:04,098 - Changing owner for /usr/hdp/current/hadoop-client/conf/taskcontroller.cfg from 0 to hdfs
2017-06-06 14:24:04,099 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,117 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:24:04,118 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,199 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 203 to mapred
2017-06-06 14:24:04,200 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,218 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:24:04,218 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,244 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 203 to hdfs
2017-06-06 14:24:04,245 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,266 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:24:04,266 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,277 - Writing File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] because it doesn't exist
2017-06-06 14:24:04,278 - Changing owner for /usr/hdp/current/hadoop-client/conf/ssl-client.xml from 0 to hdfs
2017-06-06 14:24:04,278 - Changing group for /usr/hdp/current/hadoop-client/conf/ssl-client.xml from 0 to hadoop
2017-06-06 14:24:04,279 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:04,279 - Creating directory Directory['/usr/hdp/current/hadoop-client/conf/secure'] since it doesn't exist.
2017-06-06 14:24:04,280 - Changing group for /usr/hdp/current/hadoop-client/conf/secure from 0 to hadoop
2017-06-06 14:24:04,282 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,306 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:24:04,307 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,318 - Writing File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] because it doesn't exist
2017-06-06 14:24:04,321 - Changing owner for /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml from 0 to hdfs
2017-06-06 14:24:04,322 - Changing group for /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml from 0 to hadoop
2017-06-06 14:24:04,322 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:04,345 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:24:04,345 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:04,355 - Writing File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] because it doesn't exist
2017-06-06 14:24:04,356 - Changing owner for /usr/hdp/current/hadoop-client/conf/ssl-server.xml from 0 to hdfs
INFO 2017-06-06 14:24:21,343 ActionQueue.py:471 - Cmd log for taskId=56 and chunk 3/3 of log for command: 
2017-06-06 14:24:04,358 - Changing group for /usr/hdp/current/hadoop-client/conf/ssl-server.xml from 0 to hadoop
2017-06-06 14:24:04,359 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:24:04,360 - Changing owner for /usr/hdp/current/hadoop-client/conf/ssl-client.xml.example from 0 to mapred
2017-06-06 14:24:04,361 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:24:04,361 - Changing owner for /usr/hdp/current/hadoop-client/conf/ssl-server.xml.example from 0 to mapred
2017-06-06 14:24:04,362 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:05,287 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:05,294 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:05,294 - FS Type: 
2017-06-06 14:24:05,294 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:05,348 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:05,350 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:05,430 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,852 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,853 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:20,854 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:20,855 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:20,856 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:20,856 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:20,857 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:20,857 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:20,857 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:20,858 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:20,858 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:20,858 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:20,859 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:20,859 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:20,859 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:20,860 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:20,860 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:20,860 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:20,861 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:20,861 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:20,861 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:20,862 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:20,862 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:20,863 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:20,863 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:20,867 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:20,867 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:20,867 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:20,871 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:20,871 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:20,871 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:20,873 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!
INFO 2017-06-06 14:24:21,343 ActionQueue.py:382 - End command output log for command with id = 56, role = YARN_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,344 RecoveryManager.py:179 - New status, current status is set to INSTALLED for YARN_CLIENT
INFO 2017-06-06 14:24:21,345 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=56, current state of YARN_CLIENT to INSTALLED
INFO 2017-06-06 14:24:21,342 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=50, current state of MAPREDUCE2_CLIENT to INSTALLED
INFO 2017-06-06 14:24:21,640 AlertSchedulerHandler.py:271 - [AlertScheduler] Caching cluster davidmod05cluster with alert hash 7c47af1ecdc089b3ddea8ca59c708fd9
INFO 2017-06-06 14:24:21,720 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling hive_metastore_process with UUID e2ab050a-fe02-4af3-bdd6-ca9f1b322570
INFO 2017-06-06 14:24:21,721 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling hive_server_process with UUID 8587a5f2-cc6b-408d-9cf8-165bb04e4c9b
INFO 2017-06-06 14:24:21,721 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling hive_webhcat_server_status with UUID d3bc6613-ddf4-45e5-adbe-9868cefd597d
INFO 2017-06-06 14:24:21,722 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_cpu with UUID 758c40ef-117a-4a82-9678-50e06345b9cc
INFO 2017-06-06 14:24:21,723 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_hdfs_pending_deletion_blocks with UUID 427b2ea4-fa98-42d7-9fbb-aa508a3619da
INFO 2017-06-06 14:24:21,723 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_client_rpc_queue_latency_daily with UUID 1cae0953-eb01-4036-9f34-863467899dc0
INFO 2017-06-06 14:24:21,724 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_ha_health with UUID 133d9279-67f4-4854-acfa-e019021b4642
INFO 2017-06-06 14:24:21,724 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling datanode_health_summary with UUID 1e12a392-5f99-4a99-b42c-36982090d9c4
INFO 2017-06-06 14:24:21,724 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_service_rpc_queue_latency_daily with UUID 4b049e25-2bda-43d7-899a-a22e26d1a52b
INFO 2017-06-06 14:24:21,725 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_client_rpc_processing_latency_daily with UUID 554155d4-e0c8-4652-a33b-dfde4e5843c4
INFO 2017-06-06 14:24:21,725 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_hdfs_blocks_health with UUID 5d825be1-8a0a-4754-97b7-e9be788b9838
INFO 2017-06-06 14:24:21,725 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_webui with UUID b5d8f062-d8ef-48f0-bf90-0eb0950bd3ae
INFO 2017-06-06 14:24:21,726 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_service_rpc_processing_latency_hourly with UUID 1696944a-f8d6-4bf2-8f53-cacc7dbc7f0e
INFO 2017-06-06 14:24:21,726 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_increase_in_storage_capacity_usage_daily with UUID cd5a2aca-dcfe-425a-b405-e65425948fb0
INFO 2017-06-06 14:24:21,726 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_client_rpc_queue_latency_hourly with UUID eec0d49e-e781-41f7-96d2-264282936b3f
INFO 2017-06-06 14:24:21,727 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_service_rpc_processing_latency_daily with UUID 8c670c51-86d8-454b-8950-aacac1f21539
INFO 2017-06-06 14:24:21,727 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling upgrade_finalized_state with UUID 5829a394-fc63-4155-accb-1e8af3218edb
INFO 2017-06-06 14:24:21,728 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_client_rpc_processing_latency_hourly with UUID a8a4b2ec-f20a-4b77-8184-ded3cfe36431
INFO 2017-06-06 14:24:21,728 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_increase_in_storage_capacity_usage_weekly with UUID 78ecef82-ffb8-4ab9-b66c-d5fc2d4c808c
INFO 2017-06-06 14:24:21,729 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling hdfs_zookeeper_failover_controller_process with UUID ee3ef62d-8c6b-41ed-bffb-fa395d1c3b96
INFO 2017-06-06 14:24:21,729 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_directory_status with UUID db6bc1ec-d3e1-460b-8554-dfaa3d48c539
INFO 2017-06-06 14:24:21,729 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_service_rpc_queue_latency_hourly with UUID 3df12336-d753-423f-a38e-40f27a663041
INFO 2017-06-06 14:24:21,730 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling increase_nn_heap_usage_weekly with UUID 451458a1-dc4b-4aad-9728-da3f5160fc00
INFO 2017-06-06 14:24:21,730 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_hdfs_capacity_utilization with UUID 4e19383d-1d36-4326-a193-dc96f1e4c09f
INFO 2017-06-06 14:24:21,730 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_rpc_latency with UUID ccccfe5b-f026-4bcb-b2c4-418be26b21d2
INFO 2017-06-06 14:24:21,731 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling namenode_last_checkpoint with UUID 344df066-12ab-479c-bc8d-3598d38e08fc
INFO 2017-06-06 14:24:21,731 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling increase_nn_heap_usage_daily with UUID 8883cd58-33cd-4567-bdb7-429e758594fa
INFO 2017-06-06 14:24:21,731 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling yarn_resourcemanager_webui with UUID 89f79172-183f-4646-8e25-7453bc07b951
INFO 2017-06-06 14:24:21,732 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling yarn_resourcemanager_cpu with UUID 5f0d4efa-fc10-4f89-87fc-6418d0e5953c
INFO 2017-06-06 14:24:21,732 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling yarn_resourcemanager_rpc_latency with UUID b718c578-73c8-4fa8-a135-de3870a8602f
INFO 2017-06-06 14:24:21,732 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling nodemanager_health_summary with UUID 9e62a6e1-1eab-455e-8594-3f3bdc9289bb
INFO 2017-06-06 14:24:21,733 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling yarn_app_timeline_server_webui with UUID 8113daaa-162d-49cb-a2dc-6f4ab47d9e77
INFO 2017-06-06 14:24:21,733 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling ams_metrics_monitor_process with UUID 8ffd051e-22ae-4ba9-b4ce-eb0c49217d4d
INFO 2017-06-06 14:24:21,733 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling ams_metrics_collector_process with UUID bc262790-2491-4b2d-ab9e-b10d00ec36d4
INFO 2017-06-06 14:24:21,734 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling ams_metrics_collector_hbase_master_process with UUID cc1a3595-d960-43e0-a080-5c5cd1e37db3
INFO 2017-06-06 14:24:21,734 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling ams_metrics_collector_hbase_master_cpu with UUID df41736d-03f0-4bb2-a24c-433b177a3618
INFO 2017-06-06 14:24:21,734 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling ams_metrics_collector_autostart with UUID a756a031-a7c7-4a84-837e-3bf0b0856ce0
INFO 2017-06-06 14:24:21,739 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling mapreduce_history_server_process with UUID 53a2f67a-bf17-43de-804a-35f0c59c54f5
INFO 2017-06-06 14:24:21,742 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling mapreduce_history_server_webui with UUID 08b14019-8b59-4654-8525-4f7ffcd9fada
INFO 2017-06-06 14:24:21,742 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling mapreduce_history_server_rpc_latency with UUID 4d7f6c54-e18a-46b4-9da9-8b96e98d6bb8
INFO 2017-06-06 14:24:21,743 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling mapreduce_history_server_cpu with UUID 15628223-09cb-43ed-a3d7-56c146580d96
INFO 2017-06-06 14:24:21,744 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling oozie_server_webui with UUID 9e0ab52f-e257-44ec-94cf-67315edb36a0
INFO 2017-06-06 14:24:21,745 AlertSchedulerHandler.py:356 - [AlertScheduler] Scheduling oozie_server_status with UUID 66c3b7f4-c87a-4e49-ba38-2b7c7a5d9b42
INFO 2017-06-06 14:24:21,745 AlertSchedulerHandler.py:211 - [AlertScheduler] Reschedule Summary: 43 rescheduled, 0 unscheduled
INFO 2017-06-06 14:24:21,898 ActionQueue.py:358 - Quit retrying for command id 49. Status: COMPLETED, retryAble: True, retryDuration (sec): 569, last delay (sec): 1
INFO 2017-06-06 14:24:21,898 ActionQueue.py:363 - Command 49 completed successfully!
INFO 2017-06-06 14:24:21,898 ActionQueue.py:379 - Begin command output log for command with id = 49, role = HIVE_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,899 ActionQueue.py:471 - Cmd log for taskId=49 and chunk 1/2 of log for command: 
2017-06-06 14:23:58,235 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:58,265 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:58,265 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:58,265 - FS Type: 
2017-06-06 14:23:58,266 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:58,524 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:58,547 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:02,160 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:02,297 - call['ambari-python-wrap /usr/bin/hdp-select status hive-server2'] {'timeout': 20}
2017-06-06 14:24:02,583 - call returned (0, 'hive-server2 - 2.5.4.2-7')
2017-06-06 14:24:02,584 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:02,856 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:02,857 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:19,678 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:19,682 - Directory['/etc/hive'] {'mode': 0755}
2017-06-06 14:24:19,683 - Directories to fill with configs: [u'/usr/hdp/current/hive-client/conf']
2017-06-06 14:24:19,684 - Directory['/usr/hdp/current/hive-client/conf'] {'owner': 'hive', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:19,685 - Changing owner for /usr/hdp/current/hive-client/conf from 0 to hive
2017-06-06 14:24:19,686 - Changing group for /usr/hdp/current/hive-client/conf from 0 to hadoop
2017-06-06 14:24:19,686 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:19,721 - Generating config: /usr/hdp/current/hive-client/conf/mapred-site.xml
2017-06-06 14:24:19,722 - File['/usr/hdp/current/hive-client/conf/mapred-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:19,903 - Writing File['/usr/hdp/current/hive-client/conf/mapred-site.xml'] because it doesn't exist
2017-06-06 14:24:19,903 - Changing owner for /usr/hdp/current/hive-client/conf/mapred-site.xml from 0 to hive
2017-06-06 14:24:19,904 - Changing group for /usr/hdp/current/hive-client/conf/mapred-site.xml from 0 to hadoop
2017-06-06 14:24:19,904 - File['/usr/hdp/current/hive-client/conf/hive-default.xml.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:19,905 - Changing owner for /usr/hdp/current/hive-client/conf/hive-default.xml.template from 0 to hive
2017-06-06 14:24:19,905 - Changing group for /usr/hdp/current/hive-client/conf/hive-default.xml.template from 0 to hadoop
2017-06-06 14:24:19,905 - File['/usr/hdp/current/hive-client/conf/hive-env.sh.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:19,906 - Changing owner for /usr/hdp/current/hive-client/conf/hive-env.sh.template from 0 to hive
2017-06-06 14:24:19,906 - Changing group for /usr/hdp/current/hive-client/conf/hive-env.sh.template from 0 to hadoop
2017-06-06 14:24:19,907 - File['/usr/hdp/current/hive-client/conf/hive-exec-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:19,907 - Writing File['/usr/hdp/current/hive-client/conf/hive-exec-log4j.properties'] because contents don't match
2017-06-06 14:24:19,909 - Changing owner for /usr/hdp/current/hive-client/conf/hive-exec-log4j.properties from 0 to hive
2017-06-06 14:24:19,909 - Changing group for /usr/hdp/current/hive-client/conf/hive-exec-log4j.properties from 0 to hadoop
2017-06-06 14:24:19,910 - File['/usr/hdp/current/hive-client/conf/hive-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:19,910 - Writing File['/usr/hdp/current/hive-client/conf/hive-log4j.properties'] because contents don't match
2017-06-06 14:24:19,911 - Changing owner for /usr/hdp/current/hive-client/conf/hive-log4j.properties from 0 to hive
2017-06-06 14:24:19,911 - Changing group for /usr/hdp/current/hive-client/conf/hive-log4j.properties from 0 to hadoop
2017-06-06 14:24:19,912 - XmlConfig['hive-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-client/conf', 'mode': 0644, 'configuration_attributes': {u'hidden': {u'javax.jdo.option.ConnectionPassword': u'HIVE_CLIENT,WEBHCAT_SERVER,HCAT,CONFIG_DOWNLOAD'}}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:19,927 - Generating config: /usr/hdp/current/hive-client/conf/hive-site.xml
2017-06-06 14:24:19,928 - File['/usr/hdp/current/hive-client/conf/hive-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:20,376 - File['/usr/hdp/current/hive-client/conf/hive-env.sh'] {'content': InlineTemplate(...), 'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:20,376 - Writing File['/usr/hdp/current/hive-client/conf/hive-env.sh'] because it doesn't exist
2017-06-06 14:24:20,379 - Changing owner for /usr/hdp/current/hive-client/conf/hive-env.sh from 0 to hive
2017-06-06 14:24:20,380 - Changing group for /usr/hdp/current/hive-client/conf/hive-env.sh from 0 to hadoop
2017-06-06 14:24:20,380 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:20,387 - File['/etc/security/limits.d/hive.conf'] {'content': Template('hive.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:20,390 - Writing File['/etc/security/limits.d/hive.conf'] because it doesn't exist
2017-06-06 14:24:20,393 - File['/usr/lib/ambari-agent/DBConnectionVerification.jar'] {'content': DownloadSource('http://10.0.0.13:8080/resources/DBConnectionVerification.jar'), 'mode': 0644}
2017-06-06 14:24:20,393 - Downloading the file from http://10.0.0.13:8080/resources/DBConnectionVerification.jar
2017-06-06 14:24:20,403 - Writing File['/usr/lib/ambari-agent/DBConnectionVerification.jar'] because it doesn't exist
2017-06-06 14:24:20,404 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:21,759 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:21,759 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:21,760 - FS Type: 
2017-06-06 14:24:21,760 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:21,804 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:21,805 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:21,841 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:21,842 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:21,843 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:21,843 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:21,843 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:21,843 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
INFO 2017-06-06 14:24:21,899 ActionQueue.py:471 - Cmd log for taskId=49 and chunk 2/2 of log for command: 
2017-06-06 14:24:21,844 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
2017-06-06 14:24:21,844 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:21,844 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:21,844 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:21,845 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:21,845 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:21,845 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:21,846 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:21,846 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:21,846 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:21,847 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:21,847 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:21,847 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:21,847 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:21,847 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:21,847 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:21,848 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:21,848 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:21,848 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:21,848 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:21,849 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:21,849 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:21,849 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:21,849 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:21,850 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:21,850 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:21,850 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!
INFO 2017-06-06 14:24:21,899 ActionQueue.py:382 - End command output log for command with id = 49, role = HIVE_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:21,899 RecoveryManager.py:179 - New status, current status is set to INSTALLED for HIVE_CLIENT
INFO 2017-06-06 14:24:21,900 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=49, current state of HIVE_CLIENT to INSTALLED
INFO 2017-06-06 14:24:22,559 ActionQueue.py:358 - Quit retrying for command id 51. Status: COMPLETED, retryAble: True, retryDuration (sec): 568, last delay (sec): 1
INFO 2017-06-06 14:24:22,559 ActionQueue.py:363 - Command 51 completed successfully!
INFO 2017-06-06 14:24:22,560 ActionQueue.py:379 - Begin command output log for command with id = 51, role = OOZIE_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:22,560 ActionQueue.py:471 - Cmd log for taskId=51 and chunk 1/2 of log for command: 
2017-06-06 14:23:56,961 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:23:57,012 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:23:57,012 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:23:57,013 - FS Type: 
2017-06-06 14:23:57,013 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:23:57,155 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:23:57,159 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:01,481 - Node has all packages pre-installed. Skipping.
2017-06-06 14:24:01,482 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,404 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:20,434 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:20,525 - checked_call['dpkg -s hdp-select | grep Version | awk '{print $2}''] {'stderr': -1}
2017-06-06 14:24:20,621 - checked_call returned (0, '2.5.4.2-7', '')
2017-06-06 14:24:20,624 - Directory['/usr/hdp/current/oozie-client/conf'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop'}
2017-06-06 14:24:20,628 - Changing owner for /usr/hdp/current/oozie-client/conf from 0 to oozie
2017-06-06 14:24:20,628 - Changing group for /usr/hdp/current/oozie-client/conf from 0 to hadoop
2017-06-06 14:24:20,628 - XmlConfig['oozie-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/oozie-client/conf', 'mode': 0664, 'configuration_attributes': {}, 'owner': 'oozie', 'configurations': ...}
2017-06-06 14:24:20,648 - Generating config: /usr/hdp/current/oozie-client/conf/oozie-site.xml
2017-06-06 14:24:20,648 - File['/usr/hdp/current/oozie-client/conf/oozie-site.xml'] {'owner': 'oozie', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0664, 'encoding': 'UTF-8'}
2017-06-06 14:24:20,684 - Writing File['/usr/hdp/current/oozie-client/conf/oozie-site.xml'] because contents don't match
2017-06-06 14:24:20,684 - Changing owner for /usr/hdp/current/oozie-client/conf/oozie-site.xml from 0 to oozie
2017-06-06 14:24:20,685 - Changing group for /usr/hdp/current/oozie-client/conf/oozie-site.xml from 0 to hadoop
2017-06-06 14:24:20,685 - Changing permission for /usr/hdp/current/oozie-client/conf/oozie-site.xml from 644 to 664
2017-06-06 14:24:20,690 - File['/usr/hdp/current/oozie-client/conf/oozie-env.sh'] {'content': InlineTemplate(...), 'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:20,691 - Writing File['/usr/hdp/current/oozie-client/conf/oozie-env.sh'] because contents don't match
2017-06-06 14:24:20,693 - Changing group for /usr/hdp/current/oozie-client/conf/oozie-env.sh from 0 to hadoop
2017-06-06 14:24:20,694 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:20,764 - File['/etc/security/limits.d/oozie.conf'] {'content': Template('oozie.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:20,773 - Writing File['/etc/security/limits.d/oozie.conf'] because it doesn't exist
2017-06-06 14:24:20,784 - File['/usr/hdp/current/oozie-client/conf/oozie-log4j.properties'] {'content': ..., 'owner': 'oozie', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:20,784 - Writing File['/usr/hdp/current/oozie-client/conf/oozie-log4j.properties'] because contents don't match
2017-06-06 14:24:20,793 - Changing owner for /usr/hdp/current/oozie-client/conf/oozie-log4j.properties from 0 to oozie
2017-06-06 14:24:20,805 - Changing group for /usr/hdp/current/oozie-client/conf/oozie-log4j.properties from 0 to hadoop
2017-06-06 14:24:20,828 - File['/usr/hdp/current/oozie-client/conf/adminusers.txt'] {'content': Template('adminusers.txt.j2'), 'owner': 'oozie', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:20,829 - Writing File['/usr/hdp/current/oozie-client/conf/adminusers.txt'] because contents don't match
2017-06-06 14:24:20,830 - Changing owner for /usr/hdp/current/oozie-client/conf/adminusers.txt from 0 to oozie
2017-06-06 14:24:20,830 - Changing group for /usr/hdp/current/oozie-client/conf/adminusers.txt from 0 to hadoop
2017-06-06 14:24:20,831 - File['/usr/lib/ambari-agent/DBConnectionVerification.jar'] {'content': DownloadSource('http://10.0.0.13:8080/resources/DBConnectionVerification.jar')}
2017-06-06 14:24:20,831 - Not downloading the file from http://10.0.0.13:8080/resources/DBConnectionVerification.jar, because /var/lib/ambari-agent/tmp/DBConnectionVerification.jar already exists
2017-06-06 14:24:20,832 - File['/usr/hdp/current/oozie-client/conf/hadoop-config.xml'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:20,832 - Changing owner for /usr/hdp/current/oozie-client/conf/hadoop-config.xml from 0 to oozie
2017-06-06 14:24:20,833 - Changing group for /usr/hdp/current/oozie-client/conf/hadoop-config.xml from 0 to hadoop
2017-06-06 14:24:20,833 - File['/usr/hdp/current/oozie-client/conf/oozie-default.xml'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:20,833 - Writing File['/usr/hdp/current/oozie-client/conf/oozie-default.xml'] because it doesn't exist
2017-06-06 14:24:20,834 - Changing owner for /usr/hdp/current/oozie-client/conf/oozie-default.xml from 0 to oozie
2017-06-06 14:24:20,834 - Changing group for /usr/hdp/current/oozie-client/conf/oozie-default.xml from 0 to hadoop
2017-06-06 14:24:20,835 - Directory['/usr/hdp/current/oozie-client/conf/action-conf'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:20,836 - Changing owner for /usr/hdp/current/oozie-client/conf/action-conf from 0 to oozie
2017-06-06 14:24:20,836 - Changing group for /usr/hdp/current/oozie-client/conf/action-conf from 0 to hadoop
2017-06-06 14:24:20,836 - File['/usr/hdp/current/oozie-client/conf/action-conf/hive.xml'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:20,837 - Changing owner for /usr/hdp/current/oozie-client/conf/action-conf/hive.xml from 0 to oozie
2017-06-06 14:24:20,837 - Changing group for /usr/hdp/current/oozie-client/conf/action-conf/hive.xml from 0 to hadoop
2017-06-06 14:24:20,838 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:22,383 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:22,385 - Skipping running stack-selector-tool for stack 2.5 as its a sys_prepped host. This may cause symlink pointers not to be created for HDP componets installed later on top of an already sys_prepped host.
2017-06-06 14:24:22,385 - FS Type: 
2017-06-06 14:24:22,397 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'only_if': 'ls /usr/hdp/current/hadoop-client/conf', 'configurations': ...}
2017-06-06 14:24:22,449 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:22,450 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:22,481 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:22,481 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:22,482 - Skipping /etc/nifi/conf as it does not exist.
2017-06-06 14:24:22,482 - /etc/ranger/kms/conf is already linked to /etc/ranger-kms/2.5.4.2-7/0
2017-06-06 14:24:22,483 - /etc/hive2/conf is already linked to /etc/hive2/2.5.4.2-7/0
2017-06-06 14:24:22,483 - /etc/zookeeper/conf is already linked to /etc/zookeeper/2.5.4.2-7/0
2017-06-06 14:24:22,483 - /etc/kafka/conf is already linked to /etc/kafka/2.5.4.2-7/0
INFO 2017-06-06 14:24:22,560 ActionQueue.py:471 - Cmd log for taskId=51 and chunk 2/2 of log for command: 
2017-06-06 14:24:22,483 - /etc/tez/conf is already linked to /etc/tez/2.5.4.2-7/0
2017-06-06 14:24:22,484 - /etc/oozie/conf is already linked to /etc/oozie/2.5.4.2-7/0
2017-06-06 14:24:22,484 - /etc/hbase/conf is already linked to /etc/hbase/2.5.4.2-7/0
2017-06-06 14:24:22,484 - /etc/spark/conf is already linked to /etc/spark/2.5.4.2-7/0
2017-06-06 14:24:22,484 - /etc/ranger/tagsync/conf is already linked to /etc/ranger-tagsync/2.5.4.2-7/0
2017-06-06 14:24:22,485 - /etc/ranger/usersync/conf is already linked to /etc/ranger-usersync/2.5.4.2-7/0
2017-06-06 14:24:22,486 - /etc/hadoop/conf is already linked to /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:24:22,486 - /etc/mahout/conf is already linked to /etc/mahout/2.5.4.2-7/0
2017-06-06 14:24:22,486 - /etc/storm/conf is already linked to /etc/storm/2.5.4.2-7/0
2017-06-06 14:24:22,486 - Skipping /etc/atlas/conf as it does not exist.
2017-06-06 14:24:22,487 - /etc/ranger/admin/conf is already linked to /etc/ranger-admin/2.5.4.2-7/0
2017-06-06 14:24:22,487 - Skipping /etc/flume/conf as it does not exist.
2017-06-06 14:24:22,487 - /etc/sqoop/conf is already linked to /etc/sqoop/2.5.4.2-7/0
2017-06-06 14:24:22,487 - Skipping /etc/accumulo/conf as it does not exist.
2017-06-06 14:24:22,487 - Skipping /etc/phoenix/conf as it does not exist.
2017-06-06 14:24:22,488 - /etc/storm-slider-client/conf is already linked to /etc/storm-slider-client/2.5.4.2-7/0
2017-06-06 14:24:22,488 - /etc/slider/conf is already linked to /etc/slider/2.5.4.2-7/0
2017-06-06 14:24:22,488 - /etc/zeppelin/conf is already linked to /etc/zeppelin/2.5.4.2-7/0
2017-06-06 14:24:22,488 - /etc/hive-webhcat/conf is already linked to /etc/hive-webhcat/2.5.4.2-7/0
2017-06-06 14:24:22,488 - /etc/hive-hcatalog/conf is already linked to /etc/hive-hcatalog/2.5.4.2-7/0
2017-06-06 14:24:22,489 - /etc/falcon/conf is already linked to /etc/falcon/2.5.4.2-7/0
2017-06-06 14:24:22,489 - Skipping /etc/knox/conf as it does not exist.
2017-06-06 14:24:22,489 - /etc/pig/conf is already linked to /etc/pig/2.5.4.2-7/0
2017-06-06 14:24:22,489 - /etc/spark2/conf is already linked to /etc/spark2/2.5.4.2-7/0
2017-06-06 14:24:22,490 - /etc/hive/conf is already linked to /etc/hive/2.5.4.2-7/0
2017-06-06 14:24:22,490 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file

Command completed successfully!
INFO 2017-06-06 14:24:22,560 ActionQueue.py:382 - End command output log for command with id = 51, role = OOZIE_CLIENT, roleCommand = INSTALL
INFO 2017-06-06 14:24:22,561 RecoveryManager.py:179 - New status, current status is set to INSTALLED for OOZIE_CLIENT
INFO 2017-06-06 14:24:22,561 ActionQueue.py:419 - After EXECUTION_COMMAND (STOP/INSTALL), with taskId=51, current state of OOZIE_CLIENT to INSTALLED
INFO 2017-06-06 14:24:22,646 RecoveryManager.py:255 - HIVE_METASTORE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,646 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,647 RecoveryManager.py:255 - RESOURCEMANAGER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,648 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,648 RecoveryManager.py:255 - WEBHCAT_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,648 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,648 RecoveryManager.py:255 - METRICS_MONITOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,649 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,649 RecoveryManager.py:255 - OOZIE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,649 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,649 RecoveryManager.py:255 - METRICS_COLLECTOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,650 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,650 RecoveryManager.py:255 - NAMENODE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,650 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,650 RecoveryManager.py:255 - HIVE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,650 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:22,651 RecoveryManager.py:255 - ZKFC needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:22,651 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,804 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:23,839 RecoveryManager.py:255 - HIVE_METASTORE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,839 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,839 RecoveryManager.py:255 - RESOURCEMANAGER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,839 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,840 RecoveryManager.py:255 - WEBHCAT_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,841 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,841 RecoveryManager.py:255 - METRICS_MONITOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,841 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,841 RecoveryManager.py:255 - OOZIE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,842 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,842 RecoveryManager.py:255 - METRICS_COLLECTOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,842 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,842 RecoveryManager.py:255 - NAMENODE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,842 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,842 RecoveryManager.py:255 - HIVE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,843 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,843 RecoveryManager.py:255 - ZKFC needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:23,843 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:23,918 AlertSchedulerHandler.py:271 - [AlertScheduler] Caching cluster davidmod05cluster with alert hash 7c47af1ecdc089b3ddea8ca59c708fd9
INFO 2017-06-06 14:24:23,952 AlertSchedulerHandler.py:211 - [AlertScheduler] Reschedule Summary: 0 rescheduled, 0 unscheduled
INFO 2017-06-06 14:24:24,865 RecoveryManager.py:255 - HIVE_METASTORE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,866 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,866 RecoveryManager.py:255 - RESOURCEMANAGER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,866 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,866 RecoveryManager.py:255 - WEBHCAT_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,866 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,866 RecoveryManager.py:255 - METRICS_MONITOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,867 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,867 RecoveryManager.py:255 - OOZIE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,867 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,867 RecoveryManager.py:255 - METRICS_COLLECTOR needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,867 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,868 RecoveryManager.py:255 - NAMENODE needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,868 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,868 RecoveryManager.py:255 - HIVE_SERVER needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,868 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:24,868 RecoveryManager.py:255 - ZKFC needs recovery, desired = STARTED, and current = INSTALLED.
INFO 2017-06-06 14:24:24,868 RecoveryManager.py:822 - Recovery is paused, likely tasks waiting in pipeline for this host.
INFO 2017-06-06 14:24:26,736 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:26,771 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:26,815 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:26,851 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:26,892 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:26,946 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:27,001 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:27,059 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:27,107 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of HIVE_METASTORE to STARTED
INFO 2017-06-06 14:24:27,108 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of HIVE_SERVER to STARTED
INFO 2017-06-06 14:24:27,108 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of METRICS_COLLECTOR to STARTED
INFO 2017-06-06 14:24:27,108 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of METRICS_MONITOR to STARTED
INFO 2017-06-06 14:24:27,108 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of OOZIE_SERVER to STARTED
INFO 2017-06-06 14:24:27,108 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of RESOURCEMANAGER to STARTED
INFO 2017-06-06 14:24:27,108 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of WEBHCAT_SERVER to STARTED
INFO 2017-06-06 14:24:27,109 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of ZKFC to STARTED
INFO 2017-06-06 14:24:27,109 Controller.py:246 - Adding 8 commands. Heartbeat id = 36
INFO 2017-06-06 14:24:27,109 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role HIVE_METASTORE for service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,109 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role HIVE_SERVER for service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,109 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role METRICS_COLLECTOR for service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,110 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role METRICS_MONITOR for service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,110 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role OOZIE_SERVER for service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,110 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role RESOURCEMANAGER for service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,110 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role WEBHCAT_SERVER for service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,110 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role ZKFC for service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:27,139 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=57
INFO 2017-06-06 14:24:27,140 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 57 for role = HIVE_METASTORE of cluster davidmod05cluster.
INFO 2017-06-06 14:24:27,140 ActionQueue.py:316 - Command execution metadata - taskId = 57, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:24:27,141 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=58
INFO 2017-06-06 14:24:27,143 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=59
INFO 2017-06-06 14:24:27,144 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 58 for role = HIVE_SERVER of cluster davidmod05cluster.
INFO 2017-06-06 14:24:27,144 ActionQueue.py:316 - Command execution metadata - taskId = 58, retry enabled = True, max retry duration (sec) = 600, log_output = True
WARNING 2017-06-06 14:24:27,146 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-57.txt'
INFO 2017-06-06 14:24:27,147 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=60
INFO 2017-06-06 14:24:27,148 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 59 for role = METRICS_COLLECTOR of cluster davidmod05cluster.
WARNING 2017-06-06 14:24:27,156 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-58.txt'
INFO 2017-06-06 14:24:27,161 ActionQueue.py:316 - Command execution metadata - taskId = 59, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:24:27,174 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 60 for role = METRICS_MONITOR of cluster davidmod05cluster.
INFO 2017-06-06 14:24:27,174 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=62
INFO 2017-06-06 14:24:27,176 ActionQueue.py:316 - Command execution metadata - taskId = 60, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:24:27,190 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=63
INFO 2017-06-06 14:24:27,214 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 63 for role = RESOURCEMANAGER of cluster davidmod05cluster.
INFO 2017-06-06 14:24:27,214 ActionQueue.py:316 - Command execution metadata - taskId = 63, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:24:27,215 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=64
INFO 2017-06-06 14:24:27,202 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 62 for role = OOZIE_SERVER of cluster davidmod05cluster.
INFO 2017-06-06 14:24:27,250 ActionQueue.py:316 - Command execution metadata - taskId = 62, retry enabled = True, max retry duration (sec) = 600, log_output = True
WARNING 2017-06-06 14:24:27,265 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-57.txt'
WARNING 2017-06-06 14:24:27,298 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-58.txt'
WARNING 2017-06-06 14:24:27,299 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-59.txt'
WARNING 2017-06-06 14:24:27,304 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-60.txt'
WARNING 2017-06-06 14:24:27,326 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-62.txt'
WARNING 2017-06-06 14:24:27,326 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-63.txt'
INFO 2017-06-06 14:24:27,337 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=65
INFO 2017-06-06 14:24:27,358 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 65 for role = ZKFC of cluster davidmod05cluster.
INFO 2017-06-06 14:24:27,337 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 64 for role = WEBHCAT_SERVER of cluster davidmod05cluster.
INFO 2017-06-06 14:24:27,379 ActionQueue.py:316 - Command execution metadata - taskId = 65, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:24:27,380 ActionQueue.py:316 - Command execution metadata - taskId = 64, retry enabled = True, max retry duration (sec) = 600, log_output = True
INFO 2017-06-06 14:24:37,411 ActionQueue.py:358 - Quit retrying for command id 58. Status: COMPLETED, retryAble: True, retryDuration (sec): 590, last delay (sec): 1
INFO 2017-06-06 14:24:37,412 ActionQueue.py:363 - Command 58 completed successfully!
INFO 2017-06-06 14:24:37,412 ActionQueue.py:379 - Begin command output log for command with id = 58, role = HIVE_SERVER, roleCommand = START
INFO 2017-06-06 14:24:37,413 ActionQueue.py:471 - Cmd log for taskId=58 and chunk 1/3 of log for command: 
2017-06-06 14:24:30,641 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,554 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,564 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:31,565 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:31,565 - FS Type: 
2017-06-06 14:24:31,565 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:31,594 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,596 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:31,639 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:31,727 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:31,728 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:31,731 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:31,732 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:31,742 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,750 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,753 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:31,810 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,823 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:31,824 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,832 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:31,852 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:33,458 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:33,479 - call['ambari-python-wrap /usr/bin/hdp-select status hive-server2'] {'timeout': 20}
2017-06-06 14:24:33,629 - call returned (0, 'hive-server2 - 2.5.4.2-7')
2017-06-06 14:24:33,670 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:33,795 - Execute['find /var/log/hive -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'hive'}
2017-06-06 14:24:34,330 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:35,986 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:35,996 - HdfsResource['/user/hcat'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': 'missing_principal', 'user': 'hdfs', 'owner': 'hcat', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0755}
2017-06-06 14:24:36,002 - Skipping 'HdfsResource['/user/hcat']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:24:36,008 - Called copy_to_hdfs tarball: mapreduce
2017-06-06 14:24:36,009 - Default version is None
2017-06-06 14:24:36,012 - call['/usr/bin/hdp-select versions > /var/lib/ambari-agent/tmp/copy_tarball_out.txt'] {'logoutput': True}
2017-06-06 14:24:36,103 - call returned (0, '')
2017-06-06 14:24:36,104 - Will use stack version 2.5.4.2-7
2017-06-06 14:24:36,104 - Skipping copying /usr/hdp/2.5.4.2-7/hadoop/mapreduce.tar.gz to /hdp/apps/2.5.4.2-7/mapreduce/mapreduce.tar.gz for mapreduce as its a sys_prepped host.
2017-06-06 14:24:36,104 - Called copy_to_hdfs tarball: tez
2017-06-06 14:24:36,104 - Default version is None
2017-06-06 14:24:36,105 - call['/usr/bin/hdp-select versions > /var/lib/ambari-agent/tmp/copy_tarball_out.txt'] {'logoutput': True}
2017-06-06 14:24:36,154 - call returned (0, '')
2017-06-06 14:24:36,155 - Will use stack version 2.5.4.2-7
2017-06-06 14:24:36,155 - Skipping copying /usr/hdp/2.5.4.2-7/tez/lib/tez.tar.gz to /hdp/apps/2.5.4.2-7/tez/tez.tar.gz for tez as its a sys_prepped host.
2017-06-06 14:24:36,155 - Called copy_to_hdfs tarball: pig
2017-06-06 14:24:36,155 - Default version is None
2017-06-06 14:24:36,156 - call['/usr/bin/hdp-select versions > /var/lib/ambari-agent/tmp/copy_tarball_out.txt'] {'logoutput': True}
2017-06-06 14:24:36,237 - call returned (0, '')
2017-06-06 14:24:36,237 - Will use stack version 2.5.4.2-7
2017-06-06 14:24:36,238 - Skipping copying /usr/hdp/2.5.4.2-7/pig/pig.tar.gz to /hdp/apps/2.5.4.2-7/pig/pig.tar.gz for pig as its a sys_prepped host.
2017-06-06 14:24:36,238 - Called copy_to_hdfs tarball: hive
2017-06-06 14:24:36,238 - Default version is None
2017-06-06 14:24:36,239 - call['/usr/bin/hdp-select versions > /var/lib/ambari-agent/tmp/copy_tarball_out.txt'] {'logoutput': True}
2017-06-06 14:24:36,336 - call returned (0, '')
2017-06-06 14:24:36,341 - Will use stack version 2.5.4.2-7
2017-06-06 14:24:36,341 - Skipping copying /usr/hdp/2.5.4.2-7/hive/hive.tar.gz to /hdp/apps/2.5.4.2-7/hive/hive.tar.gz for hive as its a sys_prepped host.
2017-06-06 14:24:36,341 - Called copy_to_hdfs tarball: sqoop
2017-06-06 14:24:36,341 - Default version is None
2017-06-06 14:24:36,342 - call['/usr/bin/hdp-select versions > /var/lib/ambari-agent/tmp/copy_tarball_out.txt'] {'logoutput': True}
2017-06-06 14:24:36,395 - call returned (0, '')
2017-06-06 14:24:36,395 - Will use stack version 2.5.4.2-7
2017-06-06 14:24:36,395 - Skipping copying /usr/hdp/2.5.4.2-7/sqoop/sqoop.tar.gz to /hdp/apps/2.5.4.2-7/sqoop/sqoop.tar.gz for sqoop as its a sys_prepped host.
2017-06-06 14:24:36,396 - Called copy_to_hdfs tarball: hadoop_streaming
2017-06-06 14:24:36,396 - Default version is None
2017-06-06 14:24:36,396 - call['/usr/bin/hdp-select versions > /var/lib/ambari-agent/tmp/copy_tarball_out.txt'] {'logoutput': True}
2017-06-06 14:24:36,443 - call returned (0, '')
2017-06-06 14:24:36,444 - Will use stack version 2.5.4.2-7
2017-06-06 14:24:36,452 - Skipping copying /usr/hdp/2.5.4.2-7/hadoop-mapreduce/hadoop-streaming.jar to /hdp/apps/2.5.4.2-7/mapreduce/hadoop-streaming.jar for hadoop_streaming as its a sys_prepped host.
INFO 2017-06-06 14:24:37,413 ActionQueue.py:471 - Cmd log for taskId=58 and chunk 2/3 of log for command: 
2017-06-06 14:24:36,453 - HdfsResource['/hive/warehouse'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': 'missing_principal', 'user': 'hdfs', 'owner': 'hive', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0777}
2017-06-06 14:24:36,454 - Skipping 'HdfsResource['/hive/warehouse']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:24:36,455 - HdfsResource['/user/hive'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': 'missing_principal', 'user': 'hdfs', 'owner': 'hive', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0755}
2017-06-06 14:24:36,456 - Skipping 'HdfsResource['/user/hive']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:24:36,457 - HdfsResource[None] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': 'missing_principal', 'user': 'hdfs', 'action': ['execute'], 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:24:36,457 - No resources to create. 'create_on_execute' or 'delete_on_execute' wasn't triggered before this 'execute' action.
2017-06-06 14:24:36,458 - Directory['/etc/hive'] {'mode': 0755}
2017-06-06 14:24:36,458 - Directories to fill with configs: [u'/usr/hdp/current/hive-server2/conf', u'/usr/hdp/current/hive-server2/conf/conf.server']
2017-06-06 14:24:36,458 - Directory['/usr/hdp/current/hive-server2/conf'] {'owner': 'hive', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:36,466 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-server2/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:36,496 - Generating config: /usr/hdp/current/hive-server2/conf/mapred-site.xml
2017-06-06 14:24:36,497 - File['/usr/hdp/current/hive-server2/conf/mapred-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:36,599 - File['/usr/hdp/current/hive-server2/conf/hive-default.xml.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:36,600 - File['/usr/hdp/current/hive-server2/conf/hive-env.sh.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:36,601 - File['/usr/hdp/current/hive-server2/conf/hive-exec-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:36,601 - File['/usr/hdp/current/hive-server2/conf/hive-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:36,602 - Directory['/usr/hdp/current/hive-server2/conf/conf.server'] {'owner': 'hive', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:36,603 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-server2/conf/conf.server', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:36,621 - Generating config: /usr/hdp/current/hive-server2/conf/conf.server/mapred-site.xml
2017-06-06 14:24:36,621 - File['/usr/hdp/current/hive-server2/conf/conf.server/mapred-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:36,705 - File['/usr/hdp/current/hive-server2/conf/conf.server/hive-default.xml.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:36,706 - File['/usr/hdp/current/hive-server2/conf/conf.server/hive-env.sh.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:36,707 - File['/usr/hdp/current/hive-server2/conf/conf.server/hive-exec-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:36,708 - File['/usr/hdp/current/hive-server2/conf/conf.server/hive-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:36,709 - XmlConfig['hive-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-server2/conf/conf.server', 'mode': 0644, 'configuration_attributes': {u'hidden': {u'javax.jdo.option.ConnectionPassword': u'HIVE_CLIENT,WEBHCAT_SERVER,HCAT,CONFIG_DOWNLOAD'}}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:36,724 - Generating config: /usr/hdp/current/hive-server2/conf/conf.server/hive-site.xml
2017-06-06 14:24:36,724 - File['/usr/hdp/current/hive-server2/conf/conf.server/hive-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:36,982 - XmlConfig['hiveserver2-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-server2/conf/conf.server', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:37,000 - Generating config: /usr/hdp/current/hive-server2/conf/conf.server/hiveserver2-site.xml
2017-06-06 14:24:37,000 - File['/usr/hdp/current/hive-server2/conf/conf.server/hiveserver2-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:37,014 - Writing File['/usr/hdp/current/hive-server2/conf/conf.server/hiveserver2-site.xml'] because it doesn't exist
2017-06-06 14:24:37,014 - Changing owner for /usr/hdp/current/hive-server2/conf/conf.server/hiveserver2-site.xml from 0 to hive
2017-06-06 14:24:37,014 - Changing group for /usr/hdp/current/hive-server2/conf/conf.server/hiveserver2-site.xml from 0 to hadoop
2017-06-06 14:24:37,021 - File['/usr/hdp/current/hive-server2/conf/conf.server/hive-env.sh'] {'content': InlineTemplate(...), 'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:37,022 - Writing File['/usr/hdp/current/hive-server2/conf/conf.server/hive-env.sh'] because contents don't match
2017-06-06 14:24:37,023 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:37,029 - File['/etc/security/limits.d/hive.conf'] {'content': Template('hive.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:37,030 - File['/usr/lib/ambari-agent/DBConnectionVerification.jar'] {'content': DownloadSource('http://10.0.0.13:8080/resources/DBConnectionVerification.jar'), 'mode': 0644}
2017-06-06 14:24:37,030 - Not downloading the file from http://10.0.0.13:8080/resources/DBConnectionVerification.jar, because /var/lib/ambari-agent/tmp/DBConnectionVerification.jar already exists
2017-06-06 14:24:37,034 - File['/var/lib/ambari-agent/tmp/start_hiveserver2_script'] {'content': Template('startHiveserver2.sh.j2'), 'mode': 0755}
2017-06-06 14:24:37,036 - Writing File['/var/lib/ambari-agent/tmp/start_hiveserver2_script'] because it doesn't exist
INFO 2017-06-06 14:24:37,414 ActionQueue.py:471 - Cmd log for taskId=58 and chunk 3/3 of log for command: 
2017-06-06 14:24:37,037 - Changing permission for /var/lib/ambari-agent/tmp/start_hiveserver2_script from 644 to 755
2017-06-06 14:24:37,043 - File['/usr/hdp/current/hive-server2/conf/conf.server/hadoop-metrics2-hiveserver2.properties'] {'content': Template('hadoop-metrics2-hiveserver2.properties.j2'), 'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:37,044 - Writing File['/usr/hdp/current/hive-server2/conf/conf.server/hadoop-metrics2-hiveserver2.properties'] because it doesn't exist
2017-06-06 14:24:37,045 - Changing owner for /usr/hdp/current/hive-server2/conf/conf.server/hadoop-metrics2-hiveserver2.properties from 0 to hive
2017-06-06 14:24:37,045 - Changing group for /usr/hdp/current/hive-server2/conf/conf.server/hadoop-metrics2-hiveserver2.properties from 0 to hadoop
2017-06-06 14:24:37,046 - Directory['/var/run/hive'] {'owner': 'hive', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,047 - Directory['/var/log/hive'] {'owner': 'hive', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,048 - Directory['/var/lib/hive'] {'owner': 'hive', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,049 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:37,058 - Ranger admin not installed
2017-06-06 14:24:37,061 - call['ambari-sudo.sh su hive -l -s /bin/bash -c 'cat /var/run/hive/hive-server.pid 1>/tmp/tmpqMzFVN 2>/tmp/tmpI6GckV''] {'quiet': False}
2017-06-06 14:24:37,192 - call returned (1, '')
2017-06-06 14:24:37,193 - Execution of 'cat /var/run/hive/hive-server.pid 1>/tmp/tmpqMzFVN 2>/tmp/tmpI6GckV' returned 1. cat: /var/run/hive/hive-server.pid: No such file or directory

2017-06-06 14:24:37,197 - Skipping fs root check as fs_root does not start with hdfs://
2017-06-06 14:24:37,199 - Execute['/var/lib/ambari-agent/tmp/start_hiveserver2_script /var/log/hive/hive-server2.out /var/log/hive/hive-server2.err /var/run/hive/hive-server.pid /usr/hdp/current/hive-server2/conf/conf.server /var/log/hive'] {'environment': {'HIVE_BIN': 'hive', 'JAVA_HOME': u'/usr/lib/jvm/java-8-openjdk-amd64', 'HADOOP_HOME': u'/usr/hdp/current/hadoop-client'}, 'not_if': 'ls /var/run/hive/hive-server.pid >/dev/null 2>&1 && ps -p  >/dev/null 2>&1', 'user': 'hive', 'path': [u'/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/var/lib/ambari-agent:/usr/hdp/current/hive-server2/bin:/usr/hdp/current/hadoop-client/bin']}

Command completed successfully!
INFO 2017-06-06 14:24:37,414 ActionQueue.py:382 - End command output log for command with id = 58, role = HIVE_SERVER, roleCommand = START
INFO 2017-06-06 14:24:37,414 RecoveryManager.py:185 - current status is set to STARTED for HIVE_SERVER
INFO 2017-06-06 14:24:37,414 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=58, current state of HIVE_SERVER to STARTED
INFO 2017-06-06 14:24:37,704 ActionQueue.py:358 - Quit retrying for command id 63. Status: COMPLETED, retryAble: True, retryDuration (sec): 590, last delay (sec): 1
INFO 2017-06-06 14:24:37,705 ActionQueue.py:363 - Command 63 completed successfully!
INFO 2017-06-06 14:24:37,705 ActionQueue.py:379 - Begin command output log for command with id = 63, role = RESOURCEMANAGER, roleCommand = START
INFO 2017-06-06 14:24:37,706 ActionQueue.py:471 - Cmd log for taskId=63 and chunk 1/2 of log for command: 
2017-06-06 14:24:30,059 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,641 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,648 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:31,649 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:31,649 - FS Type: 
2017-06-06 14:24:31,649 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:31,726 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,734 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:31,811 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:31,850 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:31,850 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:31,854 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:31,855 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:31,861 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,875 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,878 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:31,927 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,929 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:31,930 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,947 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:31,959 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:33,368 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:33,369 - call['ambari-python-wrap /usr/bin/hdp-select status hadoop-yarn-resourcemanager'] {'timeout': 20}
2017-06-06 14:24:33,452 - call returned (0, 'hadoop-yarn-resourcemanager - 2.5.4.2-7')
2017-06-06 14:24:33,462 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:33,508 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:33,522 - Execute['find /var/log/hadoop-yarn/yarn -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'yarn'}
2017-06-06 14:24:33,876 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:34,841 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:34,850 - Directory['/var/log/hadoop-yarn/nodemanager/recovery-state'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:34,852 - Directory['/var/run/hadoop-yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:34,853 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:34,855 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:34,859 - Directory['/var/run/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:34,860 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:34,862 - Directory['/var/log/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:34,863 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:34,864 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'group': 'hadoop', 'ignore_failures': True, 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:34,865 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:34,885 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:34,886 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,939 - XmlConfig['hdfs-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:34,954 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:24:34,955 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,055 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:35,069 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:24:35,070 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,141 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 201 to yarn
2017-06-06 14:24:35,141 - XmlConfig['yarn-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:35,160 - Generating config: /usr/hdp/current/hadoop-client/conf/yarn-site.xml
2017-06-06 14:24:35,161 - File['/usr/hdp/current/hadoop-client/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,354 - XmlConfig['capacity-scheduler.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:24:35,370 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
INFO 2017-06-06 14:24:37,706 ActionQueue.py:471 - Cmd log for taskId=63 and chunk 2/2 of log for command: 
2017-06-06 14:24:35,370 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,395 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 202 to yarn
2017-06-06 14:24:35,395 - Directory['/etc/hadoop/conf'] {'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:35,396 - File['/etc/hadoop/conf/yarn.exclude'] {'owner': 'yarn', 'group': 'hadoop'}
2017-06-06 14:24:35,396 - Writing File['/etc/hadoop/conf/yarn.exclude'] because it doesn't exist
2017-06-06 14:24:35,397 - Changing owner for /etc/hadoop/conf/yarn.exclude from 0 to yarn
2017-06-06 14:24:35,397 - Changing group for /etc/hadoop/conf/yarn.exclude from 0 to hadoop
2017-06-06 14:24:35,398 - File['/var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log'] {'owner': 'yarn', 'group': 'hadoop'}
2017-06-06 14:24:35,398 - Writing File['/var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log'] because it doesn't exist
2017-06-06 14:24:35,398 - Changing owner for /var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log from 0 to yarn
2017-06-06 14:24:35,399 - Changing group for /var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log from 0 to hadoop
2017-06-06 14:24:35,403 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}
2017-06-06 14:24:35,406 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}
2017-06-06 14:24:35,413 - File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] {'content': InlineTemplate(...), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}
2017-06-06 14:24:35,414 - Writing File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] because contents don't match
2017-06-06 14:24:35,415 - File['/usr/hdp/current/hadoop-yarn-resourcemanager/bin/container-executor'] {'group': 'hadoop', 'mode': 02050}
2017-06-06 14:24:35,419 - File['/usr/hdp/current/hadoop-client/conf/container-executor.cfg'] {'content': Template('container-executor.cfg.j2'), 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:35,420 - Directory['/cgroups_test/cpu'] {'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:35,422 - File['/usr/hdp/current/hadoop-client/conf/mapred-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'mode': 0755}
2017-06-06 14:24:35,427 - File['/usr/hdp/current/hadoop-client/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:35,428 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:35,443 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:24:35,444 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,515 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 203 to mapred
2017-06-06 14:24:35,516 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:35,531 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:24:35,532 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,561 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 203 to hdfs
2017-06-06 14:24:35,561 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:35,578 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:24:35,578 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,590 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:35,591 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:35,605 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:24:35,605 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,616 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:35,629 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:24:35,630 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:35,641 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:24:35,642 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:24:35,643 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:35,646 - Verifying DFS directories where ATS stores time line data for active and completed applications.
2017-06-06 14:24:35,760 - Skipping DFS directory '/atshistory/done' as it's marked to be ignored.
2017-06-06 14:24:35,760 - Skipping DFS directory '/atshistory/active' as it's marked to be ignored.
2017-06-06 14:24:35,761 - File['/var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid'] {'action': ['delete'], 'not_if': "ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid`'"}
2017-06-06 14:24:35,930 - Execute['ulimit -c unlimited; export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-yarn-resourcemanager/sbin/yarn-daemon.sh --config /usr/hdp/current/hadoop-client/conf start resourcemanager'] {'not_if': "ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid`'", 'user': 'yarn'}
2017-06-06 14:24:37,406 - Execute['ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid`''] {'not_if': "ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid`'", 'tries': 5, 'try_sleep': 1}
2017-06-06 14:24:37,572 - Skipping Execute['ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-resourcemanager.pid`''] due to not_if

Command completed successfully!
INFO 2017-06-06 14:24:37,706 ActionQueue.py:382 - End command output log for command with id = 63, role = RESOURCEMANAGER, roleCommand = START
INFO 2017-06-06 14:24:37,706 RecoveryManager.py:185 - current status is set to STARTED for RESOURCEMANAGER
INFO 2017-06-06 14:24:37,706 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=63, current state of RESOURCEMANAGER to STARTED
INFO 2017-06-06 14:24:43,941 ActionQueue.py:358 - Quit retrying for command id 65. Status: COMPLETED, retryAble: True, retryDuration (sec): 584, last delay (sec): 1
INFO 2017-06-06 14:24:43,943 ActionQueue.py:363 - Command 65 completed successfully!
INFO 2017-06-06 14:24:43,947 ActionQueue.py:379 - Begin command output log for command with id = 65, role = ZKFC, roleCommand = START
INFO 2017-06-06 14:24:43,949 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 1/12 of log for command: 
2017-06-06 14:24:30,696 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,195 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,199 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:32,199 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:32,199 - FS Type: 
2017-06-06 14:24:32,200 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:32,224 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,225 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:32,263 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:32,294 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:32,295 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:32,297 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:32,304 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:32,310 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:32,319 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:32,329 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:32,359 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,364 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:32,365 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,372 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:32,392 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:33,388 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:33,395 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:33,428 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:33,451 - checked_call['dpkg -s hdp-select | grep Version | awk '{print $2}''] {'stderr': -1}
2017-06-06 14:24:33,641 - checked_call returned (0, '2.5.4.2-7', '')
2017-06-06 14:24:33,672 - Execute['find /var/log/hadoop/hdfs -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'hdfs'}
find: /var/log/hadoop/hdfs: No such file or directory
2017-06-06 14:24:33,982 - Skipping failure of Execute['find /var/log/hadoop/hdfs -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] due to ignore_failures. Failure reason: Execution of 'find /var/log/hadoop/hdfs -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;' returned 1. find: /var/log/hadoop/hdfs: No such file or directory
2017-06-06 14:24:33,995 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:34,028 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:34,033 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:34,090 - Generating config: /usr/hdp/current/hadoop-client/conf/hadoop-policy.xml
2017-06-06 14:24:34,090 - File['/usr/hdp/current/hadoop-client/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,109 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:34,125 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:24:34,126 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,141 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:34,146 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:34,163 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:24:34,164 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,176 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:34,189 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:24:34,190 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,200 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'configurations': ...}
2017-06-06 14:24:34,215 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:24:34,215 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,333 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:34,349 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:34,349 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,419 - File['/usr/hdp/current/hadoop-client/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:34,422 - Directory['/var/run/hadoop'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0755}
INFO 2017-06-06 14:24:43,954 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 2/12 of log for command: 
2017-06-06 14:24:34,423 - Changing owner for /var/run/hadoop from 0 to hdfs
2017-06-06 14:24:34,423 - Changing group for /var/run/hadoop from 0 to hadoop
2017-06-06 14:24:34,423 - Initialize HA state in ZooKeeper: hdfs zkfc -formatZK -nonInteractive
2017-06-06 14:24:34,424 - Try 1 out of 10
2017-06-06 14:24:34,424 - call['hdfs zkfc -formatZK -nonInteractive'] {'logoutput': False, 'user': 'hdfs'}
INFO 2017-06-06 14:24:43,962 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 3/12 of log for command: 
2017-06-06 14:24:39,298 - call returned (2, "17/06/06 14:24:36 INFO tools.DFSZKFailoverController: STARTUP_MSG: \n/************************************************************\nSTARTUP_MSG: Starting DFSZKFailoverController\nSTARTUP_MSG:   user = hdfs\nSTARTUP_MSG:   host = 10.0.0.13/10.0.0.13\nSTARTUP_MSG:   args = [-formatZK, -nonInteractive]\nSTARTUP_MSG:   version = 2.7.3.2.5.4.2-7\nSTARTUP_MSG:   classpath = /usr/hdp/2.5.4.2-7/hadoop/conf:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7-javadoc.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-core-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7-sources.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-kms-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/azure-storage-4.2.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-hdfs-plugin-shim-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-plugin-classloader-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-s3-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/joda-time-2.8.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-yarn-plugin-shim-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ojdbc6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-azure.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-azure-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-annotations-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-nfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-auth.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-aws.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-aws-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/./:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/adls2-oauth2-token-provider-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/hadoop-azure-datalake-2.0.0-SNAPSHOT.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/azure-data-lake-store-sdk-2.0.4-SNAPSHOT.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-2.7.3.
INFO 2017-06-06 14:24:43,965 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 4/12 of log for command: 
2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/hdinsight-ats-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/metrics-core-3.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-dbcp2-2.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/sqljdbc4-4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/azure-storage-4.2.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/zookeeper-3.4.6.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-pool2-2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-client-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-api-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-
INFO 2017-06-06 14:24:43,967 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 5/12 of log for command: 
7/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-extras-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-streaming-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-sls-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-distcp-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-openstack-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-rumen-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-archives-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-ant-2.7.3.2.5.4.2-7.jar::/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-clien
INFO 2017-06-06 14:24:43,969 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 6/12 of log for command: 
t-hs-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.1.0-incubating.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.4.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang3-3.4.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/nimbus-jose-jwt-3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.5.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/json-smart-1.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-3.0.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/azure-keyvault-core-0.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jcip-annotations-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-job-analyzer-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-with-fs-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-mapreduce-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-cache-plugin-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-api-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-examples-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-history-parser-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-tests-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-runtime-library-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-runtime-internals-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-dag-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-common-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/metrics-core-3.1.0.jar:/usr/hdp/2.5.4.2-7/tez/l
INFO 2017-06-06 14:24:43,972 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 7/12 of log for command: 
ib/jsr305-2.0.3.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-collections4-4.1.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-azure-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-annotations-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-yarn-server-web-proxy-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.5.4.2-7/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-aws-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/conf\nSTARTUP_MSG:   build = git@github.com:hortonworks/hadoop.git -r e1f139118ccc75d6610c176bf7e09fb5cc902eb2; compiled by 'jenkins' on 2017-04-04T10:53Z\nSTARTUP_MSG:   java = 1.8.0_131\n************************************************************/\n17/06/06 14:24:36 INFO tools.DFSZKFailoverController: registered UNIX signal handlers for [TERM, HUP, INT]\n17/06/06 14:24:38 INFO tools.DFSZKFailoverController: Failover controller configured for NameNode NameNode at hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.13:8020\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-7--1, built on 04/04/2017 10:48 GMT\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:host.name=10.0.0.13\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:java.version=1.8.0_131\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:java.class.path=/usr/hdp/2.5.4.2-7/hadoop/conf:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7-javadoc.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-core-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7-sources.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-kms-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/azure-storage-4.2.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-hdfs-plugin-shim-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-plugin-classloader-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-s3-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/joda-time-2.8.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-yarn-plugin-shim-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ojdbc6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-azure.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-azure-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-annotations-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-nfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-auth.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-aws.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-aws-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/./:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/
INFO 2017-06-06 14:24:43,974 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 8/12 of log for command: 
microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/adls2-oauth2-token-provider-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/hadoop-azure-datalake-2.0.0-SNAPSHOT.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/azure-data-lake-store-sdk-2.0.4-SNAPSHOT.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/hdinsight-ats-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/metrics-core-3.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-dbcp2-2.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/sqljdbc4-4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/azure-storage-4.2.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/zookeeper-3.4.6.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-pool2-2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-client-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-tests
INFO 2017-06-06 14:24:43,975 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 9/12 of log for command: 
.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-api-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-extras-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-streaming-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-sls-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-distcp-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-openstack-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-rumen-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//java-xmlbu
INFO 2017-06-06 14:24:43,975 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 10/12 of log for command: 
ilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-archives-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-ant-2.7.3.2.5.4.2-7.jar::/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.1.0-incubating.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.4.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang3-3.4.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/nimbus-jose-jwt-3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.5.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/json-smart-1.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-3.0.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/azure-keyvault-core-0.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/curre
INFO 2017-06-06 14:24:43,975 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 11/12 of log for command: 
nt/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jcip-annotations-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-job-analyzer-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-with-fs-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-mapreduce-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-cache-plugin-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-api-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-examples-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-history-parser-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-tests-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-runtime-library-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-runtime-internals-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-dag-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-common-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/metrics-core-3.1.0.jar:/usr/hdp/2.5.4.2-7/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-collections4-4.1.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-azure-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-annotations-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-yarn-server-web-proxy-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.5.4.2-7/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-aws-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/conf\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.5.4.2-7/hadoop/lib/native/Linux-amd64-64:/usr/lib/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.5.4.2-7/hadoop/lib/native\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:java.compiler=<NA>\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:os.name=Linux\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:os.arch=amd64\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:os.version=4.4.0-78-generic\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:user.name=hdfs\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:user.home=/home/hdfs\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Client environment:user.dir=/home/hdfs\n17/06/06 14:24:38 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=zk4-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:2181,zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:2181,zk6-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:2181 sessionTimeout=5000 watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@4944252c\n17/06/06 14:24:38 INFO zookeeper.ClientCnxn: Opening socket connection to server 10.0.0.11/10.0.0.11:2181. Will not attempt to authenticate using SASL (unknown error)\n17/06/06 14:24:39 INFO zookeeper.ClientCnxn: Socket connection established to 10.0.0.11/10.0.0.11:2181, initiating session\n17/06/06 14:24:39 INFO zookeeper.ClientCnxn: Session establishment complete on server 10.0.0.11/10.0.0.11:2181, sessionid = 0x15c7dcabcb60005, negotiated timeout = 5000\n17/06/06 14:24:39 INFO ha.ActiveStandbyElector: Terminating ZK connection for elector id=1217875525 appData=null cb=Elector callbacks for NameNode at hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.13:8020\n17/06/06 14:24:39 INFO zookeeper.ZooKeeper: Session: 0x15c7dcabcb60005 closed\n17/06/06 14:24:39 WARN ha.ActiveStandbyElector: Ignoring stale result from old client with sessionId 0x15c7dcabcb60005\n17/06/06 14:24:39 INFO zookeeper.ClientCnxn: EventThread shut down\n17/06/06 14:24:39 INFO tools.DFSZKFailoverController: SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down DFSZKFailoverController at 10.0.0.13/10.0.0.13\n************************************************************/")
INFO 2017-06-06 14:24:43,975 ActionQueue.py:471 - Cmd log for taskId=65 and chunk 12/12 of log for command: 
2017-06-06 14:24:39,298 - HA state already initialized in ZooKeeper
2017-06-06 14:24:39,300 - Directory['/var/run/hadoop'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0755}
2017-06-06 14:24:39,309 - Directory['/var/run/hadoop/hdfs'] {'owner': 'hdfs', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:39,309 - Creating directory Directory['/var/run/hadoop/hdfs'] since it doesn't exist.
2017-06-06 14:24:39,313 - Changing owner for /var/run/hadoop/hdfs from 0 to hdfs
2017-06-06 14:24:39,317 - Changing group for /var/run/hadoop/hdfs from 0 to hadoop
2017-06-06 14:24:39,317 - Directory['/var/log/hadoop/hdfs'] {'owner': 'hdfs', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:39,317 - Creating directory Directory['/var/log/hadoop/hdfs'] since it doesn't exist.
2017-06-06 14:24:39,321 - Changing owner for /var/log/hadoop/hdfs from 0 to hdfs
2017-06-06 14:24:39,325 - Changing group for /var/log/hadoop/hdfs from 0 to hadoop
2017-06-06 14:24:39,326 - File['/var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid'] {'action': ['delete'], 'not_if': 'ambari-sudo.sh  -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid && ambari-sudo.sh  -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid'}
2017-06-06 14:24:39,349 - Execute['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'ulimit -c unlimited ;  /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /usr/hdp/current/hadoop-client/conf start zkfc''] {'environment': {'HADOOP_LIBEXEC_DIR': '/usr/hdp/current/hadoop-client/libexec'}, 'not_if': 'ambari-sudo.sh  -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid && ambari-sudo.sh  -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid'}

Command completed successfully!
INFO 2017-06-06 14:24:43,975 ActionQueue.py:382 - End command output log for command with id = 65, role = ZKFC, roleCommand = START
INFO 2017-06-06 14:24:43,976 RecoveryManager.py:185 - current status is set to STARTED for ZKFC
INFO 2017-06-06 14:24:43,976 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=65, current state of ZKFC to STARTED
INFO 2017-06-06 14:24:44,698 ActionQueue.py:358 - Quit retrying for command id 59. Status: COMPLETED, retryAble: True, retryDuration (sec): 583, last delay (sec): 1
INFO 2017-06-06 14:24:44,699 ActionQueue.py:363 - Command 59 completed successfully!
INFO 2017-06-06 14:24:44,700 ActionQueue.py:379 - Begin command output log for command with id = 59, role = METRICS_COLLECTOR, roleCommand = START
INFO 2017-06-06 14:24:44,701 ActionQueue.py:471 - Cmd log for taskId=59 and chunk 1/3 of log for command: 
2017-06-06 14:24:30,438 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,091 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,096 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:32,096 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:32,097 - FS Type: 
2017-06-06 14:24:32,097 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:32,140 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,146 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:32,263 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:32,304 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:32,304 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:32,307 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:32,308 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:32,318 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:32,324 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:32,332 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:32,392 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,396 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:32,397 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,413 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:32,446 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:34,243 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:34,247 - checked_call['hostid'] {}
2017-06-06 14:24:34,285 - checked_call returned (0, '000a0d00')
2017-06-06 14:24:34,286 - Execute['find /var/log/ambari-metrics-collector -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'ams'}
find: /var/log/ambari-metrics-collector: No such file or directory
2017-06-06 14:24:34,441 - Skipping failure of Execute['find /var/log/ambari-metrics-collector -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] due to ignore_failures. Failure reason: Execution of 'find /var/log/ambari-metrics-collector -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;' returned 1. find: /var/log/ambari-metrics-collector: No such file or directory
2017-06-06 14:24:34,442 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:39,760 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:39,764 - Directory['/etc/ams-hbase/conf'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'recursive_ownership': True}
2017-06-06 14:24:39,766 - Changing owner for /etc/ams-hbase/conf from 0 to ams
2017-06-06 14:24:39,767 - Changing group for /etc/ams-hbase/conf from 0 to hadoop
2017-06-06 14:24:39,768 - Directory['/var/lib/ambari-metrics-collector/hbase-tmp'] {'owner': 'ams', 'create_parents': True, 'recursive_ownership': True, 'cd_access': 'a'}
2017-06-06 14:24:39,769 - Creating directory Directory['/var/lib/ambari-metrics-collector/hbase-tmp'] since it doesn't exist.
2017-06-06 14:24:40,021 - Changing owner for /var/lib/ambari-metrics-collector/hbase-tmp from 0 to ams
2017-06-06 14:24:40,022 - Directory['/var/lib/ambari-metrics-collector/hbase-tmp/local/jars'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:40,022 - Creating directory Directory['/var/lib/ambari-metrics-collector/hbase-tmp/local/jars'] since it doesn't exist.
2017-06-06 14:24:40,023 - Changing owner for /var/lib/ambari-metrics-collector/hbase-tmp/local/jars from 0 to ams
2017-06-06 14:24:40,023 - Changing group for /var/lib/ambari-metrics-collector/hbase-tmp/local/jars from 0 to hadoop
2017-06-06 14:24:40,023 - Changing permission for /var/lib/ambari-metrics-collector/hbase-tmp/local/jars from 755 to 775
2017-06-06 14:24:40,027 - File['/etc/ams-hbase/conf/core-site.xml'] {'owner': 'ams', 'action': ['delete']}
2017-06-06 14:24:40,027 - File['/etc/ams-hbase/conf/hdfs-site.xml'] {'owner': 'ams', 'action': ['delete']}
2017-06-06 14:24:40,028 - XmlConfig['hbase-site.xml'] {'owner': 'ams', 'group': 'hadoop', 'conf_dir': '/etc/ams-hbase/conf', 'configuration_attributes': {u'final': {u'hbase.zookeeper.quorum': u'true'}}, 'configurations': ...}
2017-06-06 14:24:40,062 - Generating config: /etc/ams-hbase/conf/hbase-site.xml
2017-06-06 14:24:40,062 - File['/etc/ams-hbase/conf/hbase-site.xml'] {'owner': 'ams', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:40,139 - Writing File['/etc/ams-hbase/conf/hbase-site.xml'] because contents don't match
2017-06-06 14:24:40,141 - Directory['/var/lib/ambari-metrics-collector/hbase-tmp/phoenix-spool'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:40,141 - Creating directory Directory['/var/lib/ambari-metrics-collector/hbase-tmp/phoenix-spool'] since it doesn't exist.
2017-06-06 14:24:40,141 - Changing owner for /var/lib/ambari-metrics-collector/hbase-tmp/phoenix-spool from 0 to ams
2017-06-06 14:24:40,142 - Changing group for /var/lib/ambari-metrics-collector/hbase-tmp/phoenix-spool from 0 to hadoop
2017-06-06 14:24:40,143 - XmlConfig['hbase-policy.xml'] {'owner': 'ams', 'group': 'hadoop', 'conf_dir': '/etc/ams-hbase/conf', 'configuration_attributes': {}, 'configurations': {u'security.masterregion.protocol.acl': u'*', u'security.admin.protocol.acl': u'*', u'security.client.protocol.acl': u'*'}}
2017-06-06 14:24:40,158 - Generating config: /etc/ams-hbase/conf/hbase-policy.xml
2017-06-06 14:24:40,158 - File['/etc/ams-hbase/conf/hbase-policy.xml'] {'owner': 'ams', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:40,164 - Writing File['/etc/ams-hbase/conf/hbase-policy.xml'] because contents don't match
2017-06-06 14:24:40,179 - File['/etc/ams-hbase/conf/hbase-env.sh'] {'content': InlineTemplate(...), 'owner': 'ams'}
2017-06-06 14:24:40,180 - Writing File['/etc/ams-hbase/conf/hbase-env.sh'] because contents don't match
2017-06-06 14:24:40,188 - File['/etc/ams-hbase/conf/hadoop-metrics2-hbase.properties'] {'content': Template('hadoop-metrics2-hbase.properties.j2'), 'owner': 'ams', 'group': 'hadoop'}
INFO 2017-06-06 14:24:44,704 ActionQueue.py:471 - Cmd log for taskId=59 and chunk 2/3 of log for command: 
2017-06-06 14:24:40,192 - Writing File['/etc/ams-hbase/conf/hadoop-metrics2-hbase.properties'] because contents don't match
2017-06-06 14:24:40,193 - TemplateConfig['/etc/ams-hbase/conf/regionservers'] {'owner': 'ams', 'template_tag': None}
2017-06-06 14:24:40,199 - File['/etc/ams-hbase/conf/regionservers'] {'content': Template('regionservers.j2'), 'owner': 'ams', 'group': None, 'mode': None}
2017-06-06 14:24:40,200 - Writing File['/etc/ams-hbase/conf/regionservers'] because contents don't match
2017-06-06 14:24:40,202 - Directory['/var/run/ambari-metrics-collector/'] {'owner': 'ams', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:40,202 - Creating directory Directory['/var/run/ambari-metrics-collector/'] since it doesn't exist.
2017-06-06 14:24:40,204 - Changing owner for /var/run/ambari-metrics-collector/ from 0 to ams
2017-06-06 14:24:40,205 - Directory['/var/log/ambari-metrics-collector'] {'owner': 'ams', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:40,205 - Creating directory Directory['/var/log/ambari-metrics-collector'] since it doesn't exist.
2017-06-06 14:24:40,206 - Changing owner for /var/log/ambari-metrics-collector from 0 to ams
2017-06-06 14:24:40,206 - Directory['/mnt/data/ambari-metrics-collector/hbase'] {'owner': 'ams', 'create_parents': True, 'recursive_ownership': True, 'cd_access': 'a'}
2017-06-06 14:24:40,206 - Creating directory Directory['/mnt/data/ambari-metrics-collector/hbase'] since it doesn't exist.
2017-06-06 14:24:40,217 - Changing owner for /mnt/data/ambari-metrics-collector/hbase from 0 to ams
2017-06-06 14:24:40,217 - File['/var/run/ambari-metrics-collector//distributed_mode'] {'owner': 'ams', 'action': ['delete']}
2017-06-06 14:24:40,218 - File['/etc/ams-hbase/conf/log4j.properties'] {'content': ..., 'owner': 'ams', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:40,219 - Writing File['/etc/ams-hbase/conf/log4j.properties'] because contents don't match
2017-06-06 14:24:40,223 - Directory['/etc/ams-hbase/conf'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'recursive_ownership': True}
2017-06-06 14:24:40,225 - Directory['/var/lib/ambari-metrics-collector/hbase-tmp'] {'owner': 'ams', 'create_parents': True, 'recursive_ownership': True, 'cd_access': 'a'}
2017-06-06 14:24:40,226 - Directory['/var/lib/ambari-metrics-collector/hbase-tmp/local/jars'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:40,229 - File['/etc/ams-hbase/conf/core-site.xml'] {'owner': 'ams', 'action': ['delete']}
2017-06-06 14:24:40,229 - File['/etc/ams-hbase/conf/hdfs-site.xml'] {'owner': 'ams', 'action': ['delete']}
2017-06-06 14:24:40,230 - XmlConfig['hbase-site.xml'] {'owner': 'ams', 'group': 'hadoop', 'conf_dir': '/etc/ams-hbase/conf', 'configuration_attributes': {u'final': {u'hbase.zookeeper.quorum': u'true'}}, 'configurations': ...}
2017-06-06 14:24:40,253 - Generating config: /etc/ams-hbase/conf/hbase-site.xml
2017-06-06 14:24:40,254 - File['/etc/ams-hbase/conf/hbase-site.xml'] {'owner': 'ams', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:40,355 - XmlConfig['hbase-policy.xml'] {'owner': 'ams', 'group': 'hadoop', 'conf_dir': '/etc/ams-hbase/conf', 'configuration_attributes': {}, 'configurations': {u'security.masterregion.protocol.acl': u'*', u'security.admin.protocol.acl': u'*', u'security.client.protocol.acl': u'*'}}
2017-06-06 14:24:40,373 - Generating config: /etc/ams-hbase/conf/hbase-policy.xml
2017-06-06 14:24:40,374 - File['/etc/ams-hbase/conf/hbase-policy.xml'] {'owner': 'ams', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:40,396 - File['/etc/ams-hbase/conf/hbase-env.sh'] {'content': InlineTemplate(...), 'owner': 'ams'}
2017-06-06 14:24:40,404 - File['/etc/ams-hbase/conf/hadoop-metrics2-hbase.properties'] {'content': Template('hadoop-metrics2-hbase.properties.j2'), 'owner': 'ams', 'group': 'hadoop'}
2017-06-06 14:24:40,408 - TemplateConfig['/etc/ams-hbase/conf/regionservers'] {'owner': 'ams', 'template_tag': None}
2017-06-06 14:24:40,412 - File['/etc/ams-hbase/conf/regionservers'] {'content': Template('regionservers.j2'), 'owner': 'ams', 'group': None, 'mode': None}
2017-06-06 14:24:40,419 - Directory['/var/run/ambari-metrics-collector/'] {'owner': 'ams', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:40,420 - Directory['/var/log/ambari-metrics-collector'] {'owner': 'ams', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:40,424 - File['/etc/ams-hbase/conf/log4j.properties'] {'content': ..., 'owner': 'ams', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:40,425 - Directory['/etc/ambari-metrics-collector/conf'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'recursive_ownership': True}
2017-06-06 14:24:40,428 - Changing owner for /etc/ambari-metrics-collector/conf from 0 to ams
2017-06-06 14:24:40,429 - Changing group for /etc/ambari-metrics-collector/conf from 0 to hadoop
2017-06-06 14:24:40,430 - Directory['/var/lib/ambari-metrics-collector/checkpoint'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'recursive_ownership': True, 'cd_access': 'a'}
2017-06-06 14:24:40,430 - Creating directory Directory['/var/lib/ambari-metrics-collector/checkpoint'] since it doesn't exist.
2017-06-06 14:24:40,431 - Changing owner for /var/lib/ambari-metrics-collector/checkpoint from 0 to ams
2017-06-06 14:24:40,431 - Changing group for /var/lib/ambari-metrics-collector/checkpoint from 0 to hadoop
2017-06-06 14:24:40,436 - XmlConfig['ams-site.xml'] {'owner': 'ams', 'group': 'hadoop', 'conf_dir': '/etc/ambari-metrics-collector/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:40,467 - Generating config: /etc/ambari-metrics-collector/conf/ams-site.xml
2017-06-06 14:24:40,468 - File['/etc/ambari-metrics-collector/conf/ams-site.xml'] {'owner': 'ams', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:40,608 - Writing File['/etc/ambari-metrics-collector/conf/ams-site.xml'] because contents don't match
2017-06-06 14:24:40,613 - XmlConfig['ssl-server.xml'] {'owner': 'ams', 'group': 'hadoop', 'conf_dir': '/etc/ambari-metrics-collector/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:40,630 - Generating config: /etc/ambari-metrics-collector/conf/ssl-server.xml
2017-06-06 14:24:40,630 - File['/etc/ambari-metrics-collector/conf/ssl-server.xml'] {'owner': 'ams', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:40,647 - Writing File['/etc/ambari-metrics-collector/conf/ssl-server.xml'] because it doesn't exist
2017-06-06 14:24:40,647 - Changing owner for /etc/ambari-metrics-collector/conf/ssl-server.xml from 0 to ams
2017-06-06 14:24:40,648 - Changing group for /etc/ambari-metrics-collector/conf/ssl-server.xml from 0 to hadoop
2017-06-06 14:24:40,648 - XmlConfig['hbase-site.xml'] {'owner': 'ams', 'group': 'hadoop', 'conf_dir': '/etc/ambari-metrics-collector/conf', 'configuration_attributes': {u'final': {u'hbase.zookeeper.quorum': u'true'}}, 'configurations': ...}
2017-06-06 14:24:40,667 - Generating config: /etc/ambari-metrics-collector/conf/hbase-site.xml
2017-06-06 14:24:40,668 - File['/etc/ambari-metrics-collector/conf/hbase-site.xml'] {'owner': 'ams', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:40,762 - Writing File['/etc/ambari-metrics-collector/conf/hbase-site.xml'] because contents don't match
2017-06-06 14:24:40,763 - File['/etc/ambari-metrics-collector/conf/log4j.properties'] {'content': ..., 'owner': 'ams', 'group': 'hadoop', 'mode': 0644}
INFO 2017-06-06 14:24:44,707 ActionQueue.py:471 - Cmd log for taskId=59 and chunk 3/3 of log for command: 
2017-06-06 14:24:40,764 - Writing File['/etc/ambari-metrics-collector/conf/log4j.properties'] because contents don't match
2017-06-06 14:24:40,772 - File['/etc/ambari-metrics-collector/conf/ams-env.sh'] {'content': InlineTemplate(...), 'owner': 'ams'}
2017-06-06 14:24:40,773 - Writing File['/etc/ambari-metrics-collector/conf/ams-env.sh'] because contents don't match
2017-06-06 14:24:40,773 - Directory['/var/log/ambari-metrics-collector'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:40,774 - Changing group for /var/log/ambari-metrics-collector from 0 to hadoop
2017-06-06 14:24:40,775 - Directory['/var/run/ambari-metrics-collector'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:40,775 - Changing group for /var/run/ambari-metrics-collector from 0 to hadoop
2017-06-06 14:24:40,776 - File['/usr/lib/ams-hbase/bin/hadoop'] {'owner': 'ams', 'mode': 0755}
2017-06-06 14:24:41,040 - Writing File['/usr/lib/ams-hbase/bin/hadoop'] because it doesn't exist
2017-06-06 14:24:41,042 - Changing owner for /usr/lib/ams-hbase/bin/hadoop from 0 to ams
2017-06-06 14:24:41,042 - Changing permission for /usr/lib/ams-hbase/bin/hadoop from 644 to 755
2017-06-06 14:24:41,042 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:41,047 - File['/etc/security/limits.d/ams.conf'] {'content': Template('ams.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:41,047 - Writing File['/etc/security/limits.d/ams.conf'] because it doesn't exist
2017-06-06 14:24:41,052 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:41,053 - Execute['/usr/sbin/ambari-metrics-collector --config /etc/ambari-metrics-collector/conf stop'] {'user': 'ams'}
2017-06-06 14:24:41,244 - Execute['ambari-sudo.sh rm -rf /var/lib/ambari-metrics-collector/hbase-tmp/*.tmp'] {}
2017-06-06 14:24:41,267 - File['/etc/ambari-metrics-collector/conf/core-site.xml'] {'owner': 'ams', 'action': ['delete']}
2017-06-06 14:24:41,268 - File['/etc/ambari-metrics-collector/conf/hdfs-site.xml'] {'owner': 'ams', 'action': ['delete']}
2017-06-06 14:24:41,273 - Execute['/usr/sbin/ambari-metrics-collector --config /etc/ambari-metrics-collector/conf start'] {'user': 'ams'}

Command completed successfully!
INFO 2017-06-06 14:24:44,709 ActionQueue.py:382 - End command output log for command with id = 59, role = METRICS_COLLECTOR, roleCommand = START
INFO 2017-06-06 14:24:44,710 RecoveryManager.py:185 - current status is set to STARTED for METRICS_COLLECTOR
INFO 2017-06-06 14:24:44,711 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=59, current state of METRICS_COLLECTOR to STARTED
INFO 2017-06-06 14:24:45,708 ActionQueue.py:358 - Quit retrying for command id 64. Status: COMPLETED, retryAble: True, retryDuration (sec): 582, last delay (sec): 1
INFO 2017-06-06 14:24:45,708 ActionQueue.py:363 - Command 64 completed successfully!
INFO 2017-06-06 14:24:45,708 ActionQueue.py:379 - Begin command output log for command with id = 64, role = WEBHCAT_SERVER, roleCommand = START
INFO 2017-06-06 14:24:45,709 ActionQueue.py:471 - Cmd log for taskId=64 and chunk 1/2 of log for command: 
2017-06-06 14:24:29,374 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,221 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,243 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:31,243 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:31,243 - FS Type: 
2017-06-06 14:24:31,244 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:31,299 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,308 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:31,402 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:31,441 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:31,441 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:31,443 - Creating directory Directory['/var/log/hadoop'] since it doesn't exist.
2017-06-06 14:24:31,444 - Changing group for /var/log/hadoop from 0 to hadoop
2017-06-06 14:24:31,444 - Changing permission for /var/log/hadoop from 755 to 775
2017-06-06 14:24:31,445 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:31,445 - Creating directory Directory['/var/run/hadoop'] since it doesn't exist.
2017-06-06 14:24:31,446 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:31,446 - Creating directory Directory['/tmp/hadoop-hdfs'] since it doesn't exist.
2017-06-06 14:24:31,447 - Changing owner for /tmp/hadoop-hdfs from 0 to hdfs
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:31,460 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,468 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,477 - Changing owner for /usr/hdp/current/hadoop-client/conf/health_check from 0 to hdfs
2017-06-06 14:24:31,478 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:31,549 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,550 - Writing File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] because contents don't match
2017-06-06 14:24:31,559 - Changing owner for /usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties from 0 to hdfs
2017-06-06 14:24:31,562 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:31,566 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,599 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:31,631 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:32,842 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,963 - call['ambari-python-wrap /usr/bin/hdp-select status hive-server2'] {'timeout': 20}
2017-06-06 14:24:33,141 - call returned (0, 'hive-server2 - 2.5.4.2-7')
2017-06-06 14:24:33,142 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:33,228 - Execute['find /var/log/webhcat -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'hcat'}
find: /var/log/webhcat: No such file or directory
2017-06-06 14:24:33,862 - Skipping failure of Execute['find /var/log/webhcat -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] due to ignore_failures. Failure reason: Execution of 'find /var/log/webhcat -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;' returned 1. find: /var/log/webhcat: No such file or directory
2017-06-06 14:24:33,875 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:34,701 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:34,705 - Directory['/var/run/webhcat'] {'owner': 'hcat', 'group': 'hadoop', 'create_parents': True, 'mode': 0755}
2017-06-06 14:24:34,706 - Changing group for /var/run/webhcat from 0 to hadoop
2017-06-06 14:24:34,706 - Directory['/var/log/webhcat'] {'owner': 'hcat', 'group': 'hadoop', 'create_parents': True, 'mode': 0755}
2017-06-06 14:24:34,707 - Creating directory Directory['/var/log/webhcat'] since it doesn't exist.
2017-06-06 14:24:34,707 - Changing owner for /var/log/webhcat from 0 to hcat
2017-06-06 14:24:34,707 - Changing group for /var/log/webhcat from 0 to hadoop
2017-06-06 14:24:34,711 - Directory['/usr/hdp/current/hive-webhcat/etc/webhcat'] {'owner': 'hcat', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:34,712 - Changing owner for /usr/hdp/current/hive-webhcat/etc/webhcat from 0 to hcat
2017-06-06 14:24:34,712 - Changing group for /usr/hdp/current/hive-webhcat/etc/webhcat from 0 to hadoop
2017-06-06 14:24:34,713 - XmlConfig['webhcat-site.xml'] {'owner': 'hcat', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-webhcat/etc/webhcat', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:34,734 - Generating config: /usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-site.xml
2017-06-06 14:24:34,734 - File['/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-site.xml'] {'owner': 'hcat', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,811 - Writing File['/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-site.xml'] because it doesn't exist
2017-06-06 14:24:34,817 - Changing owner for /usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-site.xml from 0 to hcat
2017-06-06 14:24:34,818 - Changing group for /usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-site.xml from 0 to hadoop
2017-06-06 14:24:34,837 - File['/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-env.sh'] {'content': InlineTemplate(...), 'owner': 'hcat', 'group': 'hadoop'}
2017-06-06 14:24:34,838 - Writing File['/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-env.sh'] because it doesn't exist
2017-06-06 14:24:34,838 - Changing owner for /usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-env.sh from 0 to hcat
2017-06-06 14:24:34,838 - Changing group for /usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-env.sh from 0 to hadoop
2017-06-06 14:24:34,839 - Directory['/usr/hdp/current/hive-webhcat/etc/webhcat'] {'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:34,840 - File['/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-log4j.properties'] {'content': ..., 'owner': 'hcat', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:34,840 - Writing File['/usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-log4j.properties'] because contents don't match
2017-06-06 14:24:34,840 - Changing owner for /usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-log4j.properties from 0 to hcat
INFO 2017-06-06 14:24:45,709 ActionQueue.py:471 - Cmd log for taskId=64 and chunk 2/2 of log for command: 
2017-06-06 14:24:34,841 - Changing group for /usr/hdp/current/hive-webhcat/etc/webhcat/webhcat-log4j.properties from 0 to hadoop
2017-06-06 14:24:34,841 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:34,842 - Execute['cd /var/run/webhcat ; /usr/hdp/current/hive-webhcat/sbin/webhcat_server.sh start'] {'environment': {'HADOOP_HOME': u'/usr/hdp/current/hadoop-client'}, 'not_if': "ambari-sudo.sh su hcat -l -s /bin/bash -c 'ls /var/run/webhcat/webhcat.pid >/dev/null 2>&1 && ps -p `cat /var/run/webhcat/webhcat.pid` >/dev/null 2>&1'", 'user': 'hcat'}

Command completed successfully!
INFO 2017-06-06 14:24:45,709 ActionQueue.py:382 - End command output log for command with id = 64, role = WEBHCAT_SERVER, roleCommand = START
INFO 2017-06-06 14:24:45,710 RecoveryManager.py:185 - current status is set to STARTED for WEBHCAT_SERVER
INFO 2017-06-06 14:24:45,710 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=64, current state of WEBHCAT_SERVER to STARTED
INFO 2017-06-06 14:24:46,006 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:24:46,045 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of NAMENODE to STARTED
INFO 2017-06-06 14:24:46,045 Controller.py:246 - Adding 1 commands. Heartbeat id = 58
INFO 2017-06-06 14:24:46,046 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role NAMENODE for service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:24:46,057 ActionQueue.py:186 - Kicking off a thread for the command, id=17-0 taskId=61
INFO 2017-06-06 14:24:46,058 ActionQueue.py:275 - Executing command with id = 17-0, taskId = 61 for role = NAMENODE of cluster davidmod05cluster.
INFO 2017-06-06 14:24:46,059 ActionQueue.py:316 - Command execution metadata - taskId = 61, retry enabled = True, max retry duration (sec) = 600, log_output = True
WARNING 2017-06-06 14:24:46,067 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-61.txt'
INFO 2017-06-06 14:24:47,607 ActionQueue.py:358 - Quit retrying for command id 60. Status: COMPLETED, retryAble: True, retryDuration (sec): 580, last delay (sec): 1
INFO 2017-06-06 14:24:47,608 ActionQueue.py:363 - Command 60 completed successfully!
INFO 2017-06-06 14:24:47,608 ActionQueue.py:379 - Begin command output log for command with id = 60, role = METRICS_MONITOR, roleCommand = START
INFO 2017-06-06 14:24:47,608 ActionQueue.py:473 - Cmd log for taskId=60: 2017-06-06 14:24:30,476 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,152 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,183 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:32,183 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:32,184 - FS Type: 
2017-06-06 14:24:32,184 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:32,254 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,265 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:32,346 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:32,379 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:32,379 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:32,382 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:32,383 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:32,389 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:32,396 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:32,397 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:32,469 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,471 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:32,471 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:32,481 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:32,487 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:33,804 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:33,824 - checked_call['hostid'] {}
2017-06-06 14:24:33,857 - checked_call returned (0, '000a0d00')
2017-06-06 14:24:33,858 - Execute['find /var/log/ambari-metrics-monitor -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'ams'}
find: /var/log/ambari-metrics-monitor: No such file or directory
2017-06-06 14:24:34,219 - Skipping failure of Execute['find /var/log/ambari-metrics-monitor -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] due to ignore_failures. Failure reason: Execution of 'find /var/log/ambari-metrics-monitor -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;' returned 1. find: /var/log/ambari-metrics-monitor: No such file or directory
2017-06-06 14:24:34,220 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:35,643 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:35,645 - Directory['/etc/ambari-metrics-monitor/conf'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:35,646 - Changing owner for /etc/ambari-metrics-monitor/conf from 0 to ams
2017-06-06 14:24:35,646 - Changing group for /etc/ambari-metrics-monitor/conf from 0 to hadoop
2017-06-06 14:24:35,647 - Directory['/var/log/ambari-metrics-monitor'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'mode': 0755}
2017-06-06 14:24:35,647 - Creating directory Directory['/var/log/ambari-metrics-monitor'] since it doesn't exist.
2017-06-06 14:24:35,647 - Changing owner for /var/log/ambari-metrics-monitor from 0 to ams
2017-06-06 14:24:35,648 - Changing group for /var/log/ambari-metrics-monitor from 0 to hadoop
2017-06-06 14:24:35,648 - Directory['/var/run/ambari-metrics-monitor'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'mode': 0755}
2017-06-06 14:24:35,648 - Creating directory Directory['/var/run/ambari-metrics-monitor'] since it doesn't exist.
2017-06-06 14:24:35,649 - Changing owner for /var/run/ambari-metrics-monitor from 0 to ams
2017-06-06 14:24:35,649 - Changing group for /var/run/ambari-metrics-monitor from 0 to hadoop
2017-06-06 14:24:35,649 - Directory['/usr/lib/python2.6/site-packages/resource_monitoring/psutil/build'] {'owner': 'ams', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:24:35,690 - Creating directory Directory['/usr/lib/python2.6/site-packages/resource_monitoring/psutil/build'] since it doesn't exist.
2017-06-06 14:24:35,691 - Changing owner for /usr/lib/python2.6/site-packages/resource_monitoring/psutil/build from 0 to ams
2017-06-06 14:24:35,691 - Changing group for /usr/lib/python2.6/site-packages/resource_monitoring/psutil/build from 0 to hadoop
2017-06-06 14:24:35,693 - Execute['ambari-sudo.sh chown -R ams:hadoop /usr/lib/python2.6/site-packages/resource_monitoring'] {}
2017-06-06 14:24:35,843 - TemplateConfig['/etc/ambari-metrics-monitor/conf/metric_monitor.ini'] {'owner': 'ams', 'template_tag': None, 'group': 'hadoop'}
2017-06-06 14:24:35,901 - File['/etc/ambari-metrics-monitor/conf/metric_monitor.ini'] {'content': Template('metric_monitor.ini.j2'), 'owner': 'ams', 'group': 'hadoop', 'mode': None}
2017-06-06 14:24:35,950 - Writing File['/etc/ambari-metrics-monitor/conf/metric_monitor.ini'] because contents don't match
2017-06-06 14:24:35,951 - Changing owner for /etc/ambari-metrics-monitor/conf/metric_monitor.ini from 0 to ams
2017-06-06 14:24:35,951 - Changing group for /etc/ambari-metrics-monitor/conf/metric_monitor.ini from 0 to hadoop
2017-06-06 14:24:35,952 - TemplateConfig['/etc/ambari-metrics-monitor/conf/metric_groups.conf'] {'owner': 'ams', 'template_tag': None, 'group': 'hadoop'}
2017-06-06 14:24:35,955 - File['/etc/ambari-metrics-monitor/conf/metric_groups.conf'] {'content': Template('metric_groups.conf.j2'), 'owner': 'ams', 'group': 'hadoop', 'mode': None}
2017-06-06 14:24:35,970 - Writing File['/etc/ambari-metrics-monitor/conf/metric_groups.conf'] because contents don't match
2017-06-06 14:24:35,971 - Changing owner for /etc/ambari-metrics-monitor/conf/metric_groups.conf from 0 to ams
2017-06-06 14:24:35,971 - Changing group for /etc/ambari-metrics-monitor/conf/metric_groups.conf from 0 to hadoop
2017-06-06 14:24:35,983 - File['/etc/ambari-metrics-monitor/conf/ams-env.sh'] {'content': InlineTemplate(...), 'owner': 'ams'}
2017-06-06 14:24:35,984 - Writing File['/etc/ambari-metrics-monitor/conf/ams-env.sh'] because it doesn't exist
2017-06-06 14:24:35,986 - Changing owner for /etc/ambari-metrics-monitor/conf/ams-env.sh from 0 to ams
2017-06-06 14:24:35,986 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:36,001 - Execute['/usr/sbin/ambari-metrics-monitor --config /etc/ambari-metrics-monitor/conf start'] {'user': 'ams'}

Command completed successfully!

INFO 2017-06-06 14:24:47,609 ActionQueue.py:382 - End command output log for command with id = 60, role = METRICS_MONITOR, roleCommand = START
INFO 2017-06-06 14:24:47,609 RecoveryManager.py:185 - current status is set to STARTED for METRICS_MONITOR
INFO 2017-06-06 14:24:47,609 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=60, current state of METRICS_MONITOR to STARTED
INFO 2017-06-06 14:25:02,896 Controller.py:255 - Adding 18 status commands. Heartbeat id = 73
INFO 2017-06-06 14:25:02,897 RecoveryManager.py:210 - desired status is set to INSTALLED for MAPREDUCE2_CLIENT
INFO 2017-06-06 14:25:02,898 RecoveryManager.py:210 - desired status is set to INSTALLED for OOZIE_CLIENT
INFO 2017-06-06 14:25:02,898 RecoveryManager.py:210 - desired status is set to INSTALLED for HIVE_CLIENT
INFO 2017-06-06 14:25:02,899 RecoveryManager.py:210 - desired status is set to INSTALLED for SLIDER
INFO 2017-06-06 14:25:02,900 RecoveryManager.py:210 - desired status is set to INSTALLED for APP_TIMELINE_SERVER
INFO 2017-06-06 14:25:03,257 RecoveryManager.py:210 - desired status is set to INSTALLED for HDFS_CLIENT
INFO 2017-06-06 14:25:03,351 RecoveryManager.py:210 - desired status is set to INSTALLED for PIG
INFO 2017-06-06 14:25:03,440 RecoveryManager.py:210 - desired status is set to INSTALLED for YARN_CLIENT
INFO 2017-06-06 14:25:03,568 RecoveryManager.py:210 - desired status is set to INSTALLED for SQOOP
INFO 2017-06-06 14:25:03,569 RecoveryManager.py:210 - desired status is set to INSTALLED for TEZ_CLIENT
INFO 2017-06-06 14:25:03,570 RecoveryManager.py:210 - desired status is set to INSTALLED for HISTORYSERVER
INFO 2017-06-06 14:25:03,571 RecoveryManager.py:210 - desired status is set to INSTALLED for HCAT
INFO 2017-06-06 14:25:03,571 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:03,590 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:03,621 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:03,637 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:03,653 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:03,669 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:03,821 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:04,232 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:04,396 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:04,411 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:04,667 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:04,698 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:04,990 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:05,042 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:05,326 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:05,378 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:05,437 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:05,488 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:25:19,239 ActionQueue.py:358 - Quit retrying for command id 57. Status: COMPLETED, retryAble: True, retryDuration (sec): 548, last delay (sec): 1
INFO 2017-06-06 14:25:19,240 ActionQueue.py:363 - Command 57 completed successfully!
INFO 2017-06-06 14:25:19,240 ActionQueue.py:379 - Begin command output log for command with id = 57, role = HIVE_METASTORE, roleCommand = START
INFO 2017-06-06 14:25:19,240 ActionQueue.py:471 - Cmd log for taskId=57 and chunk 1/3 of log for command: 
2017-06-06 14:24:30,358 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,319 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,339 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:31,339 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:31,339 - FS Type: 
2017-06-06 14:24:31,340 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:31,381 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,382 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:31,433 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:31,443 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:31,443 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:31,447 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:31,447 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:31,453 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,456 - Writing File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] because it doesn't exist
2017-06-06 14:24:31,456 - Changing owner for /usr/hdp/current/hadoop-client/conf/commons-logging.properties from 0 to hdfs
2017-06-06 14:24:31,463 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,463 - Writing File['/usr/hdp/current/hadoop-client/conf/health_check'] because it doesn't exist
2017-06-06 14:24:31,469 - Changing owner for /usr/hdp/current/hadoop-client/conf/health_check from 0 to hdfs
2017-06-06 14:24:31,469 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:31,472 - Writing File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] because contents don't match
2017-06-06 14:24:31,473 - Changing owner for /usr/hdp/current/hadoop-client/conf/log4j.properties from 0 to hdfs
2017-06-06 14:24:31,543 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,561 - Changing owner for /usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties from 0 to hdfs
2017-06-06 14:24:31,563 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:31,564 - Writing File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] because it doesn't exist
2017-06-06 14:24:31,564 - Changing permission for /usr/hdp/current/hadoop-client/conf/task-log4j.properties from 644 to 755
2017-06-06 14:24:31,564 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,565 - Changing owner for /usr/hdp/current/hadoop-client/conf/configuration.xsl from 0 to hdfs
2017-06-06 14:24:31,583 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:31,616 - Writing File['/etc/hadoop/conf/topology_mappings.data'] because it doesn't exist
2017-06-06 14:24:31,621 - Changing owner for /etc/hadoop/conf/topology_mappings.data from 0 to hdfs
2017-06-06 14:24:31,622 - Changing group for /etc/hadoop/conf/topology_mappings.data from 0 to hadoop
2017-06-06 14:24:31,623 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:31,641 - Writing File['/etc/hadoop/conf/topology_script.py'] because it doesn't exist
2017-06-06 14:24:31,641 - Changing permission for /etc/hadoop/conf/topology_script.py from 644 to 755
2017-06-06 14:24:32,875 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:32,903 - call['ambari-python-wrap /usr/bin/hdp-select status hive-server2'] {'timeout': 20}
2017-06-06 14:24:33,013 - call returned (0, 'hive-server2 - 2.5.4.2-7')
2017-06-06 14:24:33,014 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:33,135 - Execute['find /var/log/hive -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'hive'}
2017-06-06 14:24:33,807 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:33,807 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:33,819 - Directory['/etc/hive'] {'mode': 0755}
2017-06-06 14:24:33,820 - Directories to fill with configs: [u'/usr/hdp/current/hive-metastore/conf', u'/usr/hdp/current/hive-metastore/conf/conf.server']
2017-06-06 14:24:33,820 - Directory['/usr/hdp/current/hive-metastore/conf'] {'owner': 'hive', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:33,841 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-metastore/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:33,940 - Generating config: /usr/hdp/current/hive-metastore/conf/mapred-site.xml
2017-06-06 14:24:33,942 - File['/usr/hdp/current/hive-metastore/conf/mapred-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,077 - File['/usr/hdp/current/hive-metastore/conf/hive-default.xml.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:34,098 - File['/usr/hdp/current/hive-metastore/conf/hive-env.sh.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:34,101 - File['/usr/hdp/current/hive-metastore/conf/hive-exec-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:34,103 - File['/usr/hdp/current/hive-metastore/conf/hive-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:34,105 - Directory['/usr/hdp/current/hive-metastore/conf/conf.server'] {'owner': 'hive', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:24:34,106 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server from 2007 to hive
2017-06-06 14:24:34,106 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-metastore/conf/conf.server', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:34,131 - Generating config: /usr/hdp/current/hive-metastore/conf/conf.server/mapred-site.xml
2017-06-06 14:24:34,132 - File['/usr/hdp/current/hive-metastore/conf/conf.server/mapred-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,215 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/mapred-site.xml'] because it doesn't exist
2017-06-06 14:24:34,216 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/mapred-site.xml from 0 to hive
INFO 2017-06-06 14:25:19,241 ActionQueue.py:471 - Cmd log for taskId=57 and chunk 2/3 of log for command: 
2017-06-06 14:24:34,216 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/mapred-site.xml from 0 to hadoop
2017-06-06 14:24:34,217 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-default.xml.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:34,217 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-default.xml.template'] because it doesn't exist
2017-06-06 14:24:34,222 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hive-default.xml.template from 0 to hive
2017-06-06 14:24:34,228 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hive-default.xml.template from 0 to hadoop
2017-06-06 14:24:34,230 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh.template'] {'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:34,230 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh.template'] because it doesn't exist
2017-06-06 14:24:34,231 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh.template from 0 to hive
2017-06-06 14:24:34,231 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh.template from 0 to hadoop
2017-06-06 14:24:34,232 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-exec-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:34,232 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-exec-log4j.properties'] because it doesn't exist
2017-06-06 14:24:34,232 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hive-exec-log4j.properties from 0 to hive
2017-06-06 14:24:34,233 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hive-exec-log4j.properties from 0 to hadoop
2017-06-06 14:24:34,233 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-log4j.properties'] {'content': ..., 'owner': 'hive', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:34,233 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-log4j.properties'] because it doesn't exist
2017-06-06 14:24:34,234 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hive-log4j.properties from 0 to hive
2017-06-06 14:24:34,234 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hive-log4j.properties from 0 to hadoop
2017-06-06 14:24:34,234 - XmlConfig['hive-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-metastore/conf/conf.server', 'mode': 0644, 'configuration_attributes': {u'hidden': {u'javax.jdo.option.ConnectionPassword': u'HIVE_CLIENT,WEBHCAT_SERVER,HCAT,CONFIG_DOWNLOAD'}}, 'owner': 'hive', 'configurations': ...}
2017-06-06 14:24:34,250 - Generating config: /usr/hdp/current/hive-metastore/conf/conf.server/hive-site.xml
2017-06-06 14:24:34,251 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,558 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-site.xml'] because it doesn't exist
2017-06-06 14:24:34,559 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hive-site.xml from 0 to hive
2017-06-06 14:24:34,559 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hive-site.xml from 0 to hadoop
2017-06-06 14:24:34,560 - XmlConfig['hivemetastore-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hive-metastore/conf/conf.server', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'hive', 'configurations': {u'hive.service.metrics.hadoop2.component': u'hivemetastore', u'hive.metastore.metrics.enabled': u'true', u'hive.service.metrics.file.location': u'/var/log/hive/hivemetastore-report.json', u'hive.service.metrics.reporter': u'JSON_FILE, JMX, HADOOP2'}}
2017-06-06 14:24:34,576 - Generating config: /usr/hdp/current/hive-metastore/conf/conf.server/hivemetastore-site.xml
2017-06-06 14:24:34,577 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hivemetastore-site.xml'] {'owner': 'hive', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:34,590 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hivemetastore-site.xml'] because it doesn't exist
2017-06-06 14:24:34,590 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hivemetastore-site.xml from 0 to hive
2017-06-06 14:24:34,591 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hivemetastore-site.xml from 0 to hadoop
2017-06-06 14:24:34,597 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh'] {'content': InlineTemplate(...), 'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:34,598 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh'] because it doesn't exist
2017-06-06 14:24:34,598 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh from 0 to hive
2017-06-06 14:24:34,598 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hive-env.sh from 0 to hadoop
2017-06-06 14:24:34,599 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:34,603 - File['/etc/security/limits.d/hive.conf'] {'content': Template('hive.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:34,605 - Execute[('rm', '-f', u'/usr/hdp/current/hive-metastore/lib/ojdbc6.jar')] {'path': ['/bin', '/usr/bin/'], 'sudo': True}
2017-06-06 14:24:34,614 - File['/var/lib/ambari-agent/tmp/sqljdbc41.jar'] {'content': DownloadSource('http://10.0.0.13:8080/resources//sqljdbc41.jar')}
2017-06-06 14:24:34,615 - Downloading the file from http://10.0.0.13:8080/resources//sqljdbc41.jar
2017-06-06 14:24:34,636 - Execute[('cp', '--remove-destination', u'/var/lib/ambari-agent/tmp/sqljdbc41.jar', u'/usr/hdp/current/hive-metastore/lib/sqljdbc41.jar')] {'path': ['/bin', '/usr/bin/'], 'sudo': True}
2017-06-06 14:24:34,648 - File['/usr/hdp/current/hive-metastore/lib/sqljdbc41.jar'] {'mode': 0644}
2017-06-06 14:24:34,656 - Execute[('rm', '-f', u'/usr/hdp/current/hive-metastore/lib/ojdbc6.jar')] {'path': ['/bin', '/usr/bin/'], 'sudo': True}
2017-06-06 14:24:34,666 - File['/var/lib/ambari-agent/tmp/sqljdbc41.jar'] {'content': DownloadSource('http://10.0.0.13:8080/resources//sqljdbc41.jar')}
2017-06-06 14:24:34,667 - Not downloading the file from http://10.0.0.13:8080/resources//sqljdbc41.jar, because /var/lib/ambari-agent/tmp/sqljdbc41.jar already exists
2017-06-06 14:24:34,668 - Execute[('cp', '--remove-destination', u'/var/lib/ambari-agent/tmp/sqljdbc41.jar', u'/usr/hdp/current/hive-server2-hive2/lib/sqljdbc41.jar')] {'path': ['/bin', '/usr/bin/'], 'sudo': True}
2017-06-06 14:24:34,679 - File['/usr/hdp/current/hive-server2-hive2/lib/sqljdbc41.jar'] {'mode': 0644}
2017-06-06 14:24:34,681 - File['/usr/lib/ambari-agent/DBConnectionVerification.jar'] {'content': DownloadSource('http://10.0.0.13:8080/resources/DBConnectionVerification.jar'), 'mode': 0644}
2017-06-06 14:24:34,681 - Not downloading the file from http://10.0.0.13:8080/resources/DBConnectionVerification.jar, because /var/lib/ambari-agent/tmp/DBConnectionVerification.jar already exists
2017-06-06 14:24:34,689 - File['/usr/hdp/current/hive-metastore/conf/conf.server/hadoop-metrics2-hivemetastore.properties'] {'content': Template('hadoop-metrics2-hivemetastore.properties.j2'), 'owner': 'hive', 'group': 'hadoop'}
2017-06-06 14:24:34,690 - Writing File['/usr/hdp/current/hive-metastore/conf/conf.server/hadoop-metrics2-hivemetastore.properties'] because it doesn't exist
2017-06-06 14:24:34,691 - Changing owner for /usr/hdp/current/hive-metastore/conf/conf.server/hadoop-metrics2-hivemetastore.properties from 0 to hive
INFO 2017-06-06 14:25:19,241 ActionQueue.py:471 - Cmd log for taskId=57 and chunk 3/3 of log for command: 
2017-06-06 14:24:34,691 - Changing group for /usr/hdp/current/hive-metastore/conf/conf.server/hadoop-metrics2-hivemetastore.properties from 0 to hadoop
2017-06-06 14:24:34,692 - File['/var/lib/ambari-agent/tmp/start_metastore_script'] {'content': StaticFile('startMetastore.sh'), 'mode': 0755}
2017-06-06 14:24:34,693 - Writing File['/var/lib/ambari-agent/tmp/start_metastore_script'] because it doesn't exist
2017-06-06 14:24:34,693 - Changing permission for /var/lib/ambari-agent/tmp/start_metastore_script from 644 to 755
2017-06-06 14:24:34,694 - Directory['/var/run/hive'] {'owner': 'hive', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:34,694 - Creating directory Directory['/var/run/hive'] since it doesn't exist.
2017-06-06 14:24:34,697 - Changing owner for /var/run/hive from 0 to hive
2017-06-06 14:24:34,697 - Changing group for /var/run/hive from 0 to hadoop
2017-06-06 14:24:34,698 - Directory['/var/log/hive'] {'owner': 'hive', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:34,699 - Changing group for /var/log/hive from 128 to hadoop
2017-06-06 14:24:34,699 - Directory['/var/lib/hive'] {'owner': 'hive', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:34,700 - Changing owner for /var/lib/hive from 0 to hive
2017-06-06 14:24:34,700 - Changing group for /var/lib/hive from 0 to hadoop
2017-06-06 14:24:34,700 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:34,701 - Execute['export HIVE_CONF_DIR=/usr/hdp/current/hive-metastore/conf/conf.server ; /usr/hdp/current/hive-server2-hive2/bin/schematool -initSchema -dbType azuredb -userName v3504ab5e3a5e72486dbce3ac883431219ehivemetastoreLogin@hzsrvdosx3.database.windows.net -passWord [PROTECTED] -verbose'] {'not_if': u"ambari-sudo.sh su hive -l -s /bin/bash -c 'export HIVE_CONF_DIR=/usr/hdp/current/hive-metastore/conf/conf.server ; /usr/hdp/current/hive-server2-hive2/bin/schematool -info -dbType azuredb -userName v3504ab5e3a5e72486dbce3ac883431219ehivemetastoreLogin@hzsrvdosx3.database.windows.net -passWord [PROTECTED] -verbose'", 'user': 'hive'}
2017-06-06 14:25:18,823 - Skipping Execute['export HIVE_CONF_DIR=/usr/hdp/current/hive-metastore/conf/conf.server ; /usr/hdp/current/hive-server2-hive2/bin/schematool -initSchema -dbType azuredb -userName v3504ab5e3a5e72486dbce3ac883431219ehivemetastoreLogin@hzsrvdosx3.database.windows.net -passWord [PROTECTED] -verbose'] due to not_if
2017-06-06 14:25:18,828 - call['ambari-sudo.sh su hive -l -s /bin/bash -c 'cat /var/run/hive/hive.pid 1>/tmp/tmpYq47Io 2>/tmp/tmpZANdKD''] {'quiet': False}
2017-06-06 14:25:18,948 - call returned (1, '')
2017-06-06 14:25:18,948 - Execution of 'cat /var/run/hive/hive.pid 1>/tmp/tmpYq47Io 2>/tmp/tmpZANdKD' returned 1. cat: /var/run/hive/hive.pid: No such file or directory

2017-06-06 14:25:18,949 - Execute['/var/lib/ambari-agent/tmp/start_metastore_script /var/log/hive/hive.out /var/log/hive/hive.err /var/run/hive/hive.pid /usr/hdp/current/hive-metastore/conf/conf.server /var/log/hive'] {'environment': {'HIVE_BIN': 'hive', 'JAVA_HOME': u'/usr/lib/jvm/java-8-openjdk-amd64', 'HADOOP_HOME': u'/usr/hdp/current/hadoop-client'}, 'not_if': 'ls /var/run/hive/hive.pid >/dev/null 2>&1 && ps -p  >/dev/null 2>&1', 'user': 'hive', 'path': [u'/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/var/lib/ambari-agent:/usr/hdp/current/hive-metastore/bin:/usr/hdp/current/hadoop-client/bin']}

Command completed successfully!
INFO 2017-06-06 14:25:19,241 ActionQueue.py:382 - End command output log for command with id = 57, role = HIVE_METASTORE, roleCommand = START
INFO 2017-06-06 14:25:19,241 RecoveryManager.py:185 - current status is set to STARTED for HIVE_METASTORE
INFO 2017-06-06 14:25:19,242 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=57, current state of HIVE_METASTORE to STARTED
INFO 2017-06-06 14:25:19,257 Controller.py:297 - Heartbeat (response id = 86) with server is running...
INFO 2017-06-06 14:25:19,257 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:25:19,368 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:25:20,009 Controller.py:313 - Sending Heartbeat (id = 86)
INFO 2017-06-06 14:25:20,060 Controller.py:325 - Heartbeat response received (id = 87)
INFO 2017-06-06 14:25:20,061 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:25:20,061 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:25:20,070 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:25:20,071 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:25:20,071 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:25:20,971 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:25:55,623 ActionQueue.py:358 - Quit retrying for command id 62. Status: COMPLETED, retryAble: True, retryDuration (sec): 512, last delay (sec): 1
INFO 2017-06-06 14:25:55,623 ActionQueue.py:363 - Command 62 completed successfully!
INFO 2017-06-06 14:25:55,624 ActionQueue.py:379 - Begin command output log for command with id = 62, role = OOZIE_SERVER, roleCommand = START
INFO 2017-06-06 14:25:55,625 ActionQueue.py:471 - Cmd log for taskId=62 and chunk 1/3 of log for command: 
2017-06-06 14:24:30,478 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,713 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:31,718 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:31,718 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:31,718 - FS Type: 
2017-06-06 14:24:31,719 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:31,746 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,747 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:31,796 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:31,851 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:31,851 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:31,855 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:31,856 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:31,864 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,877 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:31,881 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:31,969 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,971 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:31,971 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:31,980 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:31,999 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:33,882 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:33,938 - checked_call['dpkg -s hdp-select | grep Version | awk '{print $2}''] {'stderr': -1}
2017-06-06 14:24:34,035 - checked_call returned (0, '2.5.4.2-7', '')
2017-06-06 14:24:34,038 - Execute['find /var/log/oozie -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'oozie'}
2017-06-06 14:24:34,438 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:37,049 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:37,055 - HdfsResource['/user/oozie'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'oozie', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0775}
2017-06-06 14:24:37,057 - Skipping 'HdfsResource['/user/oozie']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:24:37,057 - HdfsResource[None] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'action': ['execute'], 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:24:37,058 - No resources to create. 'create_on_execute' or 'delete_on_execute' wasn't triggered before this 'execute' action.
2017-06-06 14:24:37,060 - Directory['/usr/hdp/current/oozie-server/conf'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop'}
2017-06-06 14:24:37,062 - XmlConfig['oozie-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/oozie-server/conf', 'mode': 0664, 'configuration_attributes': {}, 'owner': 'oozie', 'configurations': ...}
2017-06-06 14:24:37,090 - Generating config: /usr/hdp/current/oozie-server/conf/oozie-site.xml
2017-06-06 14:24:37,090 - File['/usr/hdp/current/oozie-server/conf/oozie-site.xml'] {'owner': 'oozie', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0664, 'encoding': 'UTF-8'}
2017-06-06 14:24:37,156 - File['/usr/hdp/current/oozie-server/conf/oozie-env.sh'] {'content': InlineTemplate(...), 'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:37,158 - Writing File['/usr/hdp/current/oozie-server/conf/oozie-env.sh'] because contents don't match
2017-06-06 14:24:37,159 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:37,166 - File['/etc/security/limits.d/oozie.conf'] {'content': Template('oozie.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:37,167 - File['/usr/hdp/current/oozie-server/conf/oozie-log4j.properties'] {'content': ..., 'owner': 'oozie', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:37,179 - File['/usr/hdp/current/oozie-server/conf/adminusers.txt'] {'content': Template('adminusers.txt.j2'), 'owner': 'oozie', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:37,181 - File['/usr/lib/ambari-agent/DBConnectionVerification.jar'] {'content': DownloadSource('http://10.0.0.13:8080/resources/DBConnectionVerification.jar')}
2017-06-06 14:24:37,181 - Not downloading the file from http://10.0.0.13:8080/resources/DBConnectionVerification.jar, because /var/lib/ambari-agent/tmp/DBConnectionVerification.jar already exists
2017-06-06 14:24:37,182 - File['/usr/hdp/current/oozie-server/conf/hadoop-config.xml'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:37,182 - File['/usr/hdp/current/oozie-server/conf/oozie-default.xml'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:37,183 - Directory['/usr/hdp/current/oozie-server/conf/action-conf'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:37,184 - File['/usr/hdp/current/oozie-server/conf/action-conf/hive.xml'] {'owner': 'oozie', 'group': 'hadoop'}
2017-06-06 14:24:37,185 - File['/var/run/oozie/oozie.pid'] {'action': ['delete'], 'not_if': "ambari-sudo.sh su oozie -l -s /bin/bash -c 'ls /var/run/oozie/oozie.pid >/dev/null 2>&1 && ps -p `cat /var/run/oozie/oozie.pid` >/dev/null 2>&1'"}
2017-06-06 14:24:37,314 - Directory['/usr/hdp/current/oozie-server//var/tmp/oozie'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
INFO 2017-06-06 14:25:55,627 ActionQueue.py:471 - Cmd log for taskId=62 and chunk 2/3 of log for command: 
2017-06-06 14:24:37,314 - Creating directory Directory['/usr/hdp/current/oozie-server//var/tmp/oozie'] since it doesn't exist.
2017-06-06 14:24:37,433 - Changing owner for /usr/hdp/current/oozie-server//var/tmp/oozie from 0 to oozie
2017-06-06 14:24:37,433 - Changing group for /usr/hdp/current/oozie-server//var/tmp/oozie from 0 to hadoop
2017-06-06 14:24:37,434 - Directory['/var/run/oozie'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,435 - Creating directory Directory['/var/run/oozie'] since it doesn't exist.
2017-06-06 14:24:37,435 - Changing owner for /var/run/oozie from 0 to oozie
2017-06-06 14:24:37,436 - Changing group for /var/run/oozie from 0 to hadoop
2017-06-06 14:24:37,436 - Directory['/var/log/oozie'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,437 - Changing group for /var/log/oozie from 129 to hadoop
2017-06-06 14:24:37,438 - Directory['/var/tmp/oozie'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,439 - Changing group for /var/tmp/oozie from 129 to hadoop
2017-06-06 14:24:37,439 - Directory['/hadoop/oozie/data'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,440 - Creating directory Directory['/hadoop/oozie/data'] since it doesn't exist.
2017-06-06 14:24:37,480 - Changing owner for /hadoop/oozie/data from 0 to oozie
2017-06-06 14:24:37,484 - Changing group for /hadoop/oozie/data from 0 to hadoop
2017-06-06 14:24:37,486 - Directory['/usr/hdp/current/oozie-server'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,487 - Changing owner for /usr/hdp/current/oozie-server from 0 to oozie
2017-06-06 14:24:37,487 - Changing group for /usr/hdp/current/oozie-server from 0 to hadoop
2017-06-06 14:24:37,488 - Directory['/usr/hdp/current/oozie-server/oozie-server/webapps'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,489 - Changing group for /usr/hdp/current/oozie-server/oozie-server/webapps from 129 to hadoop
2017-06-06 14:24:37,489 - Directory['/usr/hdp/current/oozie-server/oozie-server/conf'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop', 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,491 - Changing owner for /usr/hdp/current/oozie-server/oozie-server/conf from 0 to oozie
2017-06-06 14:24:37,491 - Changing group for /usr/hdp/current/oozie-server/oozie-server/conf from 0 to hadoop
2017-06-06 14:24:37,492 - Directory['/usr/hdp/current/oozie-server/oozie-server'] {'owner': 'oozie', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:37,493 - Changing group for /usr/hdp/current/oozie-server/oozie-server from 129 to hadoop
2017-06-06 14:24:37,493 - Directory['/usr/hdp/current/oozie-server/libext'] {'create_parents': True}
2017-06-06 14:24:37,497 - Execute[('tar', '-xvf', u'/usr/hdp/current/oozie-server/oozie-sharelib.tar.gz', '-C', u'/usr/hdp/current/oozie-server')] {'not_if': "ambari-sudo.sh su oozie -l -s /bin/bash -c 'ls /var/run/oozie/oozie.pid >/dev/null 2>&1 && ps -p `cat /var/run/oozie/oozie.pid` >/dev/null 2>&1' || test -f /usr/hdp/current/oozie-server/.hashcode && test -d /usr/hdp/current/oozie-server/share", 'sudo': True}
2017-06-06 14:24:37,579 - Skipping Execute[('tar', '-xvf', u'/usr/hdp/current/oozie-server/oozie-sharelib.tar.gz', '-C', u'/usr/hdp/current/oozie-server')] due to not_if
2017-06-06 14:24:37,580 - Execute[('cp', u'/usr/share/HDP-oozie/ext-2.2.zip', u'/usr/hdp/current/oozie-server/libext')] {'not_if': "ambari-sudo.sh su oozie -l -s /bin/bash -c 'ls /var/run/oozie/oozie.pid >/dev/null 2>&1 && ps -p `cat /var/run/oozie/oozie.pid` >/dev/null 2>&1'", 'sudo': True}
2017-06-06 14:24:38,923 - Execute[('chown', u'oozie:hadoop', u'/usr/hdp/current/oozie-server/libext/ext-2.2.zip')] {'not_if': "ambari-sudo.sh su oozie -l -s /bin/bash -c 'ls /var/run/oozie/oozie.pid >/dev/null 2>&1 && ps -p `cat /var/run/oozie/oozie.pid` >/dev/null 2>&1'", 'sudo': True}
2017-06-06 14:24:39,070 - Directory['/usr/hdp/current/oozie-server/oozie-server/conf'] {'owner': 'oozie', 'group': 'hadoop', 'recursion_follow_links': True, 'recursive_ownership': True}
2017-06-06 14:24:39,120 - call['ambari-sudo.sh su oozie -l -s /bin/bash -c 'ls -l /usr/hdp/current/oozie-server/libext | awk '"'"'{print $9, $5}'"'"' | awk '"'"'NF > 0'"'"' 1>/tmp/tmpj0V_hx 2>/tmp/tmpKZ42nJ''] {'quiet': False}
2017-06-06 14:24:39,243 - call returned (0, '')
2017-06-06 14:24:39,250 - No need to run prepare-war since marker file /usr/hdp/current/oozie-server/.prepare_war_cmd already exists.
2017-06-06 14:24:39,251 - File['/usr/hdp/current/oozie-server/.hashcode'] {'mode': 0644}
2017-06-06 14:24:39,259 - Directory['/usr/hdp/current/oozie-server/conf/action-conf/hive'] {'owner': 'oozie', 'create_parents': True, 'group': 'hadoop'}
2017-06-06 14:24:39,259 - Creating directory Directory['/usr/hdp/current/oozie-server/conf/action-conf/hive'] since it doesn't exist.
2017-06-06 14:24:39,260 - Changing owner for /usr/hdp/current/oozie-server/conf/action-conf/hive from 0 to oozie
2017-06-06 14:24:39,260 - Changing group for /usr/hdp/current/oozie-server/conf/action-conf/hive from 0 to hadoop
2017-06-06 14:24:39,260 - XmlConfig['hive-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/oozie-server/conf/action-conf/hive', 'mode': 0644, 'configuration_attributes': {u'hidden': {u'javax.jdo.option.ConnectionPassword': u'HIVE_CLIENT,WEBHCAT_SERVER,HCAT,CONFIG_DOWNLOAD'}}, 'owner': 'oozie', 'configurations': ...}
2017-06-06 14:24:39,283 - Generating config: /usr/hdp/current/oozie-server/conf/action-conf/hive/hive-site.xml
2017-06-06 14:24:39,284 - File['/usr/hdp/current/oozie-server/conf/action-conf/hive/hive-site.xml'] {'owner': 'oozie', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:39,652 - Writing File['/usr/hdp/current/oozie-server/conf/action-conf/hive/hive-site.xml'] because it doesn't exist
2017-06-06 14:24:39,653 - Changing owner for /usr/hdp/current/oozie-server/conf/action-conf/hive/hive-site.xml from 0 to oozie
2017-06-06 14:24:39,656 - Changing group for /usr/hdp/current/oozie-server/conf/action-conf/hive/hive-site.xml from 0 to hadoop
2017-06-06 14:24:39,657 - XmlConfig['tez-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/oozie-server/conf/action-conf/hive', 'mode': 0664, 'configuration_attributes': {}, 'owner': 'oozie', 'configurations': ...}
2017-06-06 14:24:39,673 - Generating config: /usr/hdp/current/oozie-server/conf/action-conf/hive/tez-site.xml
2017-06-06 14:24:39,673 - File['/usr/hdp/current/oozie-server/conf/action-conf/hive/tez-site.xml'] {'owner': 'oozie', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0664, 'encoding': 'UTF-8'}
2017-06-06 14:24:39,755 - Writing File['/usr/hdp/current/oozie-server/conf/action-conf/hive/tez-site.xml'] because it doesn't exist
2017-06-06 14:24:39,757 - Changing owner for /usr/hdp/current/oozie-server/conf/action-conf/hive/tez-site.xml from 0 to oozie
2017-06-06 14:24:39,758 - Changing group for /usr/hdp/current/oozie-server/conf/action-conf/hive/tez-site.xml from 0 to hadoop
2017-06-06 14:24:39,758 - Changing permission for /usr/hdp/current/oozie-server/conf/action-conf/hive/tez-site.xml from 644 to 664
2017-06-06 14:24:39,758 - Directory['/usr/hdp/current/oozie-server/oozie-server'] {'owner': 'oozie', 'group': 'hadoop', 'recursive_ownership': True}
2017-06-06 14:24:39,760 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
INFO 2017-06-06 14:25:55,631 ActionQueue.py:471 - Cmd log for taskId=62 and chunk 3/3 of log for command: 
2017-06-06 14:24:39,761 - Execute['/usr/lib/jvm/java-8-openjdk-amd64/bin/java -cp /usr/lib/ambari-agent/DBConnectionVerification.jar:/usr/hdp/current/oozie-server/libext/sqljdbc41.jar org.apache.ambari.server.DBConnectionVerification 'jdbc:sqlserver://nj401jm4dw.database.windows.net;databaseName=v3504ab5e3a5e72486dbce3ac883431219eooziemetastore;sendStringParametersAsUnicode=false;' v3504ab5e3a5e72486dbce3ac883431219eooziemetastoreLogin [PROTECTED] com.microsoft.sqlserver.jdbc.SQLServerDriver'] {'tries': 5, 'user': 'oozie', 'try_sleep': 10}
2017-06-06 14:24:42,120 - Execute['cd /var/tmp/oozie && /usr/hdp/current/oozie-server/bin/ooziedb.sh create -sqlfile oozie.sql -run'] {'not_if': "ambari-sudo.sh su oozie -l -s /bin/bash -c 'ls /var/run/oozie/oozie.pid >/dev/null 2>&1 && ps -p `cat /var/run/oozie/oozie.pid` >/dev/null 2>&1'", 'ignore_failures': True, 'user': 'oozie'}
Skipping creation of oozie sharelib as host is sys prepped
2017-06-06 14:25:18,360 - HdfsResource['/user/oozie/share/lib/spark/hive-site.xml'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'source': '/usr/hdp/current/oozie-server/conf/action-conf/hive/hive-site.xml', 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'oozie', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'file', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0444}
2017-06-06 14:25:18,362 - HdfsResource[None] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'action': ['execute'], 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:25:18,363 - File['/var/lib/ambari-agent/tmp/hdfs_resources_1496759118.36.json'] {'content': '[{"group": "hadoop", "target": "/user/oozie/share/lib/spark/hive-site.xml", "source": "/usr/hdp/current/oozie-server/conf/action-conf/hive/hive-site.xml", "manageIfExists": true, "mode": "444", "owner": "oozie", "type": "file", "action": "create"}]', 'owner': 'hdfs'}
2017-06-06 14:25:18,364 - Writing File['/var/lib/ambari-agent/tmp/hdfs_resources_1496759118.36.json'] because it doesn't exist
2017-06-06 14:25:18,364 - Changing owner for /var/lib/ambari-agent/tmp/hdfs_resources_1496759118.36.json from 0 to hdfs
2017-06-06 14:25:18,364 - Execute['hadoop --config /usr/hdp/current/hadoop-client/conf jar /var/lib/ambari-agent/lib/fast-hdfs-resource.jar /var/lib/ambari-agent/tmp/hdfs_resources_1496759118.36.json'] {'logoutput': None, 'path': ['/usr/hdp/current/hadoop-client/bin'], 'user': 'hdfs'}
2017-06-06 14:25:37,739 - Execute['cd /var/tmp/oozie && /usr/hdp/current/oozie-server/bin/oozie-start.sh'] {'environment': {'OOZIE_CONFIG': u'/usr/hdp/current/oozie-server/conf'}, 'not_if': "ambari-sudo.sh su oozie -l -s /bin/bash -c 'ls /var/run/oozie/oozie.pid >/dev/null 2>&1 && ps -p `cat /var/run/oozie/oozie.pid` >/dev/null 2>&1'", 'user': 'oozie'}

Command completed successfully!
INFO 2017-06-06 14:25:55,632 ActionQueue.py:382 - End command output log for command with id = 62, role = OOZIE_SERVER, roleCommand = START
INFO 2017-06-06 14:25:55,633 RecoveryManager.py:185 - current status is set to STARTED for OOZIE_SERVER
INFO 2017-06-06 14:25:55,634 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=62, current state of OOZIE_SERVER to STARTED
INFO 2017-06-06 14:26:04,614 Controller.py:255 - Adding 20 status commands. Heartbeat id = 132
INFO 2017-06-06 14:26:04,854 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,142 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,169 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,210 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,238 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,268 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,297 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,346 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,373 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,396 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,433 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,456 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,491 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,526 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,546 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,569 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,810 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,841 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,870 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:05,907 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:19,563 Controller.py:297 - Heartbeat (response id = 145) with server is running...
INFO 2017-06-06 14:26:19,564 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:26:19,585 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:26:20,106 Controller.py:313 - Sending Heartbeat (id = 145)
INFO 2017-06-06 14:26:20,149 Controller.py:325 - Heartbeat response received (id = 146)
INFO 2017-06-06 14:26:20,149 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:26:20,150 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:26:20,150 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:26:20,150 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:26:20,151 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:26:21,054 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:26:29,086 ActionQueue.py:358 - Quit retrying for command id 61. Status: COMPLETED, retryAble: True, retryDuration (sec): 497, last delay (sec): 1
INFO 2017-06-06 14:26:29,086 ActionQueue.py:363 - Command 61 completed successfully!
INFO 2017-06-06 14:26:29,087 ActionQueue.py:379 - Begin command output log for command with id = 61, role = NAMENODE, roleCommand = START
INFO 2017-06-06 14:26:29,088 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 1/11 of log for command: 
2017-06-06 14:24:46,735 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:47,365 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:47,369 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:24:47,370 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:24:47,370 - FS Type: 
2017-06-06 14:24:47,370 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:24:47,389 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:47,390 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:24:47,429 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:24:47,437 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:24:47,439 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:24:47,443 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:24:47,444 - Changing owner for /var/run/hadoop from 202 to root
2017-06-06 14:24:47,445 - Changing group for /var/run/hadoop from 1003 to root
2017-06-06 14:24:47,446 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:24:47,456 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:47,462 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:47,465 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:24:47,497 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:47,502 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:24:47,502 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:24:47,513 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:24:47,529 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:24:48,411 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:48,412 - Stack Feature Version Info: stack_version=2.5, version=None, current_cluster_version=None -> 2.5
2017-06-06 14:24:48,446 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:24:48,466 - checked_call['dpkg -s hdp-select | grep Version | awk '{print $2}''] {'stderr': -1}
2017-06-06 14:24:48,564 - checked_call returned (0, '2.5.4.2-7', '')
2017-06-06 14:24:48,566 - Execute['find /var/log/hadoop/hdfs -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'hdfs'}
==> /var/log/hadoop/hdfs/hadoop-hdfs-zkfc-hn0-davidm.out <==
ulimit -a for user hdfs
core file size          (blocks, -c) unlimited
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 27712
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 128000
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 65536
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2017-06-06 14:24:48,793 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:48,794 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:48,798 - Directory['/etc/security/limits.d'] {'owner': 'root', 'create_parents': True, 'group': 'root'}
2017-06-06 14:24:48,814 - File['/etc/security/limits.d/hdfs.conf'] {'content': Template('hdfs.conf.j2'), 'owner': 'root', 'group': 'root', 'mode': 0644}
2017-06-06 14:24:48,816 - XmlConfig['hadoop-policy.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:48,835 - Generating config: /usr/hdp/current/hadoop-client/conf/hadoop-policy.xml
2017-06-06 14:24:48,835 - File['/usr/hdp/current/hadoop-client/conf/hadoop-policy.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:48,854 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:48,873 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:24:48,874 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:48,888 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:24:48,892 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:48,911 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:24:48,912 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:48,928 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:24:48,957 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:24:48,957 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:24:48,980 - XmlConfig['hdfs-site.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'configurations': ...}
2017-06-06 14:24:49,000 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:24:49,000 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
INFO 2017-06-06 14:26:29,088 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 2/11 of log for command: 
2017-06-06 14:24:49,145 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:24:49,176 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:24:49,177 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:24:49,267 - File['/usr/hdp/current/hadoop-client/conf/slaves'] {'content': Template('slaves.j2'), 'owner': 'hdfs'}
2017-06-06 14:24:49,274 - Directory['/hadoop/hdfs/namenode'] {'owner': 'hdfs', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:24:49,275 - Creating directory Directory['/hadoop/hdfs/namenode'] since it doesn't exist.
2017-06-06 14:24:49,276 - Changing owner for /hadoop/hdfs/namenode from 0 to hdfs
2017-06-06 14:24:49,279 - Changing group for /hadoop/hdfs/namenode from 0 to hadoop
2017-06-06 14:24:49,279 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:24:49,285 - Called service start with upgrade_type: None
2017-06-06 14:24:49,285 - Ranger admin not installed
2017-06-06 14:24:49,286 - Execute['ls /hadoop/hdfs/namenode | wc -l  | grep -q ^0$'] {}
2017-06-06 14:24:49,311 - Execute['yes Y | hdfs --config /usr/hdp/current/hadoop-client/conf namenode -format'] {'logoutput': True, 'path': ['/usr/hdp/current/hadoop-client/bin'], 'user': 'hdfs'}
17/06/06 14:24:52 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = hdfs
STARTUP_MSG:   host = 10.0.0.13/10.0.0.13
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.7.3.2.5.4.2-7
INFO 2017-06-06 14:26:29,089 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 3/11 of log for command: 
STARTUP_MSG:   classpath = /usr/hdp/current/hadoop-client/conf:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7-javadoc.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-core-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hadoop-lzo-0.6.0.2.5.4.2-7-sources.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-kms-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/azure-storage-4.2.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-hdfs-plugin-shim-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-plugin-classloader-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/aws-java-sdk-s3-1.10.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/joda-time-2.8.1.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ranger-yarn-plugin-shim-0.6.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/ojdbc6.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-azure.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-azure-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-annotations-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-nfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-auth.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-aws.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-aws-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/./:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/adls2-oauth2-token-provider-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/hadoop-azure-datalake-2.0.0-SNAPSHOT.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/azure-data-lake-store-sdk-2.0.4-SNAPSHOT.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-hdfs/.//hadoop-hdfs-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-simple-1.1.jar:/usr/hdp/2.5.4.2-7/had
INFO 2017-06-06 14:26:29,089 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 4/11 of log for command: 
oop-yarn/lib/microsoft-log4j-etwappender-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/hdinsight-ats-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/mdsdclient-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/metrics-core-3.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-dbcp2-2.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-20160212.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/sqljdbc4-4.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/azure-storage-4.2.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/zookeeper-3.4.6.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-pool2-2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-client-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-api-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.5.4.2-7/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/l
INFO 2017-06-06 14:26:29,090 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 5/11 of log for command: 
ib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-extras-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-streaming-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-sls-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//httpcore-4.4.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-lang3-3.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-distcp-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//nimbus-jose-jwt-3.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//httpclient-4.5.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-openstack-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//json-smart-1.1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-rumen-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//azure-keyvault-core-0.8.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-archives-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jcip-annotations-1.0.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.5.4.2-7/hadoop-mapreduce/.//hadoop-ant-2.7.3.2.5.4.2-7.jar::/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collec
INFO 2017-06-06 14:26:29,090 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 6/11 of log for command: 
tions-3.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.1.0-incubating.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.4.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang3-3.4.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/nimbus-jose-jwt-3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.5.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/json-smart-1.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-3.0.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/azure-keyvault-core-0.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.7.3.2.5.4.2-7.jar:/usr/hdp/current/hadoop-mapreduce-client/jcip-annotations-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.7.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-job-analyzer-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-with-fs-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-mapreduce-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-cache-plugin-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-api-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-examples-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-history-parser-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-tests-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-runtime-library-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-runtime-internals-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-dag-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-yarn-timeline-history-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/tez-common-0.7.0.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-collections-3.2.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.5.4.2-7/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/metrics-core-3.1.0.jar:/usr/hdp/2.5.4.2-7/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-collections4-4.1.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-azure-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/guava-11.0.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-io-2.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-mapreduce-client-common-2.
INFO 2017-06-06 14:26:29,090 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 7/11 of log for command: 
7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-annotations-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.5.4.2-7/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.5.4.2-7/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-yarn-server-web-proxy-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.5.4.2-7/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-mapreduce-client-core-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.5.4.2-7/tez/lib/hadoop-aws-2.7.3.2.5.4.2-7.jar:/usr/hdp/2.5.4.2-7/tez/conf
INFO 2017-06-06 14:26:29,090 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 8/11 of log for command: 
STARTUP_MSG:   build = git@github.com:hortonworks/hadoop.git -r e1f139118ccc75d6610c176bf7e09fb5cc902eb2; compiled by 'jenkins' on 2017-04-04T10:53Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/
17/06/06 14:24:52 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
17/06/06 14:24:52 INFO namenode.NameNode: createNameNode [-format]
17/06/06 14:24:57 WARN common.Util: Path /hadoop/hdfs/namenode should be specified as a URI in configuration files. Please update hdfs configuration.
17/06/06 14:24:57 WARN common.Util: Path /hadoop/hdfs/namenode should be specified as a URI in configuration files. Please update hdfs configuration.
Formatting using clusterid: CID-1d68d003-ac65-4d92-92b4-6a0c98cf1a7b
17/06/06 14:24:57 WARN common.Storage: set restore failed storage to true
17/06/06 14:24:57 INFO namenode.FSNamesystem: No KeyProvider found.
17/06/06 14:24:57 INFO namenode.FSNamesystem: Enabling async auditlog
17/06/06 14:24:57 INFO namenode.FSNamesystem: fsLock is fair:false
17/06/06 14:24:58 INFO blockmanagement.HeartbeatManager: Setting heartbeat recheck interval to 30000 since dfs.namenode.stale.datanode.interval is less than dfs.namenode.heartbeat.recheck-interval
17/06/06 14:24:58 ERROR blockmanagement.DatanodeManager: error reading hosts files: 
java.io.FileNotFoundException: /etc/hadoop/conf/dfs.exclude (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.util.HostsFileReader.readFileToSet(HostsFileReader.java:66)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.readFile(HostFileManager.java:72)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:138)
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:205)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:304)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:746)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:706)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1166)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1616)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1754)
17/06/06 14:24:58 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
17/06/06 14:24:58 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=false
17/06/06 14:24:58 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:01:00:00.000
17/06/06 14:24:58 INFO blockmanagement.BlockManager: The block deletion will start around 2017 Jun 06 15:24:58
17/06/06 14:24:58 INFO util.GSet: Computing capacity for map BlocksMap
17/06/06 14:24:58 INFO util.GSet: VM type       = 64-bit
17/06/06 14:24:59 INFO util.GSet: 2.0% max memory 1004 MB = 20.1 MB
17/06/06 14:24:59 INFO util.GSet: capacity      = 2^21 = 2097152 entries
17/06/06 14:24:59 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=true
17/06/06 14:24:59 INFO blockmanagement.BlockManager: dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
17/06/06 14:25:00 INFO blockmanagement.BlockManager: defaultReplication         = 3
17/06/06 14:25:00 INFO blockmanagement.BlockManager: maxReplication             = 50
17/06/06 14:25:00 INFO blockmanagement.BlockManager: minReplication             = 1
17/06/06 14:25:00 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
17/06/06 14:25:00 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
17/06/06 14:25:00 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
17/06/06 14:25:00 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
17/06/06 14:25:01 INFO namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
17/06/06 14:25:01 INFO namenode.FSNamesystem: supergroup          = hdfs
17/06/06 14:25:01 INFO namenode.FSNamesystem: isPermissionEnabled = false
17/06/06 14:25:01 INFO namenode.FSNamesystem: Determined nameservice ID: mycluster
17/06/06 14:25:01 INFO namenode.FSNamesystem: HA Enabled: true
17/06/06 14:25:01 INFO namenode.FSNamesystem: Append Enabled: true
17/06/06 14:25:02 INFO util.GSet: Computing capacity for map INodeMap
17/06/06 14:25:02 INFO util.GSet: VM type       = 64-bit
17/06/06 14:25:02 INFO util.GSet: 1.0% max memory 1004 MB = 10.0 MB
17/06/06 14:25:02 INFO util.GSet: capacity      = 2^20 = 1048576 entries
17/06/06 14:25:02 INFO namenode.FSDirectory: ACLs enabled? false
17/06/06 14:25:02 INFO namenode.FSDirectory: XAttrs enabled? true
17/06/06 14:25:02 INFO namenode.FSDirectory: Maximum size of an xattr: 16384
17/06/06 14:25:02 INFO namenode.NameNode: Caching file names occuring more than 10 times
17/06/06 14:25:02 INFO util.GSet: Computing capacity for map cachedBlocks
17/06/06 14:25:02 INFO util.GSet: VM type       = 64-bit
17/06/06 14:25:02 INFO util.GSet: 0.25% max memory 1004 MB = 2.5 MB
17/06/06 14:25:02 INFO util.GSet: capacity      = 2^18 = 262144 entries
17/06/06 14:25:02 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9900000095367432
17/06/06 14:25:02 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
17/06/06 14:25:03 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
17/06/06 14:25:03 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
17/06/06 14:25:03 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
17/06/06 14:25:03 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
17/06/06 14:25:03 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
17/06/06 14:25:03 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
17/06/06 14:25:03 INFO util.GSet: Computing capacity for map NameNodeRetryCache
17/06/06 14:25:03 INFO util.GSet: VM type       = 64-bit
17/06/06 14:25:03 INFO util.GSet: 0.029999999329447746% max memory 1004 MB = 308.4 KB
17/06/06 14:25:03 INFO util.GSet: capacity      = 2^15 = 32768 entries
17/06/06 14:25:12 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:13 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:14 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:15 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:16 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
INFO 2017-06-06 14:26:29,091 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 9/11 of log for command: 
17/06/06 14:25:17 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:18 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:19 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:20 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:21 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:22 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:23 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:24 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:25 INFO ipc.Client: Retrying connect to server: zk5-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.10:8485. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
17/06/06 14:25:27 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1939273880-10.0.0.13-1496759127928
17/06/06 14:25:28 INFO common.Storage: Storage directory /hadoop/hdfs/namenode has been successfully formatted.
17/06/06 14:25:30 INFO namenode.FSImageFormatProtobuf: Saving image file /hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression
17/06/06 14:25:30 INFO namenode.FSImageFormatProtobuf: Image file /hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 336 bytes saved in 0 seconds.
17/06/06 14:25:31 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
17/06/06 14:25:31 INFO util.ExitUtil: Exiting with status 0
17/06/06 14:25:31 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at 10.0.0.13/10.0.0.13
************************************************************/
yes: standard output: Broken pipe
2017-06-06 14:25:31,448 - Directory['/hadoop/hdfs/namenode/namenode-formatted/'] {'create_parents': True}
2017-06-06 14:25:31,449 - Creating directory Directory['/hadoop/hdfs/namenode/namenode-formatted/'] since it doesn't exist.
2017-06-06 14:25:31,455 - File['/etc/hadoop/conf/dfs.exclude'] {'owner': 'hdfs', 'content': Template('exclude_hosts_list.j2'), 'group': 'hadoop'}
2017-06-06 14:25:31,456 - Writing File['/etc/hadoop/conf/dfs.exclude'] because it doesn't exist
2017-06-06 14:25:31,457 - Changing owner for /etc/hadoop/conf/dfs.exclude from 0 to hdfs
2017-06-06 14:25:31,457 - Changing group for /etc/hadoop/conf/dfs.exclude from 0 to hadoop
2017-06-06 14:25:31,457 - Options for start command are: 
2017-06-06 14:25:31,458 - Directory['/var/run/hadoop'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 0755}
2017-06-06 14:25:31,459 - Changing owner for /var/run/hadoop from 0 to hdfs
2017-06-06 14:25:31,459 - Changing group for /var/run/hadoop from 0 to hadoop
2017-06-06 14:25:31,460 - Directory['/var/run/hadoop/hdfs'] {'owner': 'hdfs', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:25:31,461 - Directory['/var/log/hadoop/hdfs'] {'owner': 'hdfs', 'group': 'hadoop', 'create_parents': True}
2017-06-06 14:25:31,462 - File['/var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid'] {'action': ['delete'], 'not_if': 'ambari-sudo.sh  -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid && ambari-sudo.sh  -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid'}
2017-06-06 14:25:31,474 - Execute['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'ulimit -c unlimited ;  /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /usr/hdp/current/hadoop-client/conf start namenode''] {'environment': {'HADOOP_LIBEXEC_DIR': '/usr/hdp/current/hadoop-client/libexec'}, 'not_if': 'ambari-sudo.sh  -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid && ambari-sudo.sh  -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid'}
2017-06-06 14:25:35,983 - Waiting for the NameNode to broadcast whether it is Active or Standby...
2017-06-06 14:25:35,986 - call['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'curl -s '"'"'http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem'"'"' 1>/tmp/tmp9dfdyY 2>/tmp/tmp8ECT1h''] {'quiet': False}
2017-06-06 14:25:36,348 - call returned (7, '')
2017-06-06 14:25:36,348 - Getting jmx metrics from NN failed. URL: http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem
Traceback (most recent call last):
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/jmx.py", line 38, in get_value_from_jmx
    _, data, _ = get_user_call_output(cmd, user=run_user, quiet=False)
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/get_user_call_output.py", line 61, in get_user_call_output
    raise Fail(err_msg)
Fail: Execution of 'curl -s 'http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem' 1>/tmp/tmp9dfdyY 2>/tmp/tmp8ECT1h' returned 7. 

2017-06-06 14:25:36,444 - call['hdfs haadmin -ns mycluster -getServiceState nn1'] {'logoutput': True, 'user': 'hdfs'}
17/06/06 14:25:49 INFO ipc.Client: Retrying connect to server: hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.13:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
Operation failed: Call From 10.0.0.13/10.0.0.13 to hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
2017-06-06 14:25:49,434 - call returned (255, '17/06/06 14:25:49 INFO ipc.Client: Retrying connect to server: hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.13:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)\nOperation failed: Call From 10.0.0.13/10.0.0.13 to hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused')
INFO 2017-06-06 14:26:29,091 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 10/11 of log for command: 
2017-06-06 14:25:49,439 - call['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'curl -s '"'"'http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem'"'"' 1>/tmp/tmpaRvM4G 2>/tmp/tmpwIpG_n''] {'quiet': False}
2017-06-06 14:25:49,549 - call returned (7, '')
2017-06-06 14:25:49,550 - Getting jmx metrics from NN failed. URL: http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem
Traceback (most recent call last):
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/jmx.py", line 38, in get_value_from_jmx
    _, data, _ = get_user_call_output(cmd, user=run_user, quiet=False)
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/get_user_call_output.py", line 61, in get_user_call_output
    raise Fail(err_msg)
Fail: Execution of 'curl -s 'http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem' 1>/tmp/tmpaRvM4G 2>/tmp/tmpwIpG_n' returned 7. 

2017-06-06 14:25:49,551 - call['hdfs haadmin -ns mycluster -getServiceState nn2'] {'logoutput': True, 'user': 'hdfs'}
17/06/06 14:26:02 INFO ipc.Client: Retrying connect to server: hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.14:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
Operation failed: Call From 10.0.0.13/10.0.0.13 to hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
2017-06-06 14:26:02,449 - call returned (255, '17/06/06 14:26:02 INFO ipc.Client: Retrying connect to server: hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.14:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)\nOperation failed: Call From 10.0.0.13/10.0.0.13 to hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused')
2017-06-06 14:26:02,449 - NameNode HA states: active_namenodes = [], standby_namenodes = [], unknown_namenodes = [(u'nn1', 'hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070'), (u'nn2', 'hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070')]
2017-06-06 14:26:02,450 - Will retry 4 time(s), caught exception: No active NameNode was found.. Sleeping for 5 sec(s)
2017-06-06 14:26:07,459 - call['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'curl -s '"'"'http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem'"'"' 1>/tmp/tmp9gelHN 2>/tmp/tmpLxz44U''] {'quiet': False}
2017-06-06 14:26:08,283 - call returned (0, '')
2017-06-06 14:26:08,285 - call['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'curl -s '"'"'http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem'"'"' 1>/tmp/tmpuRO8yk 2>/tmp/tmpWJk91s''] {'quiet': False}
2017-06-06 14:26:08,547 - call returned (7, '')
2017-06-06 14:26:08,547 - Getting jmx metrics from NN failed. URL: http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem
Traceback (most recent call last):
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/jmx.py", line 38, in get_value_from_jmx
    _, data, _ = get_user_call_output(cmd, user=run_user, quiet=False)
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/get_user_call_output.py", line 61, in get_user_call_output
    raise Fail(err_msg)
Fail: Execution of 'curl -s 'http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem' 1>/tmp/tmpuRO8yk 2>/tmp/tmpWJk91s' returned 7. 

2017-06-06 14:26:08,548 - call['hdfs haadmin -ns mycluster -getServiceState nn2'] {'logoutput': True, 'user': 'hdfs'}
17/06/06 14:26:18 INFO ipc.Client: Retrying connect to server: hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.14:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
Operation failed: Call From 10.0.0.13/10.0.0.13 to hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
2017-06-06 14:26:18,927 - call returned (255, '17/06/06 14:26:18 INFO ipc.Client: Retrying connect to server: hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net/10.0.0.14:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)\nOperation failed: Call From 10.0.0.13/10.0.0.13 to hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused')
2017-06-06 14:26:18,927 - NameNode HA states: active_namenodes = [], standby_namenodes = [(u'nn1', 'hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070')], unknown_namenodes = [(u'nn2', 'hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070')]
2017-06-06 14:26:18,928 - Will retry 3 time(s), caught exception: No active NameNode was found.. Sleeping for 5 sec(s)
2017-06-06 14:26:23,941 - call['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'curl -s '"'"'http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem'"'"' 1>/tmp/tmpKFazAM 2>/tmp/tmpX3f11L''] {'quiet': False}
2017-06-06 14:26:24,049 - call returned (0, '')
2017-06-06 14:26:24,052 - call['ambari-sudo.sh su hdfs -l -s /bin/bash -c 'curl -s '"'"'http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem'"'"' 1>/tmp/tmprrOz_U 2>/tmp/tmpEwJYZ1''] {'quiet': False}
2017-06-06 14:26:24,166 - call returned (0, '')
2017-06-06 14:26:24,167 - NameNode HA states: active_namenodes = [(u'nn1', 'hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070')], standby_namenodes = [(u'nn2', 'hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070')], unknown_namenodes = []
2017-06-06 14:26:24,168 - Waiting for this NameNode to leave Safemode due to the following conditions: HA: True, isActive: True, upgradeType: None
2017-06-06 14:26:24,168 - Waiting up to 19 minutes for the NameNode to leave Safemode...
2017-06-06 14:26:24,169 - Execute['/usr/hdp/current/hadoop-hdfs-namenode/bin/hdfs dfsadmin -fs hdfs://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:8020 -safemode get | grep 'Safe mode is OFF''] {'logoutput': True, 'tries': 115, 'user': 'hdfs', 'try_sleep': 10}
Safe mode is OFF
2017-06-06 14:26:28,967 - HdfsResource['/tmp'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': None, 'user': 'hdfs', 'owner': 'hdfs', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0777}
INFO 2017-06-06 14:26:29,091 ActionQueue.py:471 - Cmd log for taskId=61 and chunk 11/11 of log for command: 
2017-06-06 14:26:28,969 - Skipping 'HdfsResource['/tmp']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:28,970 - HdfsResource['/user/ambari-qa'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': None, 'user': 'hdfs', 'owner': 'ambari-qa', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0770}
2017-06-06 14:26:28,971 - Skipping 'HdfsResource['/user/ambari-qa']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:28,972 - HdfsResource[None] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': None, 'user': 'hdfs', 'action': ['execute'], 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:26:28,973 - No resources to create. 'create_on_execute' or 'delete_on_execute' wasn't triggered before this 'execute' action.
2017-06-06 14:26:28,973 - Ranger admin not installed

Command completed successfully!
INFO 2017-06-06 14:26:29,091 ActionQueue.py:382 - End command output log for command with id = 61, role = NAMENODE, roleCommand = START
INFO 2017-06-06 14:26:29,092 ActionQueue.py:386 - Begin command stderr log for command with id = 61, role = NAMENODE, roleCommand = START
INFO 2017-06-06 14:26:29,093 ActionQueue.py:473 - Cmd log for taskId=61: 2017-06-06 14:25:36,348 - Getting jmx metrics from NN failed. URL: http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem
Traceback (most recent call last):
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/jmx.py", line 38, in get_value_from_jmx
    _, data, _ = get_user_call_output(cmd, user=run_user, quiet=False)
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/get_user_call_output.py", line 61, in get_user_call_output
    raise Fail(err_msg)
Fail: Execution of 'curl -s 'http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem' 1>/tmp/tmp9dfdyY 2>/tmp/tmp8ECT1h' returned 7. 

2017-06-06 14:25:49,550 - Getting jmx metrics from NN failed. URL: http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem
Traceback (most recent call last):
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/jmx.py", line 38, in get_value_from_jmx
    _, data, _ = get_user_call_output(cmd, user=run_user, quiet=False)
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/get_user_call_output.py", line 61, in get_user_call_output
    raise Fail(err_msg)
Fail: Execution of 'curl -s 'http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem' 1>/tmp/tmpaRvM4G 2>/tmp/tmpwIpG_n' returned 7. 

2017-06-06 14:26:08,547 - Getting jmx metrics from NN failed. URL: http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem
Traceback (most recent call last):
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/jmx.py", line 38, in get_value_from_jmx
    _, data, _ = get_user_call_output(cmd, user=run_user, quiet=False)
  File "/usr/lib/python2.6/site-packages/resource_management/libraries/functions/get_user_call_output.py", line 61, in get_user_call_output
    raise Fail(err_msg)
Fail: Execution of 'curl -s 'http://hn1-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:30070/jmx?qry=Hadoop:service=NameNode,name=FSNamesystem' 1>/tmp/tmpuRO8yk 2>/tmp/tmpWJk91s' returned 7.
INFO 2017-06-06 14:26:29,093 ActionQueue.py:389 - End command stderr log for command with id = 61, role = NAMENODE, roleCommand = START
INFO 2017-06-06 14:26:29,094 RecoveryManager.py:185 - current status is set to STARTED for NAMENODE
INFO 2017-06-06 14:26:29,094 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=61, current state of NAMENODE to STARTED
INFO 2017-06-06 14:26:33,350 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:26:33,406 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:26:33,460 RecoveryManager.py:210 - desired status is set to STARTED for APP_TIMELINE_SERVER
INFO 2017-06-06 14:26:33,460 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of APP_TIMELINE_SERVER to STARTED
INFO 2017-06-06 14:26:33,461 RecoveryManager.py:210 - desired status is set to STARTED for HISTORYSERVER
INFO 2017-06-06 14:26:33,461 RecoveryManager.py:717 - Received EXECUTION_COMMAND (START), desired state of HISTORYSERVER to STARTED
INFO 2017-06-06 14:26:33,462 Controller.py:246 - Adding 2 commands. Heartbeat id = 160
INFO 2017-06-06 14:26:33,463 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role APP_TIMELINE_SERVER for service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:33,464 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role HISTORYSERVER for service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:26:33,497 ActionQueue.py:275 - Executing command with id = 21-0, taskId = 66 for role = APP_TIMELINE_SERVER of cluster davidmod05cluster.
INFO 2017-06-06 14:26:33,498 ActionQueue.py:316 - Command execution metadata - taskId = 66, retry enabled = False, max retry duration (sec) = 0, log_output = True
WARNING 2017-06-06 14:26:33,506 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-66.txt'
INFO 2017-06-06 14:26:38,994 ActionQueue.py:358 - Quit retrying for command id 66. Status: COMPLETED, retryAble: False, retryDuration (sec): -1, last delay (sec): 1
INFO 2017-06-06 14:26:38,995 ActionQueue.py:363 - Command 66 completed successfully!
INFO 2017-06-06 14:26:38,995 ActionQueue.py:379 - Begin command output log for command with id = 66, role = APP_TIMELINE_SERVER, roleCommand = START
INFO 2017-06-06 14:26:38,997 ActionQueue.py:471 - Cmd log for taskId=66 and chunk 1/4 of log for command: 
2017-06-06 14:26:34,236 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:34,240 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:34,246 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:34,302 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:34,303 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:34,356 - checked_call returned (0, '')
2017-06-06 14:26:34,358 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:34,358 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:34,996 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:35,000 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:35,007 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:35,056 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:35,057 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:35,103 - checked_call returned (0, '')
2017-06-06 14:26:35,105 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:35,105 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:35,106 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:26:35,107 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:26:35,107 - FS Type: 
2017-06-06 14:26:35,107 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:26:35,131 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:26:35,133 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:26:35,176 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:26:35,184 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:26:35,185 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:26:35,187 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:26:35,189 - Changing owner for /var/run/hadoop from 202 to root
2017-06-06 14:26:35,189 - Changing group for /var/run/hadoop from 1003 to root
2017-06-06 14:26:35,190 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:26:35,196 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:26:35,201 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:26:35,202 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:26:35,230 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:26:35,231 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:26:35,232 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:26:35,242 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:26:35,249 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:26:35,890 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:35,895 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:35,900 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:35,942 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:35,943 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:35,988 - checked_call returned (0, '')
2017-06-06 14:26:35,990 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:35,990 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:35,992 - call['ambari-python-wrap /usr/bin/hdp-select status hadoop-yarn-resourcemanager'] {'timeout': 20}
2017-06-06 14:26:36,030 - call returned (0, 'hadoop-yarn-resourcemanager - 2.5.4.2-7')
2017-06-06 14:26:36,040 - Stack Feature Version Info: stack_version=2.5, version=2.5.4.2-7, current_cluster_version=2.5.4.2-7 -> 2.5.4.2-7
2017-06-06 14:26:36,072 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:36,077 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:36,082 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:36,209 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:36,210 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:36,251 - checked_call returned (0, '')
2017-06-06 14:26:36,253 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:36,253 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:36,258 - Execute['find /var/log/hadoop-yarn/yarn -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'yarn'}
==> /var/log/hadoop-yarn/yarn/yarn-yarn-resourcemanager-hn0-davidm.out <==
Jun 06, 2017 2:24:53 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver as a provider class
Jun 06, 2017 2:24:53 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO 2017-06-06 14:26:38,998 ActionQueue.py:471 - Cmd log for taskId=66 and chunk 2/4 of log for command: 
INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices as a root resource class
Jun 06, 2017 2:24:53 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
Jun 06, 2017 2:24:53 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.9 09/02/2011 11:17 AM'
Jun 06, 2017 2:24:53 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
Jun 06, 2017 2:24:56 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
Jun 06, 2017 2:24:59 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices to GuiceManagedComponentProvider with the scope "Singleton"
2017-06-06 14:26:36,334 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:26:36,334 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:26:36,350 - Directory['/var/log/hadoop-yarn/nodemanager/recovery-state'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:26:36,354 - Directory['/var/run/hadoop-yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:36,355 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:36,357 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:36,358 - Directory['/var/run/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:36,361 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:36,362 - Directory['/var/log/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:36,363 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:36,364 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'group': 'hadoop', 'ignore_failures': True, 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:36,365 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:26:36,385 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
2017-06-06 14:26:36,385 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:36,435 - XmlConfig['hdfs-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:26:36,450 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:26:36,450 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:36,555 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:26:36,570 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:26:36,571 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:36,644 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 201 to yarn
2017-06-06 14:26:36,645 - XmlConfig['yarn-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:26:36,666 - Generating config: /usr/hdp/current/hadoop-client/conf/yarn-site.xml
2017-06-06 14:26:36,667 - File['/usr/hdp/current/hadoop-client/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:36,935 - XmlConfig['capacity-scheduler.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:26:36,967 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:26:36,968 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:37,014 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 202 to yarn
2017-06-06 14:26:37,015 - Directory['/hadoop/yarn/timeline'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:37,015 - Creating directory Directory['/hadoop/yarn/timeline'] since it doesn't exist.
2017-06-06 14:26:37,016 - Changing owner for /hadoop/yarn/timeline from 0 to yarn
2017-06-06 14:26:37,017 - Changing group for /hadoop/yarn/timeline from 0 to hadoop
2017-06-06 14:26:37,017 - Directory['/hadoop/yarn/timeline'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:37,018 - HdfsResource['/atshistory'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'change_permissions_for_parents': True, 'owner': 'yarn', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0755}
2017-06-06 14:26:37,021 - Skipping 'HdfsResource['/atshistory']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:37,022 - HdfsResource['/atshistory/done'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'yarn', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0700}
INFO 2017-06-06 14:26:38,998 ActionQueue.py:471 - Cmd log for taskId=66 and chunk 3/4 of log for command: 
2017-06-06 14:26:37,023 - Skipping 'HdfsResource['/atshistory/done']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:37,024 - HdfsResource['/atshistory'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'change_permissions_for_parents': True, 'owner': 'yarn', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0755}
2017-06-06 14:26:37,024 - Skipping 'HdfsResource['/atshistory']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:37,025 - HdfsResource['/atshistory/active'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'yarn', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 01777}
2017-06-06 14:26:37,026 - Skipping 'HdfsResource['/atshistory/active']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:37,027 - HdfsResource[None] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'action': ['execute'], 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:26:37,028 - No resources to create. 'create_on_execute' or 'delete_on_execute' wasn't triggered before this 'execute' action.
2017-06-06 14:26:37,035 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}
2017-06-06 14:26:37,040 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}
2017-06-06 14:26:37,048 - File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] {'content': InlineTemplate(...), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}
2017-06-06 14:26:37,050 - Writing File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] because contents don't match
2017-06-06 14:26:37,051 - File['/usr/hdp/current/hadoop-yarn-timelineserver/bin/container-executor'] {'group': 'hadoop', 'mode': 02050}
2017-06-06 14:26:37,055 - File['/usr/hdp/current/hadoop-client/conf/container-executor.cfg'] {'content': Template('container-executor.cfg.j2'), 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:26:37,056 - Directory['/cgroups_test/cpu'] {'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:26:37,060 - File['/usr/hdp/current/hadoop-client/conf/mapred-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'mode': 0755}
2017-06-06 14:26:37,064 - File['/usr/hdp/current/hadoop-client/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}
2017-06-06 14:26:37,065 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:37,084 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:26:37,084 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:37,165 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 203 to mapred
2017-06-06 14:26:37,166 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:37,181 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:26:37,181 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:37,207 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 203 to hdfs
2017-06-06 14:26:37,207 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:37,223 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:26:37,223 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:37,233 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:37,233 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:37,248 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:26:37,249 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:37,257 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:37,272 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:26:37,273 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:37,285 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:26:37,286 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:26:37,286 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:26:37,287 - File['/var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid'] {'action': ['delete'], 'not_if': "ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid`'"}
2017-06-06 14:26:37,345 - File['/hadoop/yarn/timeline/leveldb-timeline-store.ldb/LOCK'] {'action': ['delete'], 'not_if': "ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid`'", 'ignore_failures': True, 'only_if': 'ls /hadoop/yarn/timeline/leveldb-timeline-store.ldb/LOCK'}
2017-06-06 14:26:37,413 - Skipping File['/hadoop/yarn/timeline/leveldb-timeline-store.ldb/LOCK'] due to only_if
INFO 2017-06-06 14:26:38,998 ActionQueue.py:471 - Cmd log for taskId=66 and chunk 4/4 of log for command: 
2017-06-06 14:26:37,414 - Execute['ulimit -c unlimited; export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-yarn-timelineserver/sbin/yarn-daemon.sh --config /usr/hdp/current/hadoop-client/conf start timelineserver'] {'not_if': "ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid`'", 'user': 'yarn'}
2017-06-06 14:26:38,642 - Execute['ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid`''] {'not_if': "ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid`'", 'tries': 5, 'try_sleep': 1}
2017-06-06 14:26:38,763 - Skipping Execute['ambari-sudo.sh su yarn -l -s /bin/bash -c 'ls /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid && ps -p `cat /var/run/hadoop-yarn/yarn/yarn-yarn-timelineserver.pid`''] due to not_if

Command completed successfully!
INFO 2017-06-06 14:26:39,004 ActionQueue.py:382 - End command output log for command with id = 66, role = APP_TIMELINE_SERVER, roleCommand = START
INFO 2017-06-06 14:26:39,005 RecoveryManager.py:185 - current status is set to STARTED for APP_TIMELINE_SERVER
INFO 2017-06-06 14:26:39,007 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=66, current state of APP_TIMELINE_SERVER to STARTED
INFO 2017-06-06 14:26:39,020 ActionQueue.py:275 - Executing command with id = 21-0, taskId = 67 for role = HISTORYSERVER of cluster davidmod05cluster.
INFO 2017-06-06 14:26:39,021 ActionQueue.py:316 - Command execution metadata - taskId = 67, retry enabled = False, max retry duration (sec) = 0, log_output = True
WARNING 2017-06-06 14:26:39,089 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-67.txt'
INFO 2017-06-06 14:26:46,003 ActionQueue.py:358 - Quit retrying for command id 67. Status: COMPLETED, retryAble: False, retryDuration (sec): -1, last delay (sec): 1
INFO 2017-06-06 14:26:46,004 ActionQueue.py:363 - Command 67 completed successfully!
INFO 2017-06-06 14:26:46,004 ActionQueue.py:379 - Begin command output log for command with id = 67, role = HISTORYSERVER, roleCommand = START
INFO 2017-06-06 14:26:46,004 ActionQueue.py:471 - Cmd log for taskId=67 and chunk 1/4 of log for command: 
2017-06-06 14:26:39,999 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:40,006 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:40,011 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:40,082 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:40,083 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:40,156 - checked_call returned (0, '')
2017-06-06 14:26:40,157 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:40,157 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:40,810 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:40,813 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:40,821 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:40,901 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:40,902 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:40,974 - checked_call returned (0, '')
2017-06-06 14:26:40,975 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:40,975 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:40,978 - Skipping creation of User and Group as host is sys prepped or ignore_groupsusers_create flag is on
2017-06-06 14:26:40,978 - Skipping setting dfs cluster admin and tez view acls as host is sys prepped
2017-06-06 14:26:40,978 - FS Type: 
2017-06-06 14:26:40,978 - Directory['/etc/hadoop'] {'mode': 0755}
2017-06-06 14:26:41,008 - File['/usr/hdp/current/hadoop-client/conf/hadoop-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:26:41,009 - Directory['/var/lib/ambari-agent/tmp/hadoop_java_io_tmpdir'] {'owner': 'hdfs', 'group': 'hadoop', 'mode': 01777}
2017-06-06 14:26:41,054 - Execute[('setenforce', '0')] {'not_if': '(! which getenforce ) || (which getenforce && getenforce | grep -q Disabled)', 'sudo': True, 'only_if': 'test -f /selinux/enforce'}
2017-06-06 14:26:41,080 - Skipping Execute[('setenforce', '0')] due to not_if
2017-06-06 14:26:41,081 - Directory['/var/log/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'mode': 0775, 'cd_access': 'a'}
2017-06-06 14:26:41,088 - Directory['/var/run/hadoop'] {'owner': 'root', 'create_parents': True, 'group': 'root', 'cd_access': 'a'}
2017-06-06 14:26:41,089 - Directory['/tmp/hadoop-hdfs'] {'owner': 'hdfs', 'create_parents': True, 'cd_access': 'a'}
Skipping copying of fast-hdfs-resource.jar as host is sys prepped
2017-06-06 14:26:41,096 - File['/usr/hdp/current/hadoop-client/conf/commons-logging.properties'] {'content': Template('commons-logging.properties.j2'), 'owner': 'hdfs'}
2017-06-06 14:26:41,100 - File['/usr/hdp/current/hadoop-client/conf/health_check'] {'content': Template('health_check.j2'), 'owner': 'hdfs'}
2017-06-06 14:26:41,101 - File['/usr/hdp/current/hadoop-client/conf/log4j.properties'] {'content': ..., 'owner': 'hdfs', 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:26:41,132 - File['/usr/hdp/current/hadoop-client/conf/hadoop-metrics2.properties'] {'content': Template('hadoop-metrics2.properties.j2'), 'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:26:41,134 - File['/usr/hdp/current/hadoop-client/conf/task-log4j.properties'] {'content': StaticFile('task-log4j.properties'), 'mode': 0755}
2017-06-06 14:26:41,134 - File['/usr/hdp/current/hadoop-client/conf/configuration.xsl'] {'owner': 'hdfs', 'group': 'hadoop'}
2017-06-06 14:26:41,152 - File['/etc/hadoop/conf/topology_mappings.data'] {'owner': 'hdfs', 'content': Template('topology_mappings.data.j2'), 'only_if': 'test -d /etc/hadoop/conf', 'group': 'hadoop'}
2017-06-06 14:26:41,162 - File['/etc/hadoop/conf/topology_script.py'] {'content': StaticFile('topology_script.py'), 'only_if': 'test -d /etc/hadoop/conf', 'mode': 0755}
2017-06-06 14:26:42,019 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:42,024 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:42,029 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:42,124 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:42,125 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:42,248 - checked_call returned (0, '')
2017-06-06 14:26:42,253 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:42,253 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:42,255 - call['ambari-python-wrap /usr/bin/hdp-select status hadoop-yarn-resourcemanager'] {'timeout': 20}
2017-06-06 14:26:42,351 - call returned (0, 'hadoop-yarn-resourcemanager - 2.5.4.2-7')
2017-06-06 14:26:42,361 - Stack Feature Version Info: stack_version=2.5, version=2.5.4.2-7, current_cluster_version=2.5.4.2-7 -> 2.5.4.2-7
2017-06-06 14:26:42,407 - The hadoop conf dir /usr/hdp/current/hadoop-client/conf exists, will call conf-select on it for version 2.5.4.2-7
2017-06-06 14:26:42,416 - Checking if need to create versioned conf dir /etc/hadoop/2.5.4.2-7/0
2017-06-06 14:26:42,425 - call[('ambari-python-wrap', u'/usr/bin/conf-select', 'create-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False, 'stderr': -1}
2017-06-06 14:26:42,526 - call returned (1, '/etc/hadoop/2.5.4.2-7/0 exist already', '')
2017-06-06 14:26:42,527 - checked_call[('ambari-python-wrap', u'/usr/bin/conf-select', 'set-conf-dir', '--package', 'hadoop', '--stack-version', '2.5.4.2-7', '--conf-version', '0')] {'logoutput': False, 'sudo': True, 'quiet': False}
2017-06-06 14:26:42,604 - checked_call returned (0, '')
2017-06-06 14:26:42,607 - Ensuring that hadoop has the correct symlink structure
2017-06-06 14:26:42,607 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf
2017-06-06 14:26:42,610 - Execute['find /var/log/hadoop-mapreduce/mapred -maxdepth 1 -type f -name '*.out' -exec echo '==> {} <==' \; -exec tail -n 100 {} \;'] {'logoutput': True, 'ignore_failures': True, 'user': 'mapred'}
2017-06-06 14:26:42,968 - Trying to acquire a lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:26:42,968 - Acquired the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
INFO 2017-06-06 14:26:46,005 ActionQueue.py:471 - Cmd log for taskId=67 and chunk 2/4 of log for command: 
2017-06-06 14:26:42,971 - HdfsResource['/app-logs'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'user': 'hdfs', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'recursive_chmod': True, 'owner': 'yarn', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0777}
2017-06-06 14:26:42,975 - Skipping 'HdfsResource['/app-logs']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:42,975 - HdfsResource['/tmp'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'hdfs', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0777}
2017-06-06 14:26:42,976 - Skipping 'HdfsResource['/tmp']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:42,977 - HdfsResource['/tmp/entity-file-history/active'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'yarn', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:26:42,978 - Skipping 'HdfsResource['/tmp/entity-file-history/active']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:42,978 - HdfsResource['/mapred'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'mapred', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:26:42,981 - Skipping 'HdfsResource['/mapred']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:42,982 - HdfsResource['/mapred/system'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'owner': 'hdfs', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:26:42,984 - Skipping 'HdfsResource['/mapred/system']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:42,985 - HdfsResource['/mr-history/done'] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'change_permissions_for_parents': True, 'owner': 'mapred', 'group': 'hadoop', 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'type': 'directory', 'action': ['create_on_execute'], 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp'], 'mode': 0777}
2017-06-06 14:26:42,986 - Skipping 'HdfsResource['/mr-history/done']' because it is in ignore file /var/lib/ambari-agent/data/.hdfs_resource_ignore.
2017-06-06 14:26:42,987 - HdfsResource[None] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'action': ['execute'], 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:26:42,988 - No resources to create. 'create_on_execute' or 'delete_on_execute' wasn't triggered before this 'execute' action.
2017-06-06 14:26:42,988 - Directory['/hadoop/mapreduce/jhs'] {'owner': 'mapred', 'group': 'hadoop', 'create_parents': True, 'recursive_ownership': True, 'cd_access': 'a'}
2017-06-06 14:26:42,989 - Creating directory Directory['/hadoop/mapreduce/jhs'] since it doesn't exist.
2017-06-06 14:26:42,990 - Changing owner for /hadoop/mapreduce/jhs from 0 to mapred
2017-06-06 14:26:42,991 - Changing group for /hadoop/mapreduce/jhs from 0 to hadoop
2017-06-06 14:26:42,998 - Directory['/var/log/hadoop-yarn/nodemanager/recovery-state'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:26:43,000 - Directory['/var/run/hadoop-yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:43,001 - Directory['/var/run/hadoop-yarn/yarn'] {'owner': 'yarn', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:43,002 - Directory['/var/log/hadoop-yarn/yarn'] {'owner': 'yarn', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:43,003 - Directory['/var/run/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:43,005 - Directory['/var/run/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:43,006 - Directory['/var/log/hadoop-mapreduce'] {'owner': 'mapred', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:43,008 - Directory['/var/log/hadoop-mapreduce/mapred'] {'owner': 'mapred', 'group': 'hadoop', 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:43,009 - Directory['/var/log/hadoop-yarn'] {'owner': 'yarn', 'group': 'hadoop', 'ignore_failures': True, 'create_parents': True, 'cd_access': 'a'}
2017-06-06 14:26:43,012 - XmlConfig['core-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'fs.defaultFS': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:26:43,034 - Generating config: /usr/hdp/current/hadoop-client/conf/core-site.xml
INFO 2017-06-06 14:26:46,005 ActionQueue.py:471 - Cmd log for taskId=67 and chunk 3/4 of log for command: 
2017-06-06 14:26:43,034 - File['/usr/hdp/current/hadoop-client/conf/core-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,102 - XmlConfig['hdfs-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {u'final': {u'dfs.support.append': u'true', u'dfs.datanode.data.dir': u'true', u'dfs.namenode.http-address': u'true', u'dfs.namenode.name.dir': u'true', u'dfs.webhdfs.enabled': u'true', u'dfs.datanode.failed.volumes.tolerated': u'true'}}, 'owner': 'hdfs', 'configurations': ...}
2017-06-06 14:26:43,120 - Generating config: /usr/hdp/current/hadoop-client/conf/hdfs-site.xml
2017-06-06 14:26:43,123 - File['/usr/hdp/current/hadoop-client/conf/hdfs-site.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,228 - XmlConfig['mapred-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:26:43,248 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:26:43,248 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,329 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 201 to yarn
2017-06-06 14:26:43,330 - XmlConfig['yarn-site.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:26:43,348 - Generating config: /usr/hdp/current/hadoop-client/conf/yarn-site.xml
2017-06-06 14:26:43,348 - File['/usr/hdp/current/hadoop-client/conf/yarn-site.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,551 - XmlConfig['capacity-scheduler.xml'] {'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'mode': 0644, 'configuration_attributes': {}, 'owner': 'yarn', 'configurations': ...}
2017-06-06 14:26:43,567 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:26:43,567 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'yarn', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': 0644, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,591 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 202 to yarn
2017-06-06 14:26:43,597 - File['/etc/security/limits.d/yarn.conf'] {'content': Template('yarn.conf.j2'), 'mode': 0644}
2017-06-06 14:26:43,600 - File['/etc/security/limits.d/mapreduce.conf'] {'content': Template('mapreduce.conf.j2'), 'mode': 0644}
2017-06-06 14:26:43,610 - File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] {'content': InlineTemplate(...), 'owner': 'yarn', 'group': 'hadoop', 'mode': 0755}
2017-06-06 14:26:43,611 - Writing File['/usr/hdp/current/hadoop-client/conf/yarn-env.sh'] because contents don't match
2017-06-06 14:26:43,613 - File['/usr/hdp/current/hadoop-yarn-client/bin/container-executor'] {'group': 'hadoop', 'mode': 02050}
2017-06-06 14:26:43,616 - File['/usr/hdp/current/hadoop-client/conf/container-executor.cfg'] {'content': Template('container-executor.cfg.j2'), 'group': 'hadoop', 'mode': 0644}
2017-06-06 14:26:43,617 - Directory['/cgroups_test/cpu'] {'group': 'hadoop', 'create_parents': True, 'mode': 0755, 'cd_access': 'a'}
2017-06-06 14:26:43,622 - File['/usr/hdp/current/hadoop-client/conf/mapred-env.sh'] {'content': InlineTemplate(...), 'owner': 'hdfs', 'mode': 0755}
2017-06-06 14:26:43,627 - File['/usr/hdp/current/hadoop-client/conf/taskcontroller.cfg'] {'content': Template('taskcontroller.cfg.j2'), 'owner': 'hdfs'}
2017-06-06 14:26:43,628 - XmlConfig['mapred-site.xml'] {'owner': 'mapred', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:43,643 - Generating config: /usr/hdp/current/hadoop-client/conf/mapred-site.xml
2017-06-06 14:26:43,644 - File['/usr/hdp/current/hadoop-client/conf/mapred-site.xml'] {'owner': 'mapred', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,717 - Changing owner for /usr/hdp/current/hadoop-client/conf/mapred-site.xml from 203 to mapred
2017-06-06 14:26:43,718 - XmlConfig['capacity-scheduler.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:43,734 - Generating config: /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml
2017-06-06 14:26:43,734 - File['/usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,768 - Changing owner for /usr/hdp/current/hadoop-client/conf/capacity-scheduler.xml from 203 to hdfs
2017-06-06 14:26:43,769 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:43,783 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-client.xml
2017-06-06 14:26:43,784 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,794 - Directory['/usr/hdp/current/hadoop-client/conf/secure'] {'owner': 'root', 'create_parents': True, 'group': 'hadoop', 'cd_access': 'a'}
2017-06-06 14:26:43,795 - XmlConfig['ssl-client.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf/secure', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:43,810 - Generating config: /usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml
2017-06-06 14:26:43,810 - File['/usr/hdp/current/hadoop-client/conf/secure/ssl-client.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,820 - XmlConfig['ssl-server.xml'] {'owner': 'hdfs', 'group': 'hadoop', 'conf_dir': '/usr/hdp/current/hadoop-client/conf', 'configuration_attributes': {}, 'configurations': ...}
2017-06-06 14:26:43,835 - Generating config: /usr/hdp/current/hadoop-client/conf/ssl-server.xml
2017-06-06 14:26:43,836 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml'] {'owner': 'hdfs', 'content': InlineTemplate(...), 'group': 'hadoop', 'mode': None, 'encoding': 'UTF-8'}
2017-06-06 14:26:43,848 - File['/usr/hdp/current/hadoop-client/conf/ssl-client.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:26:43,849 - File['/usr/hdp/current/hadoop-client/conf/ssl-server.xml.example'] {'owner': 'mapred', 'group': 'hadoop'}
2017-06-06 14:26:43,849 - Releasing the lock on /var/lib/ambari-agent/tmp/link_configs_lock_file
2017-06-06 14:26:43,853 - Called copy_to_hdfs tarball: mapreduce
2017-06-06 14:26:43,853 - Default version is 2.5.4.2-7
2017-06-06 14:26:43,853 - Skipping copying /usr/hdp/2.5.4.2-7/hadoop/mapreduce.tar.gz to /hdp/apps/2.5.4.2-7/mapreduce/mapreduce.tar.gz for mapreduce as its a sys_prepped host.
2017-06-06 14:26:43,853 - Called copy_to_hdfs tarball: tez
2017-06-06 14:26:43,853 - Default version is 2.5.4.2-7
2017-06-06 14:26:43,854 - Skipping copying /usr/hdp/2.5.4.2-7/tez/lib/tez.tar.gz to /hdp/apps/2.5.4.2-7/tez/tez.tar.gz for tez as its a sys_prepped host.
2017-06-06 14:26:43,854 - Called copy_to_hdfs tarball: slider
2017-06-06 14:26:43,854 - Default version is 2.5.4.2-7
INFO 2017-06-06 14:26:46,005 ActionQueue.py:471 - Cmd log for taskId=67 and chunk 4/4 of log for command: 
2017-06-06 14:26:43,854 - Skipping copying /usr/hdp/2.5.4.2-7/slider/lib/slider.tar.gz to /hdp/apps/2.5.4.2-7/slider/slider.tar.gz for slider as its a sys_prepped host.
2017-06-06 14:26:43,856 - HdfsResource[None] {'security_enabled': False, 'hadoop_bin_dir': '/usr/hdp/current/hadoop-client/bin', 'keytab': [EMPTY], 'dfs_type': '', 'default_fs': 'wasb://davidmod05cluster-ctr@mod05sa.blob.core.windows.net', 'hdfs_resource_ignore_file': '/var/lib/ambari-agent/data/.hdfs_resource_ignore', 'hdfs_site': ..., 'kinit_path_local': '/usr/bin/kinit', 'principal_name': [EMPTY], 'user': 'hdfs', 'action': ['execute'], 'hadoop_conf_dir': '/usr/hdp/current/hadoop-client/conf', 'immutable_paths': [u'/hive/warehouse', u'/mr-history/done', u'/app-logs', u'/tmp']}
2017-06-06 14:26:43,857 - No resources to create. 'create_on_execute' or 'delete_on_execute' wasn't triggered before this 'execute' action.
2017-06-06 14:26:43,858 - File['/var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid'] {'action': ['delete'], 'not_if': "ambari-sudo.sh su mapred -l -s /bin/bash -c 'ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid && ps -p `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid`'"}
2017-06-06 14:26:44,142 - Execute['ulimit -c unlimited; export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-mapreduce-historyserver/sbin/mr-jobhistory-daemon.sh --config /usr/hdp/current/hadoop-client/conf start historyserver'] {'not_if': "ambari-sudo.sh su mapred -l -s /bin/bash -c 'ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid && ps -p `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid`'", 'user': 'mapred'}
2017-06-06 14:26:45,599 - Execute['ambari-sudo.sh su mapred -l -s /bin/bash -c 'ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid && ps -p `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid`''] {'not_if': "ambari-sudo.sh su mapred -l -s /bin/bash -c 'ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid && ps -p `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid`'", 'tries': 5, 'try_sleep': 1}
2017-06-06 14:26:45,825 - Skipping Execute['ambari-sudo.sh su mapred -l -s /bin/bash -c 'ls /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid && ps -p `cat /var/run/hadoop-mapreduce/mapred/mapred-mapred-historyserver.pid`''] due to not_if

Command completed successfully!
INFO 2017-06-06 14:26:46,005 ActionQueue.py:382 - End command output log for command with id = 67, role = HISTORYSERVER, roleCommand = START
INFO 2017-06-06 14:26:46,006 RecoveryManager.py:185 - current status is set to STARTED for HISTORYSERVER
INFO 2017-06-06 14:26:46,006 ActionQueue.py:414 - After EXECUTION_COMMAND (START), with taskId=67, current state of HISTORYSERVER to STARTED
INFO 2017-06-06 14:27:04,527 Controller.py:255 - Adding 21 status commands. Heartbeat id = 194
INFO 2017-06-06 14:27:04,627 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,643 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,661 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,679 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,692 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,711 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,731 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,757 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,785 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,817 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,849 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,872 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,908 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,953 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:04,976 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:05,002 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:05,257 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:05,272 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:05,286 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:05,299 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:05,313 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:27:19,584 Controller.py:297 - Heartbeat (response id = 208) with server is running...
INFO 2017-06-06 14:27:19,584 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:27:19,588 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:27:20,064 Controller.py:313 - Sending Heartbeat (id = 208)
INFO 2017-06-06 14:27:20,110 Controller.py:325 - Heartbeat response received (id = 209)
INFO 2017-06-06 14:27:20,111 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:27:20,111 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:27:20,111 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:27:20,111 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:27:20,112 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:27:21,012 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:28:05,218 Controller.py:255 - Adding 21 status commands. Heartbeat id = 258
INFO 2017-06-06 14:28:05,220 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,236 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,256 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,272 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,286 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,300 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,312 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,324 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,337 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,348 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,362 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,385 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,397 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,408 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,419 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,435 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,458 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,472 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,485 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,499 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:05,514 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:19,666 Controller.py:297 - Heartbeat (response id = 272) with server is running...
INFO 2017-06-06 14:28:19,667 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:28:19,670 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:28:20,205 Controller.py:313 - Sending Heartbeat (id = 272)
INFO 2017-06-06 14:28:20,248 Controller.py:325 - Heartbeat response received (id = 273)
INFO 2017-06-06 14:28:20,248 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:28:20,248 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:28:20,248 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:28:20,249 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:28:20,249 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:28:21,149 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:28:22,172 ClusterConfiguration.py:119 - Updating cached configurations for cluster davidmod05cluster
INFO 2017-06-06 14:28:22,212 Controller.py:246 - Adding 1 commands. Heartbeat id = 275
INFO 2017-06-06 14:28:22,213 ActionQueue.py:132 - Adding EXECUTION_COMMAND for role run_customscriptaction for service null of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:28:22,223 ActionQueue.py:275 - Executing command with id = 22-0, taskId = 68 for role = run_customscriptaction of cluster davidmod05cluster.
INFO 2017-06-06 14:28:22,224 ActionQueue.py:316 - Command execution metadata - taskId = 68, retry enabled = False, max retry duration (sec) = 0, log_output = False
WARNING 2017-06-06 14:28:22,239 CommandStatusDict.py:128 - [Errno 2] No such file or directory: '/var/lib/ambari-agent/data/output-68.txt'
INFO 2017-06-06 14:29:06,938 Controller.py:255 - Adding 21 status commands. Heartbeat id = 322
INFO 2017-06-06 14:29:06,939 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:06,986 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,049 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,090 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,131 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,159 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,194 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,226 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,265 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,295 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,349 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,394 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,426 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,466 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,507 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,566 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,632 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,691 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,753 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,807 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:07,899 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:29:19,996 Controller.py:297 - Heartbeat (response id = 334) with server is running...
INFO 2017-06-06 14:29:19,996 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:29:20,007 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:29:20,552 Controller.py:313 - Sending Heartbeat (id = 334)
INFO 2017-06-06 14:29:20,597 Controller.py:325 - Heartbeat response received (id = 335)
INFO 2017-06-06 14:29:20,597 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:29:20,597 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:29:20,598 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:29:20,598 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:29:20,598 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:29:21,498 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:29:21,735 logger.py:71 - Execute['export HIVE_CONF_DIR='/usr/hdp/current/hive-metastore/conf/conf.server' ; hive --hiveconf hive.metastore.uris=thrift://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:9083                 --hiveconf hive.metastore.client.connect.retry.delay=1                 --hiveconf hive.metastore.failure.retries=1                 --hiveconf hive.metastore.connect.retries=1                 --hiveconf hive.metastore.client.socket.timeout=14                 --hiveconf hive.execution.engine=mr -e 'show databases;''] {'path': ['/bin/', '/usr/bin/', '/usr/sbin/', u'/usr/hdp/current/hive-metastore/bin'], 'timeout_kill_strategy': 2, 'timeout': 60, 'user': 'ambari-qa'}
INFO 2017-06-06 14:29:21,741 logger.py:71 - Execute['! beeline -u 'jdbc:hive2://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:10001/;transportMode=http;httpPath=cliservice' -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL''] {'path': ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'], 'user': 'ambari-qa', 'timeout': 60}
INFO 2017-06-06 14:29:22,200 logger.py:71 - Execute['source /usr/hdp/current/oozie-server/conf/oozie-env.sh ; oozie admin -oozie http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:11000/oozie -status'] {'environment': None, 'user': 'oozie'}
INFO 2017-06-06 14:30:05,968 Controller.py:255 - Adding 21 status commands. Heartbeat id = 383
INFO 2017-06-06 14:30:05,970 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:05,981 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:05,995 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,008 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,031 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,048 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,060 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,072 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,084 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,095 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,106 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,119 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,141 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,152 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,164 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,176 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,188 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,206 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,221 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,240 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:06,251 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:30:20,104 Controller.py:297 - Heartbeat (response id = 397) with server is running...
INFO 2017-06-06 14:30:20,105 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:30:20,124 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:30:20,864 Controller.py:313 - Sending Heartbeat (id = 397)
INFO 2017-06-06 14:30:20,911 Controller.py:325 - Heartbeat response received (id = 398)
INFO 2017-06-06 14:30:20,911 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:30:20,911 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:30:20,911 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:30:20,911 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:30:20,912 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:30:21,815 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:30:38,811 ActionQueue.py:358 - Quit retrying for command id 68. Status: COMPLETED, retryAble: False, retryDuration (sec): -1, last delay (sec): 1
INFO 2017-06-06 14:30:38,812 ActionQueue.py:363 - Command 68 completed successfully!
INFO 2017-06-06 14:31:05,967 Controller.py:255 - Adding 21 status commands. Heartbeat id = 446
INFO 2017-06-06 14:31:05,968 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:05,992 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,007 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,027 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,040 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,053 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,065 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,076 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,087 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,099 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,112 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,126 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,140 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,152 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,166 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,178 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,190 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,201 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,215 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,227 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:06,239 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:31:20,340 Controller.py:297 - Heartbeat (response id = 460) with server is running...
INFO 2017-06-06 14:31:20,340 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:31:20,345 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:31:20,841 Controller.py:313 - Sending Heartbeat (id = 460)
INFO 2017-06-06 14:31:20,886 Controller.py:325 - Heartbeat response received (id = 461)
INFO 2017-06-06 14:31:20,887 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:31:20,887 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:31:20,887 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:31:20,888 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:31:20,888 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:31:21,790 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:32:06,013 Controller.py:255 - Adding 21 status commands. Heartbeat id = 510
INFO 2017-06-06 14:32:06,014 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,029 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,044 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,058 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,075 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,088 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,106 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,119 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,131 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,143 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,154 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,168 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,180 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,208 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,236 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,257 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,270 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,286 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,297 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,311 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:06,323 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:32:20,454 Controller.py:297 - Heartbeat (response id = 524) with server is running...
INFO 2017-06-06 14:32:20,455 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:32:20,461 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:32:20,960 Controller.py:313 - Sending Heartbeat (id = 524)
INFO 2017-06-06 14:32:21,004 Controller.py:325 - Heartbeat response received (id = 525)
INFO 2017-06-06 14:32:21,004 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:32:21,004 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:32:21,005 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:32:21,005 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:32:21,005 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:32:21,905 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:33:07,077 Controller.py:255 - Adding 21 status commands. Heartbeat id = 575
INFO 2017-06-06 14:33:07,078 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,092 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,105 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,118 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,132 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,146 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,158 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,170 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,180 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,192 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,205 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,219 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,232 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,243 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,258 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,271 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,288 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,305 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,326 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,339 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:07,352 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:33:20,572 Controller.py:297 - Heartbeat (response id = 588) with server is running...
INFO 2017-06-06 14:33:20,573 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:33:20,579 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:33:21,106 Controller.py:313 - Sending Heartbeat (id = 588)
INFO 2017-06-06 14:33:21,151 Controller.py:325 - Heartbeat response received (id = 589)
INFO 2017-06-06 14:33:21,152 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:33:21,152 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:33:21,153 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:33:21,154 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:33:21,154 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:33:22,054 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:34:07,240 Controller.py:255 - Adding 21 status commands. Heartbeat id = 639
INFO 2017-06-06 14:34:07,240 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,254 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,268 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,283 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,297 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,310 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,322 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,333 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,347 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,358 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,372 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,385 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,396 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,409 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,422 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,434 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,446 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,463 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,478 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,493 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:07,507 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:34:20,984 Controller.py:297 - Heartbeat (response id = 652) with server is running...
INFO 2017-06-06 14:34:20,985 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:34:20,991 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:34:21,490 Controller.py:313 - Sending Heartbeat (id = 652)
INFO 2017-06-06 14:34:21,536 Controller.py:325 - Heartbeat response received (id = 653)
INFO 2017-06-06 14:34:21,536 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:34:21,537 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:34:21,537 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:34:21,537 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:34:21,538 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:34:21,729 logger.py:71 - Execute['export HIVE_CONF_DIR='/usr/hdp/current/hive-metastore/conf/conf.server' ; hive --hiveconf hive.metastore.uris=thrift://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:9083                 --hiveconf hive.metastore.client.connect.retry.delay=1                 --hiveconf hive.metastore.failure.retries=1                 --hiveconf hive.metastore.connect.retries=1                 --hiveconf hive.metastore.client.socket.timeout=14                 --hiveconf hive.execution.engine=mr -e 'show databases;''] {'path': ['/bin/', '/usr/bin/', '/usr/sbin/', u'/usr/hdp/current/hive-metastore/bin'], 'timeout_kill_strategy': 2, 'timeout': 60, 'user': 'ambari-qa'}
INFO 2017-06-06 14:34:21,739 logger.py:71 - Execute['! beeline -u 'jdbc:hive2://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:10001/;transportMode=http;httpPath=cliservice' -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL''] {'path': ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'], 'user': 'ambari-qa', 'timeout': 60}
INFO 2017-06-06 14:34:21,941 logger.py:71 - Execute['source /usr/hdp/current/oozie-server/conf/oozie-env.sh ; oozie admin -oozie http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:11000/oozie -status'] {'environment': None, 'user': 'oozie'}
INFO 2017-06-06 14:34:22,438 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:35:07,582 Controller.py:255 - Adding 21 status commands. Heartbeat id = 703
INFO 2017-06-06 14:35:07,583 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,601 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,613 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,626 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,637 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,648 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,660 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,671 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,689 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,704 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,721 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,734 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,750 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,763 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,777 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,794 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,811 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,830 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,848 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,866 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:07,883 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:35:21,342 Controller.py:297 - Heartbeat (response id = 716) with server is running...
INFO 2017-06-06 14:35:21,343 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:35:21,350 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:35:21,893 Controller.py:313 - Sending Heartbeat (id = 716)
INFO 2017-06-06 14:35:21,939 Controller.py:325 - Heartbeat response received (id = 717)
INFO 2017-06-06 14:35:21,940 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:35:21,940 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:35:21,940 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:35:21,941 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:35:21,941 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:35:22,842 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:36:07,940 Controller.py:255 - Adding 21 status commands. Heartbeat id = 767
INFO 2017-06-06 14:36:07,941 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:07,960 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:07,976 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:07,992 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,006 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,022 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,037 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,048 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,062 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,079 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,090 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,100 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,111 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,123 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,133 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,144 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,161 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,174 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,186 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,197 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:08,208 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:36:21,409 Controller.py:297 - Heartbeat (response id = 780) with server is running...
INFO 2017-06-06 14:36:21,410 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:36:21,415 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:36:21,934 Controller.py:313 - Sending Heartbeat (id = 780)
INFO 2017-06-06 14:36:21,977 Controller.py:325 - Heartbeat response received (id = 781)
INFO 2017-06-06 14:36:21,977 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:36:21,977 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:36:21,978 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:36:21,978 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:36:21,979 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:36:22,880 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:37:08,009 Controller.py:255 - Adding 21 status commands. Heartbeat id = 831
INFO 2017-06-06 14:37:08,010 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,024 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,040 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,052 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,064 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,076 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,086 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,104 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,121 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,131 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,142 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,154 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,166 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,177 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,188 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,199 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,215 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,226 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,240 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,252 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:08,264 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:37:21,469 Controller.py:297 - Heartbeat (response id = 844) with server is running...
INFO 2017-06-06 14:37:21,931 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:37:21,936 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:37:22,459 Controller.py:313 - Sending Heartbeat (id = 844)
INFO 2017-06-06 14:37:22,501 Controller.py:325 - Heartbeat response received (id = 845)
INFO 2017-06-06 14:37:22,502 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:37:22,502 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:37:22,503 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:37:22,503 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:37:22,504 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:37:23,404 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:38:08,486 Controller.py:255 - Adding 21 status commands. Heartbeat id = 895
INFO 2017-06-06 14:38:08,487 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,503 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,517 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,532 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,544 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,559 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,575 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,589 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,600 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,610 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,623 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,636 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,648 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,659 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,672 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,688 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,700 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,710 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,721 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,735 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:08,749 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:38:21,978 Controller.py:297 - Heartbeat (response id = 908) with server is running...
INFO 2017-06-06 14:38:21,978 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:38:21,984 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:38:22,462 Controller.py:313 - Sending Heartbeat (id = 908)
INFO 2017-06-06 14:38:22,507 Controller.py:325 - Heartbeat response received (id = 909)
INFO 2017-06-06 14:38:22,507 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:38:22,508 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:38:22,508 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:38:22,509 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:38:22,509 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:38:23,410 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:39:08,528 Controller.py:255 - Adding 21 status commands. Heartbeat id = 959
INFO 2017-06-06 14:39:08,534 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,551 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,566 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,581 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,596 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,607 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,623 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,636 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,647 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,657 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,671 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,681 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,692 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,703 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,716 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,728 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,742 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,752 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,763 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,773 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:08,785 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:39:21,725 logger.py:71 - Execute['export HIVE_CONF_DIR='/usr/hdp/current/hive-metastore/conf/conf.server' ; hive --hiveconf hive.metastore.uris=thrift://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:9083                 --hiveconf hive.metastore.client.connect.retry.delay=1                 --hiveconf hive.metastore.failure.retries=1                 --hiveconf hive.metastore.connect.retries=1                 --hiveconf hive.metastore.client.socket.timeout=14                 --hiveconf hive.execution.engine=mr -e 'show databases;''] {'path': ['/bin/', '/usr/bin/', '/usr/sbin/', u'/usr/hdp/current/hive-metastore/bin'], 'timeout_kill_strategy': 2, 'timeout': 60, 'user': 'ambari-qa'}
INFO 2017-06-06 14:39:21,739 logger.py:71 - Execute['! beeline -u 'jdbc:hive2://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:10001/;transportMode=http;httpPath=cliservice' -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL''] {'path': ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'], 'user': 'ambari-qa', 'timeout': 60}
INFO 2017-06-06 14:39:21,962 logger.py:71 - Execute['source /usr/hdp/current/oozie-server/conf/oozie-env.sh ; oozie admin -oozie http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:11000/oozie -status'] {'environment': None, 'user': 'oozie'}
INFO 2017-06-06 14:39:22,006 Controller.py:297 - Heartbeat (response id = 972) with server is running...
INFO 2017-06-06 14:39:22,007 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:39:22,016 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:39:22,832 Controller.py:313 - Sending Heartbeat (id = 972)
INFO 2017-06-06 14:39:22,876 Controller.py:325 - Heartbeat response received (id = 973)
INFO 2017-06-06 14:39:22,877 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:39:22,877 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:39:22,877 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:39:22,877 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:39:22,878 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:39:23,779 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:40:08,857 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1023
INFO 2017-06-06 14:40:08,859 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,876 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,893 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,905 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,917 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,931 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,945 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,960 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,970 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,982 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:08,997 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,015 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,034 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,046 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,065 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,080 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,092 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,103 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,115 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,126 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:09,142 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:40:22,339 Controller.py:297 - Heartbeat (response id = 1036) with server is running...
INFO 2017-06-06 14:40:22,340 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:40:22,346 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:40:22,832 Controller.py:313 - Sending Heartbeat (id = 1036)
INFO 2017-06-06 14:40:22,877 Controller.py:325 - Heartbeat response received (id = 1037)
INFO 2017-06-06 14:40:22,878 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:40:22,878 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:40:22,879 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:40:22,879 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:40:22,880 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:40:23,780 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:41:08,858 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1087
INFO 2017-06-06 14:41:08,858 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,873 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,889 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,901 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,912 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,923 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,934 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,945 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,955 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,966 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,977 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:08,989 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,003 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,013 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,024 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,035 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,046 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,057 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,069 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,085 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:09,102 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:41:23,178 Controller.py:297 - Heartbeat (response id = 1101) with server is running...
INFO 2017-06-06 14:41:23,179 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:41:23,182 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:41:23,671 Controller.py:313 - Sending Heartbeat (id = 1101)
INFO 2017-06-06 14:41:23,716 Controller.py:325 - Heartbeat response received (id = 1102)
INFO 2017-06-06 14:41:23,717 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:41:23,717 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:41:23,717 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:41:23,717 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:41:23,718 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:41:24,618 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:42:08,812 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1151
INFO 2017-06-06 14:42:08,813 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,828 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,842 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,855 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,866 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,877 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,889 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,900 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,910 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,921 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,933 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,944 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,955 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,966 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,977 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:08,989 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:09,001 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:09,014 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:09,033 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:09,050 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:09,063 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:42:23,533 Controller.py:297 - Heartbeat (response id = 1165) with server is running...
INFO 2017-06-06 14:42:23,534 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:42:23,538 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:42:24,032 Controller.py:313 - Sending Heartbeat (id = 1165)
INFO 2017-06-06 14:42:24,074 Controller.py:325 - Heartbeat response received (id = 1166)
INFO 2017-06-06 14:42:24,074 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:42:24,075 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:42:24,075 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:42:24,075 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:42:24,077 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:42:24,977 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:43:09,143 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1215
INFO 2017-06-06 14:43:09,144 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,158 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,175 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,190 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,203 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,218 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,233 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,248 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,263 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,274 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,292 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,306 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,319 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,330 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,342 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,363 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,384 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,433 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,479 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,513 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:09,544 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:43:23,666 Controller.py:297 - Heartbeat (response id = 1229) with server is running...
INFO 2017-06-06 14:43:23,667 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:43:23,672 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:43:24,155 Controller.py:313 - Sending Heartbeat (id = 1229)
INFO 2017-06-06 14:43:24,202 Controller.py:325 - Heartbeat response received (id = 1230)
INFO 2017-06-06 14:43:24,202 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:43:24,203 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:43:24,203 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:43:24,203 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:43:24,204 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:43:25,104 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:44:09,325 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1279
INFO 2017-06-06 14:44:09,327 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,346 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,379 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,391 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,404 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,417 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,437 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,449 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,461 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,474 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,486 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,497 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,511 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,525 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,539 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,555 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,574 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,585 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,596 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,606 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:09,617 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:44:21,727 logger.py:71 - Execute['export HIVE_CONF_DIR='/usr/hdp/current/hive-metastore/conf/conf.server' ; hive --hiveconf hive.metastore.uris=thrift://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:9083                 --hiveconf hive.metastore.client.connect.retry.delay=1                 --hiveconf hive.metastore.failure.retries=1                 --hiveconf hive.metastore.connect.retries=1                 --hiveconf hive.metastore.client.socket.timeout=14                 --hiveconf hive.execution.engine=mr -e 'show databases;''] {'path': ['/bin/', '/usr/bin/', '/usr/sbin/', u'/usr/hdp/current/hive-metastore/bin'], 'timeout_kill_strategy': 2, 'timeout': 60, 'user': 'ambari-qa'}
INFO 2017-06-06 14:44:21,739 logger.py:71 - Execute['! beeline -u 'jdbc:hive2://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:10001/;transportMode=http;httpPath=cliservice' -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL''] {'path': ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'], 'user': 'ambari-qa', 'timeout': 60}
INFO 2017-06-06 14:44:21,930 logger.py:71 - Execute['source /usr/hdp/current/oozie-server/conf/oozie-env.sh ; oozie admin -oozie http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:11000/oozie -status'] {'environment': None, 'user': 'oozie'}
INFO 2017-06-06 14:44:23,795 Controller.py:297 - Heartbeat (response id = 1293) with server is running...
INFO 2017-06-06 14:44:23,796 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:44:23,800 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:44:24,419 Controller.py:313 - Sending Heartbeat (id = 1293)
INFO 2017-06-06 14:44:24,464 Controller.py:325 - Heartbeat response received (id = 1294)
INFO 2017-06-06 14:44:24,464 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:44:24,465 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:44:24,465 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:44:24,465 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:44:24,467 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:44:25,367 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:45:09,556 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1343
INFO 2017-06-06 14:45:09,556 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,571 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,587 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,604 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,619 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,630 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,641 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,653 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,664 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,676 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,688 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,699 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,710 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,723 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,734 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,748 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,765 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,782 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,799 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,814 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:09,830 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:45:23,940 Controller.py:297 - Heartbeat (response id = 1357) with server is running...
INFO 2017-06-06 14:45:23,941 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:45:23,944 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:45:24,473 Controller.py:313 - Sending Heartbeat (id = 1357)
INFO 2017-06-06 14:45:24,519 Controller.py:325 - Heartbeat response received (id = 1358)
INFO 2017-06-06 14:45:24,519 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:45:24,519 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:45:24,520 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:45:24,520 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:45:24,521 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:45:25,421 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:46:10,503 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1408
INFO 2017-06-06 14:46:10,504 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,516 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,532 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,544 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,561 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,575 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,594 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,606 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,620 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,633 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,645 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,657 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,668 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,681 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,695 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,709 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,721 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,732 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,743 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,754 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:10,765 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:46:23,973 Controller.py:297 - Heartbeat (response id = 1421) with server is running...
INFO 2017-06-06 14:46:23,973 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:46:23,980 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:46:24,489 Controller.py:313 - Sending Heartbeat (id = 1421)
INFO 2017-06-06 14:46:24,536 Controller.py:325 - Heartbeat response received (id = 1422)
INFO 2017-06-06 14:46:24,536 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:46:24,536 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:46:24,537 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:46:24,537 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:46:24,537 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:46:25,438 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:47:10,502 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1472
INFO 2017-06-06 14:47:10,503 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,516 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,530 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,541 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,552 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,564 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,576 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,588 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,601 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,613 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,625 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,635 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,646 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,662 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,675 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,689 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,700 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,721 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,737 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,751 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:10,766 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:47:24,855 Controller.py:297 - Heartbeat (response id = 1486) with server is running...
INFO 2017-06-06 14:47:24,855 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:47:24,860 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:47:25,364 Controller.py:313 - Sending Heartbeat (id = 1486)
INFO 2017-06-06 14:47:25,411 Controller.py:325 - Heartbeat response received (id = 1487)
INFO 2017-06-06 14:47:25,411 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:47:25,412 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:47:25,412 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:47:25,412 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:47:25,413 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:47:26,313 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:48:10,531 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1536
INFO 2017-06-06 14:48:10,532 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,546 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,560 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,577 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,587 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,601 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,613 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,627 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,640 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,653 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,667 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,678 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,690 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,703 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,715 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,726 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,739 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,751 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,762 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,773 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:10,791 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:48:24,909 Controller.py:297 - Heartbeat (response id = 1550) with server is running...
INFO 2017-06-06 14:48:24,910 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:48:24,915 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:48:25,411 Controller.py:313 - Sending Heartbeat (id = 1550)
INFO 2017-06-06 14:48:25,457 Controller.py:325 - Heartbeat response received (id = 1551)
INFO 2017-06-06 14:48:25,457 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:48:25,458 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:48:25,458 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:48:25,458 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:48:25,459 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:48:26,359 Controller.py:463 - Wait for next heartbeat over
INFO 2017-06-06 14:49:10,557 Controller.py:255 - Adding 21 status commands. Heartbeat id = 1600
INFO 2017-06-06 14:49:10,557 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_METASTORE of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,572 ActionQueue.py:118 - Adding STATUS_COMMAND for component MAPREDUCE2_CLIENT of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,586 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_CLIENT of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,604 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_CLIENT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,620 ActionQueue.py:118 - Adding STATUS_COMMAND for component SLIDER of service SLIDER of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,634 ActionQueue.py:118 - Adding STATUS_COMMAND for component APP_TIMELINE_SERVER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,650 ActionQueue.py:118 - Adding STATUS_COMMAND for component HIVE_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,661 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_MONITOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,673 ActionQueue.py:118 - Adding STATUS_COMMAND for component RESOURCEMANAGER of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,683 ActionQueue.py:118 - Adding STATUS_COMMAND for component HDFS_CLIENT of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,694 ActionQueue.py:118 - Adding STATUS_COMMAND for component ZKFC of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,709 ActionQueue.py:118 - Adding STATUS_COMMAND for component PIG of service PIG of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,721 ActionQueue.py:118 - Adding STATUS_COMMAND for component WEBHCAT_SERVER of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,733 ActionQueue.py:118 - Adding STATUS_COMMAND for component YARN_CLIENT of service YARN of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,748 ActionQueue.py:118 - Adding STATUS_COMMAND for component METRICS_COLLECTOR of service AMBARI_METRICS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,764 ActionQueue.py:118 - Adding STATUS_COMMAND for component NAMENODE of service HDFS of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,782 ActionQueue.py:118 - Adding STATUS_COMMAND for component OOZIE_SERVER of service OOZIE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,793 ActionQueue.py:118 - Adding STATUS_COMMAND for component SQOOP of service SQOOP of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,805 ActionQueue.py:118 - Adding STATUS_COMMAND for component TEZ_CLIENT of service TEZ of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,816 ActionQueue.py:118 - Adding STATUS_COMMAND for component HISTORYSERVER of service MAPREDUCE2 of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:10,828 ActionQueue.py:118 - Adding STATUS_COMMAND for component HCAT of service HIVE of cluster davidmod05cluster to the queue.
INFO 2017-06-06 14:49:21,728 logger.py:71 - Execute['export HIVE_CONF_DIR='/usr/hdp/current/hive-metastore/conf/conf.server' ; hive --hiveconf hive.metastore.uris=thrift://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:9083                 --hiveconf hive.metastore.client.connect.retry.delay=1                 --hiveconf hive.metastore.failure.retries=1                 --hiveconf hive.metastore.connect.retries=1                 --hiveconf hive.metastore.client.socket.timeout=14                 --hiveconf hive.execution.engine=mr -e 'show databases;''] {'path': ['/bin/', '/usr/bin/', '/usr/sbin/', u'/usr/hdp/current/hive-metastore/bin'], 'timeout_kill_strategy': 2, 'timeout': 60, 'user': 'ambari-qa'}
INFO 2017-06-06 14:49:21,744 logger.py:71 - Execute['! beeline -u 'jdbc:hive2://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:10001/;transportMode=http;httpPath=cliservice' -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL''] {'path': ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'], 'user': 'ambari-qa', 'timeout': 60}
INFO 2017-06-06 14:49:21,945 logger.py:71 - Execute['source /usr/hdp/current/oozie-server/conf/oozie-env.sh ; oozie admin -oozie http://hn0-davidm.mnk4wf22sbuexipuv5knp4cv4e.ax.internal.cloudapp.net:11000/oozie -status'] {'environment': None, 'user': 'oozie'}
INFO 2017-06-06 14:49:24,988 Controller.py:297 - Heartbeat (response id = 1614) with server is running...
INFO 2017-06-06 14:49:24,988 Controller.py:304 - Building heartbeat message
INFO 2017-06-06 14:49:24,992 Heartbeat.py:90 - Adding host info/state to heartbeat message.
INFO 2017-06-06 14:49:25,532 Controller.py:313 - Sending Heartbeat (id = 1614)
INFO 2017-06-06 14:49:25,576 Controller.py:325 - Heartbeat response received (id = 1615)
INFO 2017-06-06 14:49:25,578 Controller.py:334 - Heartbeat interval is 1 seconds
INFO 2017-06-06 14:49:25,579 Controller.py:370 - Updating configurations from heartbeat
INFO 2017-06-06 14:49:25,579 Controller.py:375 - Adding cancel commands
INFO 2017-06-06 14:49:25,580 Controller.py:379 - Adding execution commands
INFO 2017-06-06 14:49:25,581 Controller.py:456 - Waiting 0.9 for next heartbeat
INFO 2017-06-06 14:49:26,481 Controller.py:463 - Wait for next heartbeat over
